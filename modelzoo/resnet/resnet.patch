diff --git a/Intel/benchmarks/resnet/2-nodes-16s-8376H-tensorflow/README.md b/Intel/benchmarks/resnet/2-nodes-16s-8376H-tensorflow/README.md
deleted file mode 100644
index 2d637d2..0000000
--- a/Intel/benchmarks/resnet/2-nodes-16s-8376H-tensorflow/README.md
+++ /dev/null
@@ -1,128 +0,0 @@
-<!--- Licensed to the Apache Software Foundation (ASF) under one -->
-<!--- or more contributor license agreements.  See the NOTICE file -->
-<!--- distributed with this work for additional information -->
-<!--- regarding copyright ownership.  The ASF licenses this file -->
-<!--- to you under the Apache License, Version 2.0 (the -->
-<!--- "License"); you may not use this file except in compliance -->
-<!--- with the License.  You may obtain a copy of the License at -->
-
-<!---   http://www.apache.org/licenses/LICENSE-2.0 -->
-
-<!--- Unless required by applicable law or agreed to in writing, -->
-<!--- software distributed under the License is distributed on an -->
-<!--- "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY -->
-<!--- KIND, either express or implied.  See the License for the -->
-<!--- specific language governing permissions and limitations -->
-<!--- under the License. -->
-
-# Train ResNet50-v1.5 with ImageNet 1K with TensorFlow
-
-## 1. Description
-
-This repository trains ResNet50-v1.5 for image classification on ImageNet 1K dataset using TensorFlow. Part of code is forked from:
-
-https://github.com/IntelAI/models/tree/v1.6.1/models/image_recognition/tensorflow/resnet50v1_5/training
-
-See the following papers for more background about the model:
-
-[1] [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385) by Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun, Dec 2015.
-
-[2] [Identity Mappings in Deep Residual Networks](https://arxiv.org/abs/1603.05027) by Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun, Jul 2016.
-
-## 2. Installation
-
-Please follow the below steps to complete the setup of running environment.
-
-```bash
-mkdir -p $(pwd)/resnet
-cd $(pwd)/resnet
-```
-
-### 2.1 Software
-
-- TensorFlow
-Method 1: build from source
-Clone the intel-tensorflow publish repo, checkout the branch, and build from source.
-```bash
-git clone https://github.com/Intel-tensorflow/tensorflow.git
-cd tensorflow
-git checkout tf2_lars
-```
-Configure and build TF with oneDNN using the following bazel build command: 
-```
-bazel build --copt=-O3 --copt=-march=native --copt=-DENABLE_INTEL_MKL_BFLOAT16  --config=mkl --define build_with_mkl_dnn_v1_only=true -c opt //tensorflow/tools/pip_package:build_pip_package
-```
-- Intel MPI:
-This submission was done using Intel MPI 2019.10.317 version. Other versions should also work. Please consult Intel MPI page for installation instructions.  
-
-- Horovod
-We tested with horovod 0.19.1 version. Horovod can be installed using the following commands:
-```
-pip install --no-cache-dir horovod==0.19.1 
-```
-
-
-With the above steps done, TF+MPI+Horovod environment should be setup correctly. 
-
-- MLPerf logging utility
-
-```bash
-git clone https://github.com/mlperf/logging.git
-```
-Please make sure the above step are done inside the directory containing this README.md file. 
-
-
-### 2.2 Dataset
-
-The TF ResNet50-v1.5 model is trained with ImageNet 1K, a popular image classification dataset from ILSVRC challenge. The dataset can be downloaded from:
-
-http://image-net.org/download-images
-
-More dataset requirements can be found at:
-
-https://github.com/mlperf/training/tree/master/image_classification#3-datasetenvironment
-
-## 3. Training
-
-### 3.1 Structure & Loss
-
-In brief, this is a 50 layer v1 CNN. Refer to [Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385.pdf) for the layer structure and loss function.
-
-### 3.2 Optimizer
-The script supports both SGD optimizer and LARS optimizer. For best TTT, LARS optimizer should be used. 
-
-### 3.3 Training commands
-
-- Train on multiple Xeon Nodes with TensorFlow
-```
-cd mlperf_resnet
-./run_and_time_2N_32R_IntelMPI_oneCommand.sh
-```
-Please change the above node names to reflect your node names (e.g. ocpx04 -> yourhostname)
-### 3.4 Post processing the training output log to pass MLPerf compliance 
-When the above script finishes, resnet50v1.5\_\*.txt files would be generated.
-Run the following command to post process the results (as an example)
-
-```
-./post-process.sh resnet50v1.5\_0.txt
-```
-
-## 4. Quality
-
-### 4.1 Quality metric
-
-Percent of correct classifications on the ImageNet test dataset.
-
-### 4.2 Quality target
-
-0.749 accuracy (74.9% correct classifications) with TensorFlow.
-
-**Update**: MLPerf 0.6 changed the target to 75.9%.
-
-### 4.3 Evaluation frequency
-
-Evaluate after every 4 epoch.
-
-### 4.4 Evaluation thoroughness
-
-Every test example is used each time.
diff --git a/Intel/benchmarks/resnet/2-nodes-16s-8376H-tensorflow/__init__.py b/Intel/benchmarks/resnet/2-nodes-16s-8376H-tensorflow/__init__.py
old mode 100644
new mode 100755
diff --git a/Intel/benchmarks/resnet/2-nodes-16s-8376H-tensorflow/generate_submission_details.py b/Intel/benchmarks/resnet/2-nodes-16s-8376H-tensorflow/generate_submission_details.py
old mode 100644
new mode 100755
diff --git a/Intel/benchmarks/resnet/2-nodes-16s-8376H-tensorflow/lars_optimizer.py b/Intel/benchmarks/resnet/2-nodes-16s-8376H-tensorflow/lars_optimizer.py
old mode 100644
new mode 100755
diff --git a/Intel/benchmarks/resnet/2-nodes-16s-8376H-tensorflow/mlperf_resnet/imagenet_main.py b/Intel/benchmarks/resnet/2-nodes-16s-8376H-tensorflow/mlperf_resnet/imagenet_main.py
index af15c5b..fce7878 100644
--- a/Intel/benchmarks/resnet/2-nodes-16s-8376H-tensorflow/mlperf_resnet/imagenet_main.py
+++ b/Intel/benchmarks/resnet/2-nodes-16s-8376H-tensorflow/mlperf_resnet/imagenet_main.py
@@ -21,13 +21,19 @@ from __future__ import print_function
 import os
 import sys
 import random
+import os
+
+sys.path.append("/home/vmagent/app/e2eaiok/modelzoo/resnet/")
+
 
 import numpy.random
 import tensorflow as tf  # pylint: disable=g-bad-import-order
+import imagenet_preprocessing
+import resnet_model
+import resnet_run_loop
+import resnet_run_loop_eval
 
-from mlperf_resnet import imagenet_preprocessing
-from mlperf_resnet import resnet_model
-from mlperf_resnet import resnet_run_loop
+import time
 
 # import horovod if the above resnet_run_loop indiciates MPI
 if resnet_run_loop.is_mpi:
@@ -220,12 +226,14 @@ class ImagenetModel(resnet_model.Model):
     """
 
     # For bigger models, we want to use "bottleneck" layers
-    if resnet_size < 50:
-      bottleneck = False
-      final_size = 512
-    else:
-      bottleneck = True
-      final_size = 2048
+    # if resnet_size < 50:
+    #   bottleneck = False
+    #   final_size = 512
+    # else:
+    #   bottleneck = True
+    #   final_size = 2048
+    bottleneck = True
+    final_size = 2048
 
     super(ImagenetModel, self).__init__(
         resnet_size=resnet_size,
@@ -289,7 +297,9 @@ def imagenet_model_fn(features, labels, mode, params):
   if params['fine_tune']:
     base_lr = .1
   else:
-    base_lr = .128
+    base_lr = params['base_lr']
+  
+  # base_lr = 0.15
 
   num_workers = 1 if resnet_run_loop.is_mpi == 0 else hvd.size()
   global_batch_size = params['batch_size'] * num_workers
@@ -304,10 +314,12 @@ def imagenet_model_fn(features, labels, mode, params):
       labels=labels,
       mode=mode,
       model_class=ImagenetModel,
+      num_filters=params['num_filters'],
       resnet_size=params['resnet_size'],
       weight_decay=params['weight_decay'],
       learning_rate_fn=learning_rate_fn,
-      momentum=0.9,
+      momentum=params['momentum'],
+      kernel_size=params['kernel_size'],
       data_format=params['data_format'],
       version=params['version'],
       loss_scale=params['loss_scale'],
@@ -319,7 +331,16 @@ def imagenet_model_fn(features, labels, mode, params):
   )
 
 
+
+"""
+num_filters
+momentum
+
+"""
+
+
 def main(argv):
+  all_start = time.time()
   parser = resnet_run_loop.ResnetArgParser(
       resnet_size_choices=[18, 34, 50, 101, 152, 200])
 
@@ -329,6 +350,7 @@ def main(argv):
   )
 
   flags = parser.parse_args(args=argv[2:])
+  print(F"flags:{flags}")
 
   seed = int(argv[1])
   print('Setting random seed = ', seed)
@@ -339,9 +361,16 @@ def main(argv):
 
   input_function = flags.use_synthetic_data and get_synth_input_fn() or input_fn
 
-  resnet_run_loop.resnet_main(seed,
-      flags, imagenet_model_fn, input_function,
-      shape=[_DEFAULT_IMAGE_SIZE, _DEFAULT_IMAGE_SIZE, _NUM_CHANNELS])
+  if not flags.eval_mode:
+    resnet_run_loop.resnet_main(seed,
+        flags, imagenet_model_fn, input_function,
+        shape=[_DEFAULT_IMAGE_SIZE, _DEFAULT_IMAGE_SIZE, _NUM_CHANNELS])
+  else:
+    resnet_run_loop_eval.resnet_main(seed,
+        flags, imagenet_model_fn, input_function,
+        shape=[_DEFAULT_IMAGE_SIZE, _DEFAULT_IMAGE_SIZE, _NUM_CHANNELS])
+  all_end = time.time()
+  print(F"Total time:{all_end - all_start}")
 
 
 if __name__ == '__main__':
diff --git a/Intel/benchmarks/resnet/2-nodes-16s-8376H-tensorflow/mlperf_resnet/resnet_run_loop.py b/Intel/benchmarks/resnet/2-nodes-16s-8376H-tensorflow/mlperf_resnet/resnet_run_loop.py
index 4b5aeff..c17d486 100644
--- a/Intel/benchmarks/resnet/2-nodes-16s-8376H-tensorflow/mlperf_resnet/resnet_run_loop.py
+++ b/Intel/benchmarks/resnet/2-nodes-16s-8376H-tensorflow/mlperf_resnet/resnet_run_loop.py
@@ -25,9 +25,11 @@ from __future__ import print_function
 
 import argparse
 import os
+import time
+import sys
 
-import tensorflow as tf  # pylint: disable=g-bad-import-order
 
+import tensorflow as tf  # pylint: disable=g-bad-import-order
 from mlperf_compliance import mlperf_log
 from mlperf_logging import mllog
 from mlperf_compliance import tf_mlperf_log
@@ -37,12 +39,14 @@ from mlperf_utils.export import export
 from mlperf_utils.logs import hooks_helper
 from mlperf_utils.logs import logger
 from mlperf_utils.misc import model_helpers
-
+from lars_optimizer import LARSOptimizer
+from tensorflow.python import eager
 global is_mpi
 try:
     import horovod.tensorflow as hvd
     hvd.init()
     is_mpi = hvd.size()
+    print(F"horovod size:{is_mpi}")
 except ImportError:
     is_mpi = 0
     print("No MPI horovod support, this is running in no-MPI mode!")
@@ -146,8 +150,8 @@ def get_synth_input_fn(height, width, num_channels, num_classes):
   """
   def input_fn(is_training, data_dir, batch_size, *args, **kwargs):  # pylint: disable=unused-argument
     images = tf.zeros((batch_size, height, width, num_channels), tf.float32)
-    labels = tf.zeros((batch_size, num_classes), tf.int32)
-    return tf.data.Dataset.from_tensors((images, labels)).repeat()
+    labels = tf.zeros((batch_size), tf.int32)
+    return tf.data.Dataset.from_tensors((images, labels))
 
   return input_fn
 
@@ -261,8 +265,8 @@ def learning_rate_with_decay(
   return learning_rate_fn
 
 
-def resnet_model_fn(features, labels, mode, model_class,
-                    resnet_size, weight_decay, learning_rate_fn, momentum,
+def resnet_model_fn(features, labels, mode, model_class, num_filters,
+                    resnet_size, weight_decay, learning_rate_fn, momentum, kernel_size,
                     data_format, version, loss_scale, loss_filter_fn=None,
                     dtype=resnet_model.DEFAULT_DTYPE,
                     label_smoothing=0.0, enable_lars=False,
@@ -386,9 +390,8 @@ def resnet_model_fn(features, labels, mode, model_class,
     tf.identity(learning_rate, name='learning_rate')
     tf.compat.v1.summary.scalar('learning_rate', learning_rate)
 
-
     if enable_lars:
-      optimizer = tf.compat.v1.train.LARSOptimizer(
+      optimizer = LARSOptimizer(
           learning_rate=learning_rate,
           momentum=momentum,
           weight_decay=weight_decay,
@@ -550,7 +553,11 @@ def resnet_main(seed, flags, model_function, input_function, shape=None):
           'enable_lars': flags.enable_lars,
           'weight_decay': flags.weight_decay,
           'fine_tune': flags.fine_tune,
-          'use_bfloat16': flags.use_bfloat16
+          'use_bfloat16': flags.use_bfloat16,
+          'num_filters' : flags.num_filters,
+          'momentum' : flags.momentum,
+          'kernel_size' : flags.kernel_size,
+          'base_lr' : flags.base_lr
       })
   eval_classifier = tf.estimator.Estimator(
       model_fn=model_function, model_dir=model_dir.rsplit('/', 1)[0]+'/main', config=run_config,
@@ -565,7 +572,11 @@ def resnet_main(seed, flags, model_function, input_function, shape=None):
           'enable_lars': flags.enable_lars,
           'weight_decay': flags.weight_decay,
           'fine_tune': flags.fine_tune,
-          'use_bfloat16': flags.use_bfloat16
+          'use_bfloat16': flags.use_bfloat16,
+          'num_filters' : flags.num_filters,
+          'momentum' : flags.momentum,
+          'kernel_size' : flags.kernel_size,
+          'base_lr' : flags.base_lr
       })
 
   if benchmark_log_dir is not None:
@@ -584,6 +595,12 @@ def resnet_main(seed, flags, model_function, input_function, shape=None):
   # The reference performs the first evaluation on the fourth epoch. (offset
   # eval by 3 epochs)
   success = False
+  train_start_time = time.time()
+  print(F"-----flags:{flags}")
+  print(F"flags.train_epochs // flags.epochs_between_evals:{flags.train_epochs // flags.epochs_between_evals}")
+  print(F"flags.train_epochs:{flags.train_epochs}")
+  print(F"flags.epochs_between_evals:{flags.epochs_between_evals}")
+# with eager.profiler.Profiler('.'):
   for i in range(flags.train_epochs // flags.epochs_between_evals):
     # Data for epochs_between_evals (i.e. 4 epochs between evals) worth of
     # epochs is concatenated and run as a single block inside a session. For
@@ -592,7 +609,7 @@ def resnet_main(seed, flags, model_function, input_function, shape=None):
     mllogger.start(key=mllog.constants.BLOCK_START, value=i+1)
     mllogger.event(key=mllog.constants.FIRST_EPOCH_NUM, value=i*flags.epochs_between_evals)
     mllogger.event(key=mllog.constants.EPOCH_COUNT, value=flags.epochs_between_evals)
-
+    
     for j in range(flags.epochs_between_evals):
       mllogger.event(key=mllog.constants.EPOCH_NUM,
                               value=i * flags.epochs_between_evals + j)
@@ -625,7 +642,7 @@ def resnet_main(seed, flags, model_function, input_function, shape=None):
       formatter=formatter)
 
     print('Starting a training cycle.')
-
+    # proflier_hook = tf.estimator.ProfilerHook(save_steps=None, save_secs=None, output_dir='.', show_dataflow=True,show_memory=True)
     def input_fn_train():
       return input_function(
           is_training=True,
@@ -645,7 +662,6 @@ def resnet_main(seed, flags, model_function, input_function, shape=None):
           train_steps = flags.max_train_steps
       else:
           train_steps = steps_per_eval_per_worker
-
       classifier.train(input_fn=input_fn_train, hooks=train_hooks + [compliance_hook],
               steps=train_steps)
     else:
@@ -677,14 +693,18 @@ def resnet_main(seed, flags, model_function, input_function, shape=None):
     # global_step count.
     eval_hooks = [hvd.BroadcastGlobalVariablesHook(0)]
     eval_results = eval_classifier.evaluate(input_fn=input_fn_eval,
-                                       steps=flags.max_train_steps, hooks=eval_hooks)
+                                      steps=flags.max_train_steps, hooks=eval_hooks)
     eval_results_per_worker = eval_results['accuracy']
     allreduced_results = hvd.allreduce(eval_results_per_worker)
+    all_result = allreduced_results.numpy()
+    file = '/home/vmagent/app/e2eaiok/modelzoo/resnet/mlperf_resnet/metric.txt'
+    with open(file, 'w') as f:
+        f.writelines(str(all_result))
     mllogger.event(key=mllog.constants.EVAL_SAMPLES, value=int(eval_results[_NUM_EXAMPLES_NAME]))
     #mllogger.event(key=mllog.constants.EVAL_ACCURACY, value=float(eval_results['accuracy']))
     mllogger.event(key=mllog.constants.EVAL_ACCURACY, value=float(allreduced_results))
     mllogger.end(key=mllog.constants.EVAL_STOP)
-    print(allreduced_results)
+    print(F"allreduced_results:{allreduced_results}")
 
     if benchmark_logger:
       benchmark_logger.log_estimator_evaluation_result(eval_results)
@@ -693,6 +713,8 @@ def resnet_main(seed, flags, model_function, input_function, shape=None):
         flags.stop_threshold, float(allreduced_results)):
       success = True
       break
+  train_end_time = time.time()
+  print(F"train total time:{train_end_time - train_start_time}")
 
   mllogger.event(key=mllog.constants.RUN_STOP, value={"success": success})
   mllogger.end(key=mllog.constants.RUN_STOP)
@@ -728,6 +750,11 @@ class ResnetArgParser(argparse.ArgumentParser):
         help='Whether to use bfloat16 type for computations.'
     )
 
+    self.add_argument(
+        '--eval_mode', action='store_true', default=False,
+        help='Whether to use eval mode.'
+    )
+
   def parse_args(self, args=None, namespace=None):
     args = super(ResnetArgParser, self).parse_args(
         args=args, namespace=namespace)
diff --git a/Intel/benchmarks/resnet/2-nodes-16s-8376H-tensorflow/mlperf_resnet/resnet_run_loop_eval.py b/Intel/benchmarks/resnet/2-nodes-16s-8376H-tensorflow/mlperf_resnet/resnet_run_loop_eval.py
new file mode 100644
index 0000000..bddbf5d
--- /dev/null
+++ b/Intel/benchmarks/resnet/2-nodes-16s-8376H-tensorflow/mlperf_resnet/resnet_run_loop_eval.py
@@ -0,0 +1,660 @@
+# Copyright 2017 The TensorFlow Authors. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+# ==============================================================================
+"""Contains utility and supporting functions for ResNet.
+
+  This module contains ResNet code which does not directly build layers. This
+includes dataset management, hyperparameter and optimizer code, and argument
+parsing. Code for defining the ResNet layers can be found in resnet_model.py.
+"""
+
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+import argparse
+import os
+import time
+import sys
+
+
+import tensorflow as tf  # pylint: disable=g-bad-import-order
+from mlperf_compliance import mlperf_log
+from mlperf_logging import mllog
+from mlperf_compliance import tf_mlperf_log
+from mlperf_resnet import resnet_model
+from mlperf_utils.arg_parsers import parsers
+from mlperf_utils.export import export
+from mlperf_utils.logs import hooks_helper
+from mlperf_utils.logs import logger
+from mlperf_utils.misc import model_helpers
+from lars_optimizer import LARSOptimizer
+from tensorflow.python import eager
+global is_mpi
+try:
+    import horovod.tensorflow as hvd
+    hvd.init()
+    is_mpi = hvd.size()
+    print(F"horovod size:{is_mpi}")
+except ImportError:
+    is_mpi = 0
+    print("No MPI horovod support, this is running in no-MPI mode!")
+
+mllogger = mllog.get_mllogger()
+filenames = "resnet50v1.5.log-" + str(hvd.rank())
+mllog.config(filename=filenames)
+workername = "worker" + str(hvd.rank())
+mllog.config(
+    default_namespace = workername,
+    default_stack_offset = 1,
+    default_clear_line = False,
+    root_dir = os.path.normpath(
+      os.path.join(os.path.dirname(os.path.realpath(__file__)), "..", "..")))
+mllogger.event(key=mllog.constants.CACHE_CLEAR)
+mllogger.start(key=mllog.constants.RUN_START)
+
+_NUM_EXAMPLES_NAME = "num_examples"
+_NUM_IMAGES = {
+        'train': 1281167,
+        'validation': 50000
+}
+
+
+################################################################################
+# Functions for input processing.
+################################################################################
+def process_record_dataset(dataset, is_training, batch_size, shuffle_buffer,
+                           parse_record_fn, num_epochs=1, num_gpus=None,
+                           examples_per_epoch=None, dtype=tf.float32):
+  """Given a Dataset with raw records, return an iterator over the records.
+
+  Args:
+    dataset: A Dataset representing raw records
+    is_training: A boolean denoting whether the input is for training.
+    batch_size: The number of samples per batch.
+    shuffle_buffer: The buffer size to use when shuffling records. A larger
+      value results in better randomness, but smaller values reduce startup
+      time and use less memory.
+    parse_record_fn: A function that takes a raw record and returns the
+      corresponding (image, label) pair.
+    num_epochs: The number of epochs to repeat the dataset.
+    num_gpus: The number of gpus used for training.
+    examples_per_epoch: The number of examples in an epoch.
+    dtype: Data type to use for images/features.
+
+  Returns:
+    Dataset of (image, label) pairs ready for iteration.
+  """
+
+  # We prefetch a batch at a time, This can help smooth out the time taken to
+  # load input files as we go through shuffling and processing.
+  dataset = dataset.prefetch(buffer_size=batch_size)
+  if is_training:
+    if is_mpi:
+      dataset = dataset.shard(hvd.size(), hvd.rank())
+    # Shuffle the records. Note that we shuffle before repeating to ensure
+    # that the shuffling respects epoch boundaries.
+    dataset = dataset.shuffle(buffer_size=shuffle_buffer)
+
+  # If we are training over multiple epochs before evaluating, repeat the
+  # dataset for the appropriate number of epochs.
+  dataset = dataset.repeat(num_epochs)
+
+  # Parse the raw records into images and labels. Testing has shown that setting
+  # num_parallel_batches > 1 produces no improvement in throughput, since
+  # batch_size is almost always much greater than the number of CPU cores.
+  dataset = dataset.apply(
+      tf.data.experimental.map_and_batch(
+          lambda value: parse_record_fn(value, is_training, dtype),
+          batch_size=batch_size,
+          num_parallel_batches=1))
+
+  # Operations between the final prefetch and the get_next call to the iterator
+  # will happen synchronously during run time. We prefetch here again to
+  # background all of the above processing work and keep it out of the
+  # critical training path. Setting buffer_size to tf.contrib.data.AUTOTUNE
+  # allows DistributionStrategies to adjust how many batches to fetch based
+  # on how many devices are present.
+  dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)
+
+  return dataset
+
+
+def get_synth_input_fn(height, width, num_channels, num_classes):
+  """Returns an input function that returns a dataset with zeroes.
+
+  This is useful in debugging input pipeline performance, as it removes all
+  elements of file reading and image preprocessing.
+
+  Args:
+    height: Integer height that will be used to create a fake image tensor.
+    width: Integer width that will be used to create a fake image tensor.
+    num_channels: Integer depth that will be used to create a fake image tensor.
+    num_classes: Number of classes that should be represented in the fake labels
+      tensor
+
+  Returns:
+    An input_fn that can be used in place of a real one to return a dataset
+    that can be used for iteration.
+  """
+  def input_fn(is_training, data_dir, batch_size, *args, **kwargs):  # pylint: disable=unused-argument
+    images = tf.zeros((batch_size, height, width, num_channels), tf.float32)
+    labels = tf.zeros((batch_size), tf.int32)
+    return tf.data.Dataset.from_tensors((images, labels))
+
+  return input_fn
+
+
+################################################################################
+# Functions for running training/eval/validation loops for the model.
+################################################################################
+def learning_rate_with_decay(
+    batch_size, batch_denom, num_images, boundary_epochs, decay_rates,
+    base_lr=0.1, enable_lars=False):
+  """Get a learning rate that decays step-wise as training progresses.
+
+  Args:
+    batch_size: the number of examples processed in each training batch.
+    batch_denom: this value will be used to scale the base learning rate.
+      `0.1 * batch size` is divided by this number, such that when
+      batch_denom == batch_size, the initial learning rate will be 0.1.
+    num_images: total number of images that will be used for training.
+    boundary_epochs: list of ints representing the epochs at which we
+      decay the learning rate.
+    decay_rates: list of floats representing the decay rates to be used
+      for scaling the learning rate. It should have one more element
+      than `boundary_epochs`, and all elements should have the same type.
+    base_lr: Initial learning rate scaled based on batch_denom.
+
+  Returns:
+    Returns a function that takes a single argument - the number of batches
+    trained so far (global_step)- and returns the learning rate to be used
+    for training the next batch.
+  """
+  initial_learning_rate = base_lr * batch_size / batch_denom
+  batches_per_epoch = num_images / batch_size
+
+  # Multiply the learning rate by 0.1 at 100, 150, and 200 epochs.
+  boundaries = [int(batches_per_epoch * epoch) for epoch in boundary_epochs]
+  vals = [initial_learning_rate * decay for decay in decay_rates]
+
+  def learning_rate_fn(global_step):
+    lr = tf.compat.v1.train.piecewise_constant(global_step, boundaries, vals)
+    warmup_steps = int(batches_per_epoch * 5)
+    warmup_lr = (
+        initial_learning_rate * tf.cast(global_step, tf.float32) / tf.cast(
+        warmup_steps, tf.float32))
+    return tf.cond(pred=global_step < warmup_steps, true_fn=lambda: warmup_lr, false_fn=lambda: lr)
+
+  def poly_rate_fn(global_step):
+    """Handles linear scaling rule, gradual warmup, and LR decay.
+
+    The learning rate starts at 0, then it increases linearly per step.  After
+    flags.poly_warmup_epochs, we reach the base learning rate (scaled to account
+    for batch size). The learning rate is then decayed using a polynomial rate
+    decay schedule with power 2.0.
+
+    Args:
+    global_step: the current global_step
+
+    Returns:
+    returns the current learning rate
+    """
+
+    # Learning rate schedule for LARS polynomial schedule
+    if batch_size <= 4096:
+      plr = 10.0
+      w_epochs = 5
+    elif batch_size <= 8192:
+      plr = 10.0
+      w_epochs = 5
+    elif batch_size <= 16384:
+      plr = 25.0
+      w_epochs = 5
+    else: # e.g. 32768
+      plr = 33.0
+      w_epochs = 25
+
+    # overwrite plr
+    # Note: the following may need to be changed when changing HPs
+    # Applying Google v0.7 tpu-v3-32-TF2.0 HyperParameters
+    # Apply NVIDIA HP
+    plr = 10.5
+    w_epochs = 2
+    #w_steps = int(w_epochs * batches_per_epoch)
+    # 313 per step, warmup 2 epochs
+    # 393 per step
+    w_steps = 786 
+    wrate = (plr * tf.cast(global_step, tf.float32) / tf.cast(
+        w_steps, tf.float32))
+
+    num_epochs = 37  # not used 
+    #train_steps = batches_per_epoch * num_epochs
+    #train_steps = 12794 # Google learning rate decay step + 626 -1
+    train_steps = 14541
+    mllogger.event(key=mllog.constants.LARS_OPT_LR_DECAY_STEPS, value=train_steps-w_steps+1)
+
+    min_step = tf.constant(1, dtype=tf.int64)
+    decay_steps = tf.maximum(min_step, tf.subtract(global_step, w_steps))
+    poly_rate = tf.compat.v1.train.polynomial_decay(
+        plr,
+        decay_steps,
+        train_steps - w_steps + 1,
+        power=2.0)
+    mllogger.event(key=mllog.constants.OPT_BASE_LR, value=plr)
+    mllogger.event(key=mllog.constants.LARS_OPT_LR_DECAY_POLY_POWER, value=2)
+    mllogger.event(key=mllog.constants.LARS_OPT_END_LR, value=0.0001)
+    mllogger.event(key=mllog.constants.OPT_LR_WARMUP_EPOCHS, value=w_epochs)
+    return tf.compat.v1.where(global_step <= w_steps, wrate, poly_rate)
+
+  # For LARS we have a new learning rate schedule
+  if enable_lars:
+    return poly_rate_fn
+
+  return learning_rate_fn
+
+
+def resnet_model_fn(features, labels, mode, model_class, num_filters,
+                    resnet_size, weight_decay, learning_rate_fn, momentum, kernel_size,
+                    data_format, version, loss_scale, loss_filter_fn=None,
+                    dtype=resnet_model.DEFAULT_DTYPE,
+                    label_smoothing=0.0, enable_lars=False,
+                    use_bfloat16=False):
+  """Shared functionality for different resnet model_fns.
+
+  Initializes the ResnetModel representing the model layers
+  and uses that model to build the necessary EstimatorSpecs for
+  the `mode` in question. For training, this means building losses,
+  the optimizer, and the train op that get passed into the EstimatorSpec.
+  For evaluation and prediction, the EstimatorSpec is returned without
+  a train op, but with the necessary parameters for the given mode.
+
+  Args:
+    features: tensor representing input images
+    labels: tensor representing class labels for all input images
+    mode: current estimator mode; should be one of
+      `tf.estimator.ModeKeys.TRAIN`, `EVALUATE`, `PREDICT`
+    model_class: a class representing a TensorFlow model that has a __call__
+      function. We assume here that this is a subclass of ResnetModel.
+    resnet_size: A single integer for the size of the ResNet model.
+    weight_decay: weight decay loss rate used to regularize learned variables.
+    learning_rate_fn: function that returns the current learning rate given
+      the current global_step
+    momentum: momentum term used for optimization
+    data_format: Input format ('channels_last', 'channels_first', or None).
+      If set to None, the format is dependent on whether a GPU is available.
+    version: Integer representing which version of the ResNet network to use.
+      See README for details. Valid values: [1, 2]
+    loss_scale: The factor to scale the loss for numerical stability. A detailed
+      summary is present in the arg parser help text.
+    loss_filter_fn: function that takes a string variable name and returns
+      True if the var should be included in loss calculation, and False
+      otherwise. If None, batch_normalization variables will be excluded
+      from the loss.
+    dtype: the TensorFlow dtype to use for calculations.
+    use_bfloat16: Whether to use bfloat16 type for calculations.
+
+  Returns:
+    EstimatorSpec parameterized according to the input params and the
+    current mode.
+  """
+
+  # Generate a summary node for the images
+  tf.compat.v1.summary.image('images', features, max_outputs=6)
+
+  # Checks that features/images have same data type being used for calculations.
+  assert features.dtype == dtype
+
+  if use_bfloat16 == True:
+    dtype = tf.bfloat16
+
+  features = tf.cast(features, dtype)
+
+  model = model_class(resnet_size, data_format, version=version, dtype=dtype)
+
+  logits = model(features, mode == tf.estimator.ModeKeys.TRAIN)
+
+  # This acts as a no-op if the logits are already in fp32 (provided logits are
+  # not a SparseTensor). If dtype is is low precision, logits must be cast to
+  # fp32 for numerical stability.
+  logits = tf.cast(logits, tf.float32)
+
+  num_examples_metric = tf_mlperf_log.sum_metric(tensor=tf.shape(input=logits)[0], name=_NUM_EXAMPLES_NAME)
+
+  predictions = {
+      'classes': tf.argmax(input=logits, axis=1),
+      'probabilities': tf.nn.softmax(logits, name='softmax_tensor')
+  }
+
+  mode = 'EVALUATE'
+  if mode == tf.estimator.ModeKeys.PREDICT:
+    # Return the predictions and the specification for serving a SavedModel
+    return tf.estimator.EstimatorSpec(
+        mode=mode,
+        predictions=predictions,
+        export_outputs={
+            'predict': tf.estimator.export.PredictOutput(predictions)
+        })
+
+  # Calculate loss, which includes softmax cross entropy and L2 regularization.
+
+  if label_smoothing != 0.0:
+    one_hot_labels = tf.one_hot(labels, 1001)
+    cross_entropy = tf.compat.v1.losses.softmax_cross_entropy(
+        logits=logits, onehot_labels=one_hot_labels,
+        label_smoothing=label_smoothing)
+  else:
+    cross_entropy = tf.compat.v1.losses.sparse_softmax_cross_entropy(
+        logits=logits, labels=labels)
+
+  # Create a tensor named cross_entropy for logging purposes.
+  tf.identity(cross_entropy, name='cross_entropy')
+  tf.compat.v1.summary.scalar('cross_entropy', cross_entropy)
+
+  # If no loss_filter_fn is passed, assume we want the default behavior,
+  # which is that batch_normalization variables are excluded from loss.
+  def exclude_batch_norm(name):
+    return 'batch_normalization' not in name
+  loss_filter_fn = loss_filter_fn or exclude_batch_norm
+
+
+  # Add weight decay to the loss.
+  l2_loss = weight_decay * tf.add_n(
+      # loss is computed using fp32 for numerical stability.
+      [tf.nn.l2_loss(tf.cast(v, tf.float32)) for v in tf.compat.v1.trainable_variables()
+       if loss_filter_fn(v.name)])
+  tf.compat.v1.summary.scalar('l2_loss', l2_loss)
+  loss = cross_entropy + l2_loss
+
+  if mode == tf.estimator.ModeKeys.TRAIN:
+    global_step = tf.compat.v1.train.get_or_create_global_step()
+
+    learning_rate = learning_rate_fn(global_step)
+
+    log_id = mlperf_log.resnet_print(key=mlperf_log.OPT_LR, deferred=True)
+    learning_rate = tf_mlperf_log.log_deferred(op=learning_rate, log_id=log_id,
+                                               every_n=100)
+
+    # Create a tensor named learning_rate for logging purposes
+    tf.identity(learning_rate, name='learning_rate')
+    tf.compat.v1.summary.scalar('learning_rate', learning_rate)
+
+    if enable_lars:
+      optimizer = LARSOptimizer(
+          learning_rate=learning_rate,
+          momentum=momentum,
+          weight_decay=weight_decay,
+          skip_list=['batch_normalization', 'bias'])
+      mllogger.event(key=mllog.constants.OPT_NAME,
+                            value=mllog.constants.LARS)
+      mllogger.event(key=mllog.constants.LARS_EPSILON, value=0.0)
+      mllogger.event(key=mllog.constants.LARS_OPT_WEIGHT_DECAY, value=weight_decay)
+    else:
+      optimizer = tf.compat.v1.train.MomentumOptimizer(
+          learning_rate=learning_rate,
+          momentum=momentum
+      )
+    if is_mpi:
+      optimizer = hvd.DistributedOptimizer(optimizer)
+
+    if loss_scale != 1:
+      # When computing fp16 gradients, often intermediate tensor values are
+      # so small, they underflow to 0. To avoid this, we multiply the loss by
+      # loss_scale to make these tensor values loss_scale times bigger.
+      scaled_grad_vars = optimizer.compute_gradients(loss * loss_scale)
+
+      # Once the gradient computation is complete we can scale the gradients
+      # back to the correct scale before passing them to the optimizer.
+      unscaled_grad_vars = [(grad / loss_scale, var)
+                            for grad, var in scaled_grad_vars]
+      minimize_op = optimizer.apply_gradients(unscaled_grad_vars, global_step)
+    else:
+      minimize_op = optimizer.minimize(loss, global_step)
+
+    update_ops = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.UPDATE_OPS)
+    train_op = tf.group(minimize_op, update_ops, num_examples_metric[1])
+  else:
+    train_op = None
+
+  accuracy = tf.compat.v1.metrics.accuracy(labels, predictions['classes'])
+  accuracy_top_5 = tf.compat.v1.metrics.mean(tf.nn.in_top_k(predictions=logits,
+                                                  targets=labels,
+                                                  k=5,
+                                                  name='top_5_op'))
+
+  metrics = {'accuracy': accuracy,
+             'accuracy_top_5': accuracy_top_5,
+             _NUM_EXAMPLES_NAME: num_examples_metric}
+
+  # Create a tensor named train_accuracy for logging purposes
+  tf.identity(accuracy[1], name='train_accuracy')
+  tf.identity(accuracy_top_5[1], name='train_accuracy_top_5')
+  tf.compat.v1.summary.scalar('train_accuracy', accuracy[1])
+  tf.compat.v1.summary.scalar('train_accuracy_top_5', accuracy_top_5[1])
+
+  return tf.estimator.EstimatorSpec(
+      mode=mode,
+      predictions=predictions,
+      loss=loss,
+      train_op=train_op,
+      eval_metric_ops=metrics)
+
+
+def per_device_batch_size(batch_size, num_gpus):
+  """For multi-gpu, batch-size must be a multiple of the number of GPUs.
+
+  Note that this should eventually be handled by DistributionStrategies
+  directly. Multi-GPU support is currently experimental, however,
+  so doing the work here until that feature is in place.
+
+  Args:
+    batch_size: Global batch size to be divided among devices. This should be
+      equal to num_gpus times the single-GPU batch_size for multi-gpu training.
+    num_gpus: How many GPUs are used with DistributionStrategies.
+
+  Returns:
+    Batch size per device.
+
+  Raises:
+    ValueError: if batch_size is not divisible by number of devices
+  """
+  if num_gpus <= 1:
+    return batch_size
+
+  remainder = batch_size % num_gpus
+  if remainder:
+    err = ('When running with multiple GPUs, batch size '
+           'must be a multiple of the number of available GPUs. Found {} '
+           'GPUs with a batch size of {}; try --batch_size={} instead.'
+          ).format(num_gpus, batch_size, batch_size - remainder)
+    raise ValueError(err)
+  return int(batch_size / num_gpus)
+
+
+def resnet_main(seed, flags, model_function, input_function, shape=None):
+  """Shared main loop for ResNet Models.
+
+  Args:
+    flags: FLAGS object that contains the params for running. See
+      ResnetArgParser for created flags.
+    model_function: the function that instantiates the Model and builds the
+      ops for train/eval. This will be passed directly into the estimator.
+    input_function: the function that processes the dataset and returns a
+      dataset that the estimator can train on. This will be wrapped with
+      all the relevant flags for running and passed to estimator.
+    shape: list of ints representing the shape of the images used for training.
+      This is only used if flags.export_dir is passed.
+  """
+
+
+  # Using the Winograd non-fused algorithms provides a small performance boost.
+  os.environ['TF_ENABLE_WINOGRAD_NONFUSED'] = '1'
+
+  # Create session config based on values of inter_op_parallelism_threads and
+  # intra_op_parallelism_threads. Note that we default to having
+  # allow_soft_placement = True, which is required for multi-GPU and not
+  # harmful for other modes.
+  session_config = tf.compat.v1.ConfigProto(
+      inter_op_parallelism_threads=flags.inter_op_parallelism_threads,
+      intra_op_parallelism_threads=flags.intra_op_parallelism_threads,
+      allow_soft_placement=True)
+
+  if flags.num_gpus == 0:
+    distribution = tf.distribute.OneDeviceStrategy('device:CPU:0')
+  elif flags.num_gpus == 1:
+    distribution = tf.distribute.OneDeviceStrategy('device:GPU:0')
+  else:
+    distribution = tf.distribute.MirroredStrategy(
+        num_gpus=flags.num_gpus
+    )
+
+  mllogger.event(key=mllog.constants.SEED, value=seed)
+  run_config = tf.estimator.RunConfig(train_distribute=distribution,
+                                      session_config=session_config,
+                                      log_step_count_steps=20, # output logs more frequently
+                                      save_checkpoints_steps=2502,
+                                      keep_checkpoint_max=1,
+                                      tf_random_seed=seed)
+
+  mllogger.event(key=mllog.constants.GLOBAL_BATCH_SIZE,
+                          value=flags.batch_size*hvd.size())
+
+  if is_mpi:
+      if hvd.rank() == 0:
+          model_dir = os.path.join(flags.model_dir,"main")
+      else:
+          model_dir = os.path.join(flags.model_dir,"tmp{}".format(hvd.rank()))
+      benchmark_log_dir = flags.benchmark_log_dir if hvd.rank() == 0 else None
+  else:
+      model_dir = flags.model_dir
+      benchmark_log_dir = flags.benchmark_log_dir
+
+  eval_classifier = tf.estimator.Estimator(
+      model_fn=model_function, model_dir=model_dir.rsplit('/', 1)[0]+'/main', config=run_config,
+      params={
+          'resnet_size': flags.resnet_size,
+          'data_format': flags.data_format,
+          'batch_size': flags.batch_size,
+          'version': flags.version,
+          'loss_scale': flags.loss_scale,
+          'dtype': flags.dtype,
+          'label_smoothing': flags.label_smoothing,
+          'enable_lars': flags.enable_lars,
+          'weight_decay': flags.weight_decay,
+          'fine_tune': flags.fine_tune,
+          'use_bfloat16': flags.use_bfloat16,
+          'num_filters' : flags.num_filters,
+          'momentum' : flags.momentum,
+          'kernel_size' : flags.kernel_size,
+          'base_lr' : flags.base_lr
+      })
+
+  if benchmark_log_dir is not None:
+    benchmark_logger = logger.BenchmarkLogger(benchmark_log_dir)
+    benchmark_logger.log_run_info('resnet')
+  else:
+    benchmark_logger = None
+
+  # for MPI only to figure out the steps per epoch or per eval, per worker 
+  if is_mpi:
+    num_eval_steps = _NUM_IMAGES['validation'] // flags.batch_size
+    steps_per_epoch = _NUM_IMAGES['train'] // flags.batch_size
+    steps_per_epoch_per_worker = steps_per_epoch // hvd.size()
+    steps_per_eval_per_worker = steps_per_epoch_per_worker * flags.epochs_between_evals
+
+  # The reference performs the first evaluation on the fourth epoch. (offset
+  # eval by 3 epochs)
+  success = False
+  
+  print('Starting to evaluate.')
+    # Evaluate the model and print results
+  def input_fn_eval():
+    return input_function(
+        is_training=False,
+        data_dir=flags.data_dir,
+        #batch_size=per_device_batch_size(flags.batch_size, flags.num_gpus),
+        batch_size=100,
+        num_epochs=1,
+        dtype=flags.dtype
+    )
+
+
+    mllogger.start(key=mllog.constants.EVAL_START)
+
+  mllogger.start(key=mllog.constants.EVAL_START)
+  # flags.max_train_steps is generally associated with testing and profiling.
+  # As a result it is frequently called with synthetic data, which will
+  # iterate forever. Passing steps=flags.max_train_steps allows the eval
+  # (which is generally unimportant in those circumstances) to terminate.
+  # Note that eval will run for max_train_steps each loop, regardless of the
+  # global_step count.
+  eval_hooks = [hvd.BroadcastGlobalVariablesHook(0)]
+  eval_results = eval_classifier.evaluate(input_fn=input_fn_eval, hooks=eval_hooks)
+  eval_results_per_worker = eval_results['accuracy']
+  allreduced_results = hvd.allreduce(eval_results_per_worker)
+  mllogger.event(key=mllog.constants.EVAL_SAMPLES, value=int(eval_results[_NUM_EXAMPLES_NAME]))
+  #mllogger.event(key=mllog.constants.EVAL_ACCURACY, value=float(eval_results['accuracy']))
+  mllogger.event(key=mllog.constants.EVAL_ACCURACY, value=float(allreduced_results))
+  mllogger.end(key=mllog.constants.EVAL_STOP)
+  print(F"allreduced_results:{allreduced_results}")
+
+
+  mllogger.event(key=mllog.constants.RUN_STOP, value={"success": success})
+  mllogger.end(key=mllog.constants.RUN_STOP)
+
+
+
+class ResnetArgParser(argparse.ArgumentParser):
+  """Arguments for configuring and running a Resnet Model."""
+
+  def __init__(self, resnet_size_choices=None):
+    super(ResnetArgParser, self).__init__(parents=[
+        parsers.BaseParser(multi_gpu=False),
+        parsers.PerformanceParser(num_parallel_calls=False),
+        parsers.ImageModelParser(),
+        parsers.ExportParser(),
+        parsers.BenchmarkParser(),
+    ])
+
+    self.add_argument(
+        '--version', '-v', type=int, choices=[1, 2],
+        default=resnet_model.DEFAULT_VERSION,
+        help='Version of ResNet. (1 or 2) See README.md for details.'
+    )
+
+    self.add_argument(
+        '--resnet_size', '-rs', type=int, default=50,
+        choices=resnet_size_choices,
+        help='[default: %(default)s] The size of the ResNet model to use.',
+        metavar='<RS>' if resnet_size_choices is None else None
+    )
+
+    self.add_argument(
+        '--use_bfloat16', action='store_true', default=False,
+        help='Whether to use bfloat16 type for computations.'
+    )
+
+    self.add_argument(
+        '--eval_mode', action='store_true', default=False,
+        help='Whether to use eval mode.'
+    )
+
+  def parse_args(self, args=None, namespace=None):
+    args = super(ResnetArgParser, self).parse_args(
+        args=args, namespace=namespace)
+
+    # handle coupling between dtype and loss_scale
+    parsers.parse_dtype_info(args)
+
+    return args
diff --git a/Intel/benchmarks/resnet/2-nodes-16s-8376H-tensorflow/mlperf_resnet/run_and_time.sh b/Intel/benchmarks/resnet/2-nodes-16s-8376H-tensorflow/mlperf_resnet/run_and_time.sh
new file mode 100755
index 0000000..3e205df
--- /dev/null
+++ b/Intel/benchmarks/resnet/2-nodes-16s-8376H-tensorflow/mlperf_resnet/run_and_time.sh
@@ -0,0 +1,23 @@
+#/usr/bin/bash
+
+echo 3 > /proc/sys/vm/drop_caches 
+
+RANDOM_SEED=`date +%s`
+
+QUALITY=0.759
+
+set -e
+
+
+
+export OMP_NUM_THREADS=24
+
+
+export KMP_BLOCKTIME=1
+
+export KMP_AFFINITY="granularity=fine,compact,1,0"
+
+MODEL_DIR="./resnet_imagenet_${RANDOM_SEED}"
+
+
+horovodrun -n 2 HOROVOD_CPU_OPERATIONS=CCL CCL_ATL_TRANSPORT=mpi python imagenet_main.py 1623291220 --data_dir /home/vmagent/app/dataset/resnet/ --model_dir $MODEL_DIR --train_epochs 1 --stop_threshold $QUALITY --batch_size 1632 --version 1 --resnet_size 50 --epochs_between_evals 1 --inter_op_parallelism_threads 2 --intra_op_parallelism_threads 2 --enable_lars --label_smoothing=0.1 --weight_decay=0.00005  2>&1 |tee lars-1epochs_eval_every_0_epochs_global_batch_size_3264_${RANDOM_SEED}.log
diff --git a/Intel/benchmarks/resnet/2-nodes-16s-8376H-tensorflow/mlperf_utils/arg_parsers/parsers.py b/Intel/benchmarks/resnet/2-nodes-16s-8376H-tensorflow/mlperf_utils/arg_parsers/parsers.py
index 4747ceb..9e3c9e0 100644
--- a/Intel/benchmarks/resnet/2-nodes-16s-8376H-tensorflow/mlperf_utils/arg_parsers/parsers.py
+++ b/Intel/benchmarks/resnet/2-nodes-16s-8376H-tensorflow/mlperf_utils/arg_parsers/parsers.py
@@ -111,9 +111,9 @@ class BaseParser(argparse.ArgumentParser):
                train_epochs=True, epochs_between_evals=True,
                stop_threshold=True, batch_size=True,
                multi_gpu=False, num_gpu=True, hooks=True,
-               enable_lars=True, label_smoothing=True, weight_decay=True, fine_tune=True):
+               enable_lars=True, label_smoothing=True, weight_decay=True, 
+               num_filters=True, base_lr=True, momentum=True, fine_tune=True, kernel_size=True):
     super(BaseParser, self).__init__(add_help=add_help)
-
     if data_dir:
       self.add_argument(
           "--data_dir", "-dd", default="/tmp",
@@ -180,6 +180,32 @@ class BaseParser(argparse.ArgumentParser):
          help='[default: %(default)s] Weight decay coefficiant for l2 regularization.',
          metavar="<WD>"
       )
+    
+    if num_filters:
+      self.add_argument(
+         "--num_filters", "-nf", type=int, default=64,
+         help='[default: %(default)s] number filters of convolution layer ',
+         metavar="<NF>"
+      )
+
+    if kernel_size:
+      self.add_argument(
+         "--kernel_size", "-ks", type=int, default=7,
+         help='[default: %(default)s] kernel size of convolution layer ',
+         metavar="<KS>"
+      )
+    if base_lr:
+      self.add_argument(
+         "--base_lr", "-bl", type=float, default=0.128,
+         help='[default: %(default)s] base learning rate ',
+         metavar="<BL>"
+      )
+    if momentum:
+      self.add_argument(
+         "--momentum", "-mm", type=float, default=0.9,
+         help='[default: %(default)s] parameter for optimizer',
+         metavar="<MM>"
+      )
 
     if fine_tune:
       self.add_argument(
diff --git a/Intel/benchmarks/resnet/2-nodes-16s-8376H-tensorflow/post-process.awk b/Intel/benchmarks/resnet/2-nodes-16s-8376H-tensorflow/post-process.awk
old mode 100644
new mode 100755
