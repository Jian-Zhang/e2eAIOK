{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/env/bin/python\n",
    "\n",
    "import init\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import *\n",
    "from pyspark import *\n",
    "import pyspark.sql.functions as f\n",
    "from timeit import default_timer as timer\n",
    "import logging\n",
    "from RecsysSchema import RecsysSchema\n",
    "from pyrecdp.data_processor import *\n",
    "from pyrecdp.utils import *\n",
    "import hashlib\n",
    "\n",
    "def categorifyAllFeatures(df, proc, output_name=\"categorified\", gen_dict=False):\n",
    "    dict_dfs = []\n",
    "    if gen_dict:\n",
    "        # only call below function when target dicts were not pre-prepared\n",
    "        op_multiItems = GenerateDictionary(\n",
    "            ['present_domains', 'present_links', 'hashtags'], doSplit=True)\n",
    "        op_singleItems = GenerateDictionary(['tweet_id', 'language', {'src_cols': [\n",
    "                                            'engaged_with_user_id', 'engaging_user_id'], 'col_name': 'user_id'}])\n",
    "        proc.reset_ops([op_multiItems, op_singleItems])\n",
    "        t1 = timer()\n",
    "        dict_dfs = proc.generate_dicts(df)\n",
    "        t2 = timer()\n",
    "        print(\"Generate Dictionary took %.3f\" % (t2 - t1))\n",
    "    else:\n",
    "        # or we can simply load from pre-gened\n",
    "        dict_names = ['hashtags', 'language', 'present_domains',\n",
    "                      'present_links', 'tweet_id', 'user_id']\n",
    "        dict_dfs = [{'col_name': name, 'dict': proc.spark.read.parquet(\n",
    "            \"%s/%s/%s/%s\" % (proc.path_prefix, proc.current_path, proc.dicts_path, name))} for name in dict_names]\n",
    "\n",
    "    # pre-defined dict\n",
    "    # pre-define\n",
    "    media = {\n",
    "        '': 0,\n",
    "        'GIF': 1,\n",
    "        'GIF_GIF': 2,\n",
    "        'GIF_Photo': 3,\n",
    "        'GIF_Video': 4,\n",
    "        'Photo': 5,\n",
    "        'Photo_GIF': 6,\n",
    "        'Photo_Photo': 7,\n",
    "        'Photo_Video': 8,\n",
    "        'Video': 9,\n",
    "        'Video_GIF': 10,\n",
    "        'Video_Photo': 11,\n",
    "        'Video_Video': 12\n",
    "    }\n",
    "\n",
    "    tweet_type = {'Quote': 0, 'Retweet': 1, 'TopLevel': 2}\n",
    "\n",
    "    media_df = proc.spark.createDataFrame(convert_to_spark_dict(media))\n",
    "    tweet_type_df = proc.spark.createDataFrame(\n",
    "        convert_to_spark_dict(tweet_type))\n",
    "\n",
    "    dict_dfs.append({'col_name': 'present_media', 'dict': media_df})\n",
    "    dict_dfs.append({'col_name': 'tweet_type', 'dict': tweet_type_df})\n",
    "\n",
    "    for i in dict_dfs:\n",
    "        dict_name = i['col_name']\n",
    "        dict_df = i['dict']\n",
    "        print(\"%s has numRows as %d\" % (dict_name, dict_df.count()))\n",
    "\n",
    "    ###### 2. define operations and append them to data processor ######\n",
    "\n",
    "    # 1. define operations\n",
    "    # 1.1 fill na and features\n",
    "    op_fillna_str = FillNA(\n",
    "        ['present_domains', 'present_links', 'hashtags', 'present_media', 'tweet_id'], \"\")\n",
    "    op_fillna_num = FillNA(['reply_timestamp', 'retweet_timestamp',\n",
    "                        'retweet_with_comment_timestamp', 'like_timestamp'], 0)\n",
    "    op_feature_modification_type_convert = FeatureModification(cols=['tweet_timestamp',\n",
    "                                                                     'engaged_with_user_follower_count',\n",
    "                                                                     'engaged_with_user_following_count',\n",
    "                                                                     'engaged_with_user_account_creation',\n",
    "                                                                     'engaging_user_follower_count',\n",
    "                                                                     'engaging_user_following_count',\n",
    "                                                                     'engaging_user_account_creation',\n",
    "                                                                     'reply_timestamp',\n",
    "                                                                     'retweet_timestamp',\n",
    "                                                                     'retweet_with_comment_timestamp',\n",
    "                                                                     'like_timestamp'], op='toInt')\n",
    "    op_feature_add_originals = FeatureAdd(\n",
    "        cols={\"original_present_domains\": \"f.col('present_domains')\",\\\n",
    "              \"original_present_links\": \"f.col('present_links')\",\\\n",
    "              \"original_hashtags\": \"f.col('hashtags')\",\\\n",
    "              \"original_language\": \"f.col('language')\",\\\n",
    "              \"original_tweet_id\": \"f.col('tweet_id')\",\\\n",
    "              \"original_present_media\": \"f.col('present_media')\",\\\n",
    "              \"original_tweet_type\": \"f.col('tweet_type')\",\\\n",
    "              \"original_engaged_with_user_id\": \"f.col('engaged_with_user_id')\",\\\n",
    "              \"original_engaging_user_id\": \"f.col('engaging_user_id')\"\n",
    "             }, \n",
    "        op='inline')\n",
    "    op_feature_modification_present_media_replace = FeatureModification(\n",
    "        cols={'present_media': \"f.concat_ws('_', f.slice(f.split(f.col('present_media'),'\\t'), 1, 2))\"}, op='inline')\n",
    "    op_feature_add_len_hashtags = FeatureAdd(\n",
    "        cols={'len_hashtags': \"f.when(f.col('hashtags') == '', f.lit(0)).otherwise(f.size(f.split(f.col('hashtags'), '\\t')))\"}, op='inline')\n",
    "    op_feature_add_len_domains = FeatureAdd(\n",
    "        cols={'len_domains': \"f.when(f.col('present_domains') == '', f.lit(0)).otherwise(f.size(f.split(f.col('present_domains'), '\\t')))\"}, op='inline')\n",
    "    op_feature_add_len_links = FeatureAdd(\n",
    "        cols={'len_links': \"f.when(f.col('present_links') == '', f.lit(0)).otherwise(f.size(f.split(f.col('present_links'), '\\t')))\"}, op='inline')\n",
    "    op_new_feature_dt_dow = FeatureAdd(cols={\n",
    "        \"dt_dow\": \"f.dayofweek(f.from_unixtime(f.col('tweet_timestamp'))).cast(t.IntegerType())\",\n",
    "        \"dt_hour\": \"f.hour(f.from_unixtime(f.col('tweet_timestamp'))).cast(t.IntegerType())\",\n",
    "        \"dt_minute\": \"f.minute(f.from_unixtime(f.col('tweet_timestamp'))).cast(t.IntegerType())\",\n",
    "        \"dt_second\": \"f.second(f.from_unixtime(f.col('tweet_timestamp'))).cast(t.IntegerType())\"}, op='inline')\n",
    "    op_feature_add_engage_time = FeatureAdd(\n",
    "        cols={'engage_time': \"f.least(f.col('reply_timestamp'), f.col('retweet_timestamp'), f.col('retweet_with_comment_timestamp'), f.col('like_timestamp'))\"}, op='inline')\n",
    "    op_feature_change = FeatureModification(cols={\n",
    "        \"reply_timestamp\": \"f.when(f.col('reply_timestamp') > 0, 1).otherwise(0)\",\n",
    "        \"retweet_timestamp\": \"f.when(f.col('retweet_timestamp') > 0, 1).otherwise(0)\",\n",
    "        \"retweet_with_comment_timestamp\": \"f.when(f.col('retweet_with_comment_timestamp') > 0, 1).otherwise(0)\",\n",
    "        \"like_timestamp\": \"f.when(f.col('like_timestamp') > 0, 1).otherwise(0)\"}, op='inline')\n",
    "    op_fillna_tweet_timestamp = FillNA(['tweet_timestamp'], -1)\n",
    "    \n",
    "    ops = [op_fillna_str, op_fillna_num,\n",
    "           op_feature_modification_type_convert, op_feature_add_originals, \n",
    "           op_feature_modification_present_media_replace,\n",
    "           op_feature_add_len_hashtags, op_feature_add_len_domains, op_feature_add_len_links,\n",
    "           op_new_feature_dt_dow, op_feature_add_engage_time, op_feature_change, op_fillna_tweet_timestamp]\n",
    "    proc.reset_ops(ops)\n",
    "\n",
    "    # 1.3 categorify\n",
    "    # since language dict is small, we may use udf to make partition more even\n",
    "    op_categorify_multi = Categorify(\n",
    "        ['present_domains', 'present_links', 'hashtags'], dict_dfs=dict_dfs, doSplit=True, keepMostFrequent=True)\n",
    "    op_categorify_1 = Categorify(['language', 'present_media', 'tweet_type'], dict_dfs=dict_dfs)\n",
    "    op_fillna_for_categorified = FillNA(['present_domains', 'present_links', 'hashtags', 'language',\n",
    "                                         'present_media', 'tweet_type', ], -1)\n",
    "    ops_1 = [op_categorify_multi, op_categorify_1, op_fillna_for_categorified]\n",
    "    proc.append_ops(ops_1)\n",
    "\n",
    "    t1 = timer()\n",
    "    df = proc.transform(df)\n",
    "    t2 = timer()\n",
    "    print(\"Data Process 1 and udf categorify took %.3f\" % (t2 - t1))\n",
    "    ### process 2\n",
    "    \n",
    "    op_categorify_2 = Categorify([{'engaged_with_user_id': 'user_id'}, {'engaging_user_id': 'user_id'}], dict_dfs=dict_dfs)\n",
    "    op_fillna_for_categorified = FillNA(['engaged_with_user_id', 'engaging_user_id'], -1)\n",
    "    ops = [op_categorify_2, op_fillna_for_categorified]\n",
    "    proc.reset_ops(ops)\n",
    "\n",
    "    t1 = timer()\n",
    "    df = proc.transform(df)\n",
    "    t2 = timer()\n",
    "    print(\"Data Process 2 and udf categorify took %.3f\" % (t2 - t1))\n",
    "    ### process 3\n",
    "    op_categorify_3 = Categorify(['tweet_id'], dict_dfs=dict_dfs)\n",
    "    op_fillna_for_categorified = FillNA(['tweet_id'], -1)\n",
    "    ops = [op_categorify_3, op_fillna_for_categorified]\n",
    "    proc.reset_ops(ops)\n",
    "\n",
    "    t1 = timer()\n",
    "    df = proc.transform(df, output_name)\n",
    "    t2 = timer()    \n",
    "    print(\"Data Process 3 and udf categorify took %.3f\" % (t2 - t1))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def categorifyTweetText(df, proc, output_name=\"tweet_text_categorified\", gen_dict=False):\n",
    "    dict_dfs = []\n",
    "    if gen_dict:\n",
    "        # only call below function when target dicts were not pre-prepared\n",
    "        op_multiItems = GenerateDictionary(\n",
    "            ['tweet'], doSplit=True, withCount=True, sep=' ')\n",
    "        proc.reset_ops([op_multiItems])\n",
    "        ##### transform #####\n",
    "        t1 = timer()\n",
    "        dict_dfs = proc.generate_dicts(df)\n",
    "        t2 = timer()\n",
    "        print(\"Generate Dictionary took %.3f\" % (t2 - t1))\n",
    "    else:\n",
    "        # or we can simply load from pre-gened\n",
    "        name = \"tweet\"\n",
    "        tweet_dict_df = proc.spark.read.parquet(\n",
    "            \"%s/%s/%s/%s\" % (proc.path_prefix, proc.current_path, proc.dicts_path, name))\n",
    "        dict_dfs = [{'col_name': 'tweet', 'dict': tweet_dict_df}]        \n",
    "\n",
    "    tweet_dict_df = dict_dfs[0]['dict']\n",
    "    freqRange = [2, 100000]\n",
    "    tweet_dict_df = tweet_dict_df.filter((f.col('count') <= f.lit(\n",
    "        freqRange[1])) & (f.col('count') >= f.lit(freqRange[0])))\n",
    "    dict_dfs = [{'col_name': 'tweet', 'dict': tweet_dict_df}]\n",
    "    \n",
    "    op_fillNA = FillNA(['tweet'], \"\")\n",
    "    op_rename = FeatureAdd(cols={\"original_tweet\": \"f.col('tweet')\"}, op='inline')\n",
    "    op_categorify = Categorify(['tweet'], dict_dfs=dict_dfs, doSplit=True, sep=' ', doSortForArray=True)\n",
    "    proc.reset_ops([op_fillNA, op_rename, op_categorify])\n",
    "    t1 = timer()\n",
    "    df = proc.transform(df, name=output_name)\n",
    "    t2 = timer()\n",
    "    print(\"Categorify tweet took %.3f\" % (t2 - t1))\n",
    "    return df    \n",
    "\n",
    "\n",
    "def categorifyTweetHash(df, proc, output_name=\"tweet_text_processed\", gen_dict=False):\n",
    "    dict_dfs = []\n",
    "    if gen_dict:\n",
    "        # only call below function when target dicts were not pre-prepared\n",
    "        op_gen_dict = GenerateDictionary(\n",
    "            ['tw_hash','tw_first_word','tw_second_word','tw_last_word','tw_llast_word'])\n",
    "        proc.reset_ops([op_gen_dict])\n",
    "        ##### transform #####\n",
    "        t1 = timer()\n",
    "        dict_dfs = proc.generate_dicts(df)\n",
    "        t2 = timer()\n",
    "        print(\"Generate Dictionary took %.3f\" % (t2 - t1))\n",
    "    else:\n",
    "        # or we can simply load from pre-gened\n",
    "        dict_names = ['tw_hash','tw_first_word',\n",
    "                      'tw_second_word','tw_last_word','tw_llast_word']\n",
    "        dict_dfs = [{'col_name': name, 'dict': proc.spark.read.parquet(\n",
    "            \"%s/%s/%s/%s\" % (proc.path_prefix, proc.current_path, proc.dicts_path, name))} for name in dict_names]\n",
    "    \n",
    "    op_categorify = Categorify(['tw_first_word', 'tw_second_word', 'tw_last_word', 'tw_llast_word', 'tw_hash'], dict_dfs=dict_dfs, saveTmpToDisk=True)\n",
    "    proc.reset_ops([op_categorify])\n",
    "    t1 = timer()\n",
    "    df = proc.transform(df)\n",
    "    t2 = timer()\n",
    "    print(\"Categorify hash features took %.3f\" % (t2 - t1))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def decodeBertTokenizer(df, proc, output_name=\"data_all_with_text\"):\n",
    "    from transformers import BertTokenizer\n",
    "    tokenizer = BertTokenizer.from_pretrained(\n",
    "        'bert-base-multilingual-cased', do_lower_case=False)\n",
    "\n",
    "    # define UDF\n",
    "    tokenizer_decode = f.udf(lambda x: tokenizer.decode(\n",
    "        [int(n) for n in x.split('\\t')]))\n",
    "    format_url = f.udf(lambda x: x.replace(\n",
    "        'https : / / t. co / ', 'https://t.co/').replace('@ ', '@'))\n",
    "\n",
    "    # define operations\n",
    "    op_feature_modification_tokenizer_decode = FeatureAdd(\n",
    "        cols={'tweet': 'text_tokens'}, udfImpl=tokenizer_decode)\n",
    "    op_feature_modification_format_url = FeatureModification(\n",
    "        cols=['tweet'], udfImpl=format_url)\n",
    "\n",
    "    # execute\n",
    "    proc.reset_ops([op_feature_modification_tokenizer_decode,\n",
    "                    op_feature_modification_format_url])\n",
    "    t1 = timer()\n",
    "    df = proc.transform(df, name=output_name)\n",
    "    t2 = timer()\n",
    "    print(\"BertTokenizer decode and format took %.3f\" % (t2 - t1))\n",
    "\n",
    "    return df\n",
    "\n",
    "def tweet_first_last_word(df, proc, output_name=\"data_with_word\"):\n",
    "    t1 = timer()\n",
    "    freqRange = [2, 100000]\n",
    "    name = \"tweet\"\n",
    "    tweet_dict_df = proc.spark.read.parquet(\n",
    "        \"%s/%s/%s/%s\" % (proc.path_prefix, proc.current_path, proc.dicts_path, name))\n",
    "    tweet_dict_df = tweet_dict_df.filter((f.col('count') <= f.lit(\n",
    "        freqRange[1])) & (f.col('count') >= f.lit(freqRange[0])))    \n",
    "    tweet_dict_df.show()\n",
    "    df = df.withColumn('row_id', spk_func.monotonically_increasing_id())\n",
    "    df.write.format('parquet').mode('overwrite').save(\"%s/%s/tmp_valid_with_row_id\" % (proc.path_prefix, proc.current_path))  \n",
    "    df = spark.read.parquet(\"%s/%s/tmp_valid_with_row_id\" % (proc.path_prefix, proc.current_path))\n",
    "    \n",
    "    tmp_df = df.select('row_id', 'tweet')\\\n",
    "               .withColumn('tweet_word', f.explode(f.split(f.col('tweet'), ' ')))\\\n",
    "               .join(tweet_dict_df.withColumnRenamed('dict_col', 'tweet_word').hint('shuffle_hash'), 'tweet_word', 'left')\\\n",
    "               .select('row_id', 'tweet_word', 'count')\n",
    "    tmp_df.write.format('parquet').mode('overwrite').save(\"%s/%s/tmp_valid_joined_tweet_word\" % (proc.path_prefix, proc.current_path))\n",
    "    tmp_df = spark.read.parquet(\"%s/%s/tmp_valid_joined_tweet_word\" % (proc.path_prefix, proc.current_path))\n",
    "    first_word_df = tmp_df\\\n",
    "           .withColumn('max_count', f.max('count').over(Window.partitionBy('row_id')))\\\n",
    "           .where((f.col('count') == f.col('max_count')))\\\n",
    "           .groupby('row_id').agg(f.first('tweet_word').alias('tw_first_word'))\\\n",
    "           .select('row_id', 'tw_first_word')\n",
    "    last_word_df = tmp_df\\\n",
    "           .withColumn('min_count', f.min('count').over(Window.partitionBy('row_id')))\\\n",
    "           .where((f.col('count') == f.col('min_count')))\\\n",
    "           .groupby('row_id').agg(f.last('tweet_word').alias('tw_last_word'))\\\n",
    "           .select('row_id', 'tw_last_word')\n",
    "    df = df.join(first_word_df.hint('shuffle_hash'), 'row_id', 'left')\\\n",
    "           .join(last_word_df.hint('shuffle_hash'), 'row_id', 'left')\\\n",
    "           .drop('row_id')\n",
    "    df.write.format('parquet').mode('overwrite').save(\"%s/%s/%s\" % (proc.path_prefix, proc.current_path, output_name))\n",
    "    \n",
    "    t2 = timer()\n",
    "    print(\"Feature Engineering for tweet text: encoded tweet column took %.3f\" % (t2 - t1))\n",
    "    return df\n",
    "\n",
    "\n",
    "def tweetFeatureEngineer(df, proc, output_name=\"tweet_feature_engineer\"):\n",
    "    \n",
    "    def categorify(x):\n",
    "        dict_list = bc.value\n",
    "        for i in x.split:\n",
    "            dict_list[i]\n",
    "        \n",
    "    \n",
    "    def extract_hash(text, split_text='@', no=0):\n",
    "        text = text.lower()\n",
    "        uhash = ''\n",
    "        text_split = text.split('@')\n",
    "        if len(text_split) > (no+1):\n",
    "            text_split = text_split[no+1].split(' ')\n",
    "            cl_loop = True\n",
    "            uhash += clean_text(text_split[0])\n",
    "            while cl_loop:\n",
    "                if len(text_split) > 1:\n",
    "                    if text_split[1] in ['_']:\n",
    "                        uhash += clean_text(text_split[1]) + \\\n",
    "                            clean_text(text_split[2])\n",
    "                        text_split = text_split[2:]\n",
    "                    else:\n",
    "                        cl_loop = False\n",
    "                else:\n",
    "                    cl_loop = False\n",
    "        hash_object = hashlib.md5(uhash.encode('utf-8'))\n",
    "        return hash_object.hexdigest()\n",
    "\n",
    "    def clean_text(text):\n",
    "        if len(text) > 1:\n",
    "            if text[-1] in ['!', '?', ':', ';', '.', ',']:\n",
    "                return(text[:-1])\n",
    "        return(text)\n",
    "\n",
    "    # features upon tweet\n",
    "    to_notsign = f.udf(lambda x: x.replace('\\[CLS\\] RT @', ''))\n",
    "    count_space = f.udf(lambda x: x.count(' '))\n",
    "    count_text_length = f.udf(lambda x: len(x))\n",
    "    user_defined_hash = f.udf(\n",
    "        lambda x: extract_hash(x, split_text='RT @', no=0))\n",
    "    # features upon tweet_nortsign\n",
    "    count_at = f.udf(lambda x: x.count('@'))\n",
    "    user_define_hash_1 = f.udf(lambda x: extract_hash(x))\n",
    "    user_define_hash_2 = f.udf(lambda x: extract_hash(x, no=1))\n",
    "\n",
    "    # features upon tweet\n",
    "    op_fillna_for_tweet = FillNA(['original_tweet'], \"\")\n",
    "    op_feature_add_tweet_nortsign = FeatureAdd(\n",
    "        cols={'tweet_nortsign': 'original_tweet'}, udfImpl=to_notsign)\n",
    "    op_feature_add_count_words = FeatureAdd(\n",
    "        cols={'count_words': 'original_tweet'}, udfImpl=count_space)\n",
    "    op_feature_add_count_char = FeatureAdd(\n",
    "        cols={'count_char': 'original_tweet'}, udfImpl=count_text_length)\n",
    "    op_feature_add_tw_uhash = FeatureAdd(\n",
    "        cols={'tw_uhash': 'original_tweet'}, udfImpl=user_defined_hash)\n",
    "    op_feature_add_tw_hash = FeatureAdd(\n",
    "        cols={'tw_hash': \"f.hash(f.col('original_tweet'))%1000000000\"}, op='inline')\n",
    "    # features upon tweet_nortsign\n",
    "    op_feature_add_count_at = FeatureAdd(\n",
    "        cols={'count_ats': 'tweet_nortsign'}, udfImpl=count_at)\n",
    "    op_feature_add_tw_uhash0 = FeatureAdd(\n",
    "        cols={'tw_hash0': 'tweet_nortsign'}, udfImpl=user_define_hash_1)\n",
    "    op_feature_add_tw_uhash1 = FeatureAdd(\n",
    "        cols={'tw_hash1': 'tweet_nortsign'}, udfImpl=user_define_hash_2)\n",
    "    op_feature_add_tw_first_word = FeatureAdd(\n",
    "        {'tw_first_word': \"f.col('tweet').getItem(0)\"}, op='inline')\n",
    "    op_feature_add_tw_second_word = FeatureAdd(\n",
    "        {'tw_second_word': \"f.col('tweet').getItem(1)\"}, op='inline')\n",
    "    op_feature_add_tw_last_word = FeatureAdd(\n",
    "        {'tw_last_word': \"f.col('tweet').getItem(f.size(f.col('tweet')) - 1)\"}, op='inline')\n",
    "    op_feature_add_tw_second_last_word = FeatureAdd(\n",
    "        {'tw_llast_word': \"f.col('tweet').getItem(f.size(f.col('tweet')) - 1)\"}, op='inline')\n",
    "    op_feature_add_tw_word_len = FeatureAdd(\n",
    "        {'tw_len': \"f.size(f.col('tweet'))\"}, op='inline')\n",
    "    op_feature_modification_fillna = FillNA(\n",
    "        ['tw_hash', 'tw_first_word', 'tw_second_word', 'tw_last_word', 'tw_llast_word', 'tw_len'], -1)\n",
    "\n",
    "    proc.reset_ops([op_fillna_for_tweet, \n",
    "                    op_feature_add_tweet_nortsign, op_feature_add_count_words, op_feature_add_count_char,\n",
    "                    op_feature_add_tw_uhash, op_feature_add_tw_hash,\n",
    "                    op_feature_add_count_at, op_feature_add_tw_uhash0, op_feature_add_tw_uhash1,\n",
    "                    op_feature_add_tw_first_word, op_feature_add_tw_second_word,\n",
    "                    op_feature_add_tw_last_word, op_feature_add_tw_second_last_word, op_feature_add_tw_word_len,\n",
    "                    op_feature_modification_fillna])\n",
    "    t1 = timer()\n",
    "    df = proc.transform(df, name=output_name)\n",
    "    t2 = timer()\n",
    "    print(\"feature engineering upon Frequency: encoded tweet column took %.3f\" % (t2 - t1))\n",
    "    return df\n",
    "\n",
    "def get_train_data_with_amount_of_days(df, proc, only_train=False, num_of_day = 20, output_name = \"data_splitted_by_day\"):\n",
    "    categorified_with_text_df = df\n",
    "    # categorified_with_text_df.cache()\n",
    "    # 1.1 get timestamp range\n",
    "    import datetime\n",
    "    min_timestamp = categorified_with_text_df.select('tweet_timestamp').agg({'tweet_timestamp': 'min'}).collect()[0]['min(tweet_timestamp)']\n",
    "    max_timestamp = categorified_with_text_df.select('tweet_timestamp').agg({'tweet_timestamp': 'max'}).collect()[0]['max(tweet_timestamp)']\n",
    "    seconds_in_day = 3600 * 24\n",
    "\n",
    "    print(\n",
    "        \"min_timestamp is %s, max_timestamp is %s, %d days max is %s\" % (\n",
    "            datetime.datetime.fromtimestamp(min_timestamp).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            datetime.datetime.fromtimestamp(max_timestamp).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            num_of_day,\n",
    "            datetime.datetime.fromtimestamp(min_timestamp + num_of_day * seconds_in_day).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        ))\n",
    "\n",
    "    if only_train:\n",
    "        min_timestamp += 2 * seconds_in_day\n",
    "        num_of_day -= 4\n",
    "    time_range_split = {\n",
    "        'target': (min_timestamp, seconds_in_day * num_of_day + min_timestamp)\n",
    "    }\n",
    "\n",
    "    print(time_range_split)\n",
    "\n",
    "    # 1.2 save ranged data for train\n",
    "    # filtering out train range data and save\n",
    "    train_start, train_end = time_range_split['target']\n",
    "    df = categorified_with_text_df.filter(\n",
    "        (f.col('tweet_timestamp') >= f.lit(train_start)) & (f.col('tweet_timestamp') < f.lit(train_end)))\n",
    "    output_path = \"%s/%s/%s\" % (proc.path_prefix, proc.current_path, output_name)\n",
    "    df.write.format('parquet').mode('overwrite').save(output_path)\n",
    "    return proc.spark.read.parquet(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+-----+\n",
      "|    dict_col|dict_col_id|count|\n",
      "+------------+-----------+-----+\n",
      "|       Entre|       8960|99977|\n",
      "|        Tudo|       8961|99975|\n",
      "|   positions|       8962|99975|\n",
      "|        وانا|       8963|99974|\n",
      "|       filha|       8964|99965|\n",
      "|      くんが|       8965|99960|\n",
      "|       VLIVE|       8966|99955|\n",
      "|          励|       8967|99950|\n",
      "|      expert|       8968|99919|\n",
      "|       padre|       8969|99901|\n",
      "|       lucha|       8970|99886|\n",
      "|        trio|       8971|99834|\n",
      "|@paulagonzza|       8972|99828|\n",
      "|        far.|       8973|99820|\n",
      "|       Sport|       8974|99810|\n",
      "|    こちらの|       8975|99794|\n",
      "|         ya.|       8976|99776|\n",
      "|          مو|       8977|99776|\n",
      "|          BB|       8978|99768|\n",
      "|        God,|       8979|99753|\n",
      "+------------+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "Feature Engineering for tweet text: encoded tweet column took 75.335\n"
     ]
    }
   ],
   "source": [
    "path_prefix = \"hdfs://\"\n",
    "current_path = \"/recsys2021_0608_processed/sample_0_3/\"\n",
    "original_folder = \"/recsys2021_0608/\"\n",
    "dicts_folder = \"recsys_dicts/\"\n",
    "recsysSchema = RecsysSchema()\n",
    "\n",
    "##### 1. Start spark and initialize data processor #####\n",
    "t0 = timer()\n",
    "spark = SparkSession.builder.master('yarn')\\\n",
    "    .appName(\"Recsys2021_data_process\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "schema = recsysSchema.toStructType()\n",
    "\n",
    "# 1.1 prepare dataFrames\n",
    "# 1.2 create RecDP DataProcessor\n",
    "proc = DataProcessor(spark, path_prefix,\n",
    "                     current_path=current_path, dicts_path=dicts_folder)\n",
    "\n",
    "# ===============================================\n",
    "# basic: Do categorify for all columns for xgboost\n",
    "# df = spark.read.schema(schema).option('sep', '\\x01').csv(path_prefix + original_folder)\n",
    "# df = spark.read.parquet(path_prefix + original_folder)\n",
    "# df = get_train_data_with_amount_of_days(df, proc, 0.5)\n",
    "# df = spark.read.parquet(\"%s/data_splitted_by_0days/\" % current_path)\n",
    "# rename firstly\n",
    "#df = df.withColumnRenamed('enaging_user_following_count', 'engaging_user_following_count')\n",
    "#df = df.withColumnRenamed('enaging_user_is_verified', 'engaging_user_is_verified')\n",
    "#df = categorifyAllFeatures(df, proc, gen_dict=False)\n",
    "#\n",
    "## ===============================================\n",
    "## optional: do bert decode\n",
    "df = spark.read.parquet(\"/recsys2021_0608_processed/sample_0_3/validate_decoded\")\n",
    "#df = decodeBertTokenizer(df, proc, \"validate_decoded\")\n",
    "df = tweet_first_last_word(df, proc, \"validate_decoded_with_word\")\n",
    "#\n",
    "## ===============================================\n",
    "## optional: do tweet text feature engineering\n",
    "## step1: categorify tweet text\n",
    "# df = spark.read.parquet(\"%s/data_all_with_text/\" % current_path)\n",
    "# df = categorifyTweetText(df, proc, gen_dict=False)\n",
    "\n",
    "# step2: add new feature with categorified tweet\n",
    "# df = spark.read.parquet(\"%s/tweet_text_categorified/\" % current_path)\n",
    "# df = tweetFeatureEngineer(df, proc)\n",
    "\n",
    "# step3: categorify tweet hash\n",
    "# df = spark.read.parquet(\"%s/tweet_feature_engineer/\" % current_path)\n",
    "# df = categorifyTweetHash(df, proc, gen_dict=False)\n",
    "# output is tweet_text_processed\n",
    "# ===============================================\n",
    "#df = spark.read.parquet(\"%s/tweet_feature_engineer/\" % current_path)\n",
    "#df = categorifyTweetHash(df, proc, gen_dict=False, output_name=\"verify\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+\n",
      "| tw_first_word|        tw_last_word|\n",
      "+--------------+--------------------+\n",
      "|         الهوى|               رديمٌ|\n",
      "|        チョコ|          いりますか|\n",
      "|        sohbet|                  Eş|\n",
      "|           smh|            Juggalos|\n",
      "|        マスク|          いうがいは|\n",
      "|        めちゃ|              めちゃ|\n",
      "|          Idol|          exploiting|\n",
      "|       Burnley|           Bristol's|\n",
      "|        Bayern|            madreada|\n",
      "|         best!|    accomplishments!|\n",
      "|       ▼グッズ|   キラメキライダー☆|\n",
      "|      adorable|            poupe...|\n",
      "|@ilustracionxs|      @ilustracionxs|\n",
      "|          FORA|          dúvidas...|\n",
      "|           أنه|           @fheeed33|\n",
      "|       visited|                MTHL|\n",
      "|       hubiera|https://t.co/q1ps...|\n",
      "|      れません|        はなちゃんと|\n",
      "|         Heart|              Inhale|\n",
      "|       จริงดิ?|             จริงดิ?|\n",
      "+--------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"/recsys2021_0608_processed/sample_0_3/validate_decoded_with_word\")\n",
    "df.select('tw_first_word', 'tw_last_word').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = \"/recsys2021/1day\"\n",
    "path_prefix = \"hdfs://\"\n",
    "original_folder = \"/recsys2021/decompress\"\n",
    "dicts_folder = \"recsys_dicts/\"\n",
    "recsysSchema = RecsysSchema()\n",
    "\n",
    "##### 1. Start spark and initialize data processor #####\n",
    "t0 = timer()\n",
    "spark = SparkSession.builder.master('yarn')\\\n",
    "    .appName(\"Recsys2021_data_process\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark.read.parquet(\"%s/tweet_feature_engineer/\" % current_path)\n",
    "df.show(1, vertical=True, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " text_tokens                        | 101\t56898\t137\t144\t83260\t12111\t95113\t36742\t78675\t131\t10197\t768\t79991\t10278\t59901\t15909\t16163\t834\t16295\t28384\t32962\t10909\t82397\t13761\t10502\t768\t29255\t825\t26894\t11242\t55038\t829\t35155\t22929\t752\t77111\t78959\t12710\t752\t770\t10564\t11326\t53065\t10502\t752\t31495\t11242\t789\t56779\t19300\t12710\t48881\t31495\t11242\t784\t31902\t10700\t96940\t59901\t11509\t52437\t11242\t100\t102                                                                  \n",
      " hashtags                           | null                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
      " tweet_id                           | 245102C81593340B57EBAF3C4E15144C                                                                                                                                                                                                                                                                                                                                                                                               \n",
      " present_media                      | null                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
      " present_links                      | null                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
      " present_domains                    | null                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
      " tweet_type                         | Retweet                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
      " language                           | 00304D7356D6C64481190D708D8F739C                                                                                                                                                                                                                                                                                                                                                                                               \n",
      " tweet_timestamp                    | 1613574302                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
      " engaged_with_user_id               | 89330C0009F7649762BE34781AA7209F                                                                                                                                                                                                                                                                                                                                                                                               \n",
      " engaged_with_user_follower_count   | 32436                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
      " engaged_with_user_following_count  | 23541                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
      " engaged_with_user_is_verified      | false                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
      " engaged_with_user_account_creation | 1526875125                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
      " engaging_user_id                   | C7077F5459ECBB75C999E2E5AE4AA7EA                                                                                                                                                                                                                                                                                                                                                                                               \n",
      " engaging_user_follower_count       | 38                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
      " enaging_user_following_count       | 119                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
      " enaging_user_is_verified           | false                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
      " engaging_user_account_creation     | 1527441543                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
      " engagee_follows_engager            | false                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
      " reply_timestamp                    | null                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
      " retweet_timestamp                  | null                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
      " retweet_with_comment_timestamp     | null                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
      " like_timestamp                     | 1.613918817E9                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
      " tokens                             | [101, 56898, 137, 144, 83260, 12111, 95113, 36742, 78675, 131, 10197, 768, 79991, 10278, 59901, 15909, 16163, 834, 16295, 28384, 32962, 10909, 82397, 13761, 10502, 768, 29255, 825, 26894, 11242, 55038, 829, 35155, 22929, 752, 77111, 78959, 12710, 752, 770, 10564, 11326, 53065, 10502, 752, 31495, 11242, 789, 56779, 19300, 12710, 48881, 31495, 11242, 784, 31902, 10700, 96940, 59901, 11509, 52437, 11242, 100, 102] \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"/recsys2021_0608\")\n",
    "df.show(1, vertical=True, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------------------------------------------------------------------------------------------------------------------------\n",
      " text_tokens                        | 101\t36448\t13013\t106290\t10104\t23511\t10149\t14243\t10149\t18549\t44861\t69857\t10106\t32942\t102                 \n",
      " hashtags                           | 0                                                                                                      \n",
      " tweet_id                           | 43682316                                                                                               \n",
      " present_media                      | 0                                                                                                      \n",
      " present_links                      | 0                                                                                                      \n",
      " present_domains                    | 0                                                                                                      \n",
      " tweet_type                         | 2                                                                                                      \n",
      " language                           | 3                                                                                                      \n",
      " tweet_timestamp                    | 1613617367                                                                                             \n",
      " engaged_with_user_id               | 1086857                                                                                                \n",
      " engaged_with_user_follower_count   | 42                                                                                                     \n",
      " engaged_with_user_following_count  | 43                                                                                                     \n",
      " engaged_with_user_is_verified      | false                                                                                                  \n",
      " engaged_with_user_account_creation | 1355009906                                                                                             \n",
      " engaging_user_id                   | 1640618                                                                                                \n",
      " engaging_user_follower_count       | 342                                                                                                    \n",
      " engaging_user_following_count      | 385                                                                                                    \n",
      " engaging_user_is_verified          | false                                                                                                  \n",
      " engaging_user_account_creation     | 1559508296                                                                                             \n",
      " engagee_follows_engager            | true                                                                                                   \n",
      " reply_timestamp                    | 0                                                                                                      \n",
      " retweet_timestamp                  | 0                                                                                                      \n",
      " retweet_with_comment_timestamp     | 0                                                                                                      \n",
      " like_timestamp                     | 1                                                                                                      \n",
      " tokens                             | [101, 36448, 13013, 106290, 10104, 23511, 10149, 14243, 10149, 18549, 44861, 69857, 10106, 32942, 102] \n",
      " original_present_domains           |                                                                                                        \n",
      " original_present_links             |                                                                                                        \n",
      " original_hashtags                  |                                                                                                        \n",
      " original_language                  | B8B04128918BBF54E2E178BFF1ABA833                                                                       \n",
      " original_tweet_id                  | A6248C10768FE2447EB8A99105B25AB6                                                                       \n",
      " original_present_media             |                                                                                                        \n",
      " original_tweet_type                | TopLevel                                                                                               \n",
      " original_engaged_with_user_id      | BCE779079C77EDE6B2B9381D096FF4EC                                                                       \n",
      " original_engaging_user_id          | 3A10ECBC54E9CD9E49066676133B5E71                                                                       \n",
      " len_hashtags                       | 0                                                                                                      \n",
      " len_domains                        | 0                                                                                                      \n",
      " len_links                          | 0                                                                                                      \n",
      " dt_dow                             | 5                                                                                                      \n",
      " dt_hour                            | 11                                                                                                     \n",
      " dt_minute                          | 2                                                                                                      \n",
      " dt_second                          | 47                                                                                                     \n",
      " engage_time                        | 0                                                                                                      \n",
      " tweet_nortsign                     | [CLS] Fiuk saiu de filho do rei do sex appeal pra incel [SEP]                                          \n",
      " count_words                        | 12                                                                                                     \n",
      " count_char                         | 61                                                                                                     \n",
      " tw_uhash                           | d41d8cd98f00b204e9800998ecf8427e                                                                       \n",
      " tw_hash                            | 46492048                                                                                               \n",
      " count_ats                          | 0                                                                                                      \n",
      " tw_hash0                           | d41d8cd98f00b204e9800998ecf8427e                                                                       \n",
      " tw_hash1                           | d41d8cd98f00b204e9800998ecf8427e                                                                       \n",
      " tw_first_word                      | 0                                                                                                      \n",
      " tw_second_word                     | 0                                                                                                      \n",
      " tw_last_word                       | 84830                                                                                                  \n",
      " tw_llast_word                      | 84843                                                                                                  \n",
      " tw_len                             | 13                                                                                                     \n",
      " original_tweet                     | [CLS] Fiuk saiu de filho do rei do sex appeal pra incel [SEP]                                          \n",
      " tweet                              | [15180, 23334, 128389]                                                                                 \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"/recsys2021_0608_processed/tweet_text_processed_fixed/\")\n",
    "df.show(1, vertical=True, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional: adding new features upon tweet text\n",
    "categorified_with_text_df = spark.read.parquet(\"/recsys2021/data_all_with_text\")\n",
    "# 1.1 get timestamp range\n",
    "import datetime\n",
    "min_timestamp = categorified_with_text_df.select('tweet_timestamp').agg({'tweet_timestamp': 'min'}).collect()[0]['min(tweet_timestamp)']\n",
    "max_timestamp = categorified_with_text_df.select('tweet_timestamp').agg({'tweet_timestamp': 'max'}).collect()[0]['max(tweet_timestamp)']\n",
    "seconds_in_day = 3600 * 24\n",
    "\n",
    "print(\n",
    "    \"min_timestamp is %s, max_timestamp is %s, 20 days max is %s\" % (\n",
    "        datetime.datetime.fromtimestamp(min_timestamp).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        datetime.datetime.fromtimestamp(max_timestamp).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        datetime.datetime.fromtimestamp(min_timestamp + 20 * seconds_in_day).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    ))\n",
    "\n",
    "time_range_split = {\n",
    "    '20days': (min_timestamp, seconds_in_day * 20 + min_timestamp),\n",
    "    'validate': (min_timestamp, seconds_in_day * 2 + min_timestamp),\n",
    "    'train': (seconds_in_day * 2 + min_timestamp, seconds_in_day * 18 + min_timestamp),\n",
    "    'test': (seconds_in_day * 18 + min_timestamp, seconds_in_day * 20 + min_timestamp)\n",
    "}\n",
    "\n",
    "print(time_range_split)\n",
    "\n",
    "# 1.2 save ranged data for train\n",
    "# filtering out train range data and save\n",
    "train_start, train_end = time_range_split['20days']\n",
    "df = categorified_with_text_df.filter(\n",
    "    (f.col('tweet_timestamp') >= f.lit(train_start)) & (f.col('tweet_timestamp') < f.lit(train_end)))\n",
    "df.cache()\n",
    "train_data_processed = \"/recsys2021/1day/processed_for_20days\"\n",
    "df.write.format('parquet').mode('overwrite').save(path_prefix + train_data_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_names = ['hashtags', 'language', 'present_domains','present_links', 'tweet_id', 'user_id', 'tweet']\n",
    "dict_dfs = [{'col_name': name, 'dict': spark.read.parquet(\"%s/recsys2021/recsys_dicts/%s\" % (path_prefix, name))} for name in dict_names]\n",
    "for i in dict_dfs:\n",
    "    dict_name = i['col_name']\n",
    "    dict_df = i['dict']\n",
    "    print(\"%s has numRows as %d, maximun is %d\" % (dict_name, dict_df.count(), dict_df.agg({'dict_col_id': \"max\"}).collect()[0]['max(dict_col_id)']))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
