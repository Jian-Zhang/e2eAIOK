diff --git a/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/.bazelrc b/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/.bazelrc
new file mode 100644
index 0000000..e544eb5
--- /dev/null
+++ b/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/.bazelrc
@@ -0,0 +1,11 @@
+build --define=tf=1
+test -c dbg
+
+# Some of the Bazel rules used to precompile TensorFlow don't respect Bazel's
+# "manual" tag. The following hack prevents Bazel from compiling TensorFlow
+# from source when executing a command such as: bazel test cc/...
+test //cc/... -- -//cc/tensorflow/...
+
+# These .bazelrc files are generated by the cc/configure_tensorflow.sh script.
+try-import %workspace%/tf_configure.bazelrc
+try-import %workspace%/tensorflow.bazelrc
diff --git a/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/README.md b/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/README.md
index f1b8a64..3d6eaca 100644
--- a/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/README.md
+++ b/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/README.md
@@ -1,3 +1,19 @@
-### Please read ml_perf/README.md for running the benchmark ###
-This code is adapted from MLPerf reference SW at https://github.com/mlcommons/training/tree/master/reinforcement/tensorflow/minigo/cc
+## For baremetal env build from scratch, please read ml_perf/README.md ###
+## If you have already finished building env and just want to run minigo again, please follow below instructions ###
+### 
+```
+source /opt/intel/oneapi/setvars.sh
+# export gcc8.4.0 to PATH and LD_LIBRARY_PATH if not exported
+export PATH=path/to/gcc8.4.0/bin:$PATH
+export LD_LIBRARY_PATH=/usr/local/gcc-8.4.0/lib64/${LD_LIBRARY_PATH:+:$LD_LIBRARY_PATH}
+conda activate minigo_xeon_opt
 
+# for quickly do performance validate, you can build env more quickly
+copy the ml_perf/checkpoints, ml_perf/target dirs, and run ./cc/configure_tensorflow.sh (build options are all defaults) with bazel-0.24.1
+
+# Please confirm that your passwordless ssh is started before running minigo
+# Launch the following command to run the minigo workload
+# hostlist=node0,node1...nodeN
+# rootnode=node0
+HOSTLIST=hostlist ROOTNODE=rootnode ml_perf/scripts/run_minigo.sh 19
+```
diff --git a/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/build_gcc.sh b/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/build_gcc.sh
new file mode 100755
index 0000000..04ba5d7
--- /dev/null
+++ b/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/build_gcc.sh
@@ -0,0 +1,28 @@
+#!/bin/bash
+
+export http_proxy="http://proxy-prc.intel.com:912"
+export https_proxy="http://proxy-prc.intel.com:912"
+export ftp_proxy="http://proxy-prc.intel.com:912"
+
+[ -d "$HOME/src/" ] || mkdir "$HOME/src/"
+GCC_VERSION="8.4.0"
+WORKDIR="$HOME/src/"
+INSTALLDIR="/usr/local/gcc-8.4.0"
+
+cd $WORKDIR
+wget https://github.com/gcc-mirror/gcc/archive/refs/tags/releases/gcc-${GCC_VERSION}.tar.gz
+tar -zxvf gcc-${GCC_VERSION}.tar.gz
+
+cd gcc-releases-gcc-${GCC_VERSION}
+./contrib/download_prerequisites
+
+cd ..
+mkdir gcc-build
+cd gcc-build
+
+../gcc-releases-gcc-${GCC_VERSION}/configure -v --build=x86_64-linux-gnu \
+    --host=x86_64-linux-gnu --target=x86_64-linux-gnu       \
+    --prefix=${INSTALLDIR} --enable-checking=release        \
+    --enable-languages=c,c++ --disable-multilib             \
+&& make -j$(nproc) \
+&& make install
diff --git a/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/cc/.clang-format b/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/cc/.clang-format
new file mode 100644
index 0000000..ca542bf
--- /dev/null
+++ b/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/cc/.clang-format
@@ -0,0 +1,5 @@
+BasedOnStyle: Google
+
+Cpp11BracedListStyle: true
+DerivePointerAlignment: false
+PointerAlignment: Left
diff --git a/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/cluster/common.sh b/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/cluster/common.sh
old mode 100644
new mode 100755
diff --git a/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/cluster/ringmaster/ringmaster_wrapper.sh b/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/cluster/ringmaster/ringmaster_wrapper.sh
old mode 100644
new mode 100755
diff --git a/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/cluster/unset-common.sh b/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/cluster/unset-common.sh
old mode 100644
new mode 100755
diff --git a/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/cluster/utils.sh b/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/cluster/utils.sh
old mode 100644
new mode 100755
diff --git a/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/freeze_graph.sh b/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/freeze_graph.sh
old mode 100644
new mode 100755
diff --git a/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/minigui/edgetpu/install_requirements.sh b/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/minigui/edgetpu/install_requirements.sh
old mode 100644
new mode 100755
diff --git a/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/minigui/edgetpu/start_chromium.sh b/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/minigui/edgetpu/start_chromium.sh
old mode 100644
new mode 100755
diff --git a/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/minigui/minigui-common.sh b/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/minigui/minigui-common.sh
old mode 100644
new mode 100755
diff --git a/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/minigui/unset-minigui-common.sh b/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/minigui/unset-minigui-common.sh
old mode 100644
new mode 100755
diff --git a/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/ml_perf/README.md b/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/ml_perf/README.md
index f089e5e..0dc31c8 100644
--- a/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/ml_perf/README.md
+++ b/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/ml_perf/README.md
@@ -1,39 +1,57 @@
-# MLPerf Training v1.0 Intel Submission
+# Preliminary
+This repo is a staging ground for the new [MLPerf](http://mlperf.org) reinforcement model.
+Eventually this code will replace the code in
+[this directory](http://github.com/mlperf/training/tree/master/reinforcement/tensorflow/minigo).
 
 # 1. Problem
 This task benchmarks on policy reinforcement learning for the 19x19 version of the boardgame Go.
 The model plays games against itself and uses these games to improve play.
 
 # 2. Directions
-### Steps to run MiniGo
+### Steps to configure machine
+Tested OS: Ubuntu18.04LTS, CentOS7.9
 
 ```
-    # Set WORKSPACE as /path/to/Intel/benchmarks/minigo/<system_desc_id>
-    cd <WORKSPACE>
-
-    # Install dependencies
-    apt-get install -y python3 python3-pip rsync git wget pkg-config zip g++ zlib1g-dev unzip
-
-    # Install Intel MPI 2018.1.163
-    # Refer to the following commands to configure Intel MPI
-    source /path/to/compilers_and_libraries/linux/bin/compilervars.sh intel64
-    source /path/to/compilers_and_libraries/linux/mpi/intel64/bin/mpivars.sh intel64
+    # Install dependencies (for Ubuntu18.04LTS)
+    apt-get install -y python3 python3-pip rsync git wget pkg-config zip g++ zlib1g-dev unzip numactl flex
+    # Install dependencies (for CentOS7.9)
+    yum install zip unzip rsync git wget curl numactl flex zlib-devel pkgconfig gcc-c++ patch bison patchelf
+    
+    # (Ubuntu18.04LTS) change sh default program from dash to bash
+    dpkg-reconfigure dash
+    
+    # Install GCloud dev suite (For Ubuntu18.04LTS, follow deb install guide; For CentOS7.9, follow rpm install guide)
+    https://cloud.google.com/sdk/docs/install#deb
+    https://cloud.google.com/sdk/docs/install#rpm
+    
+    # Install Anaconda
+    
+    # Install Intel oneAPI HPC toolkit
+    source /opt/intel/oneapi/setvars.sh
 
     # Install GCC 8.4.0
     # Refer to the following commands to configure GCC
     export PATH=path/to/gcc8.4.0/bin:$PATH
     export LD_LIBRARY_PATH=path/to/gcc8.4.0/lib64/:$LD_LIBRARY_PATH
 
-    # download mlperf logging package
-    git clone https://github.com/mlperf/logging.git mlperf-logging
-    pip install -e mlperf-logging
+    # Clone repository
+    cd <WORKSPACE>
+    git clone https://github.com/intel-innersource/frameworks.bigdata.bluewhale.git aidk
+
+    cd aidk/modelzoo/minigo
 
     # Install anaconda and create an anaconda env (this step is optional but highly recommended).
     conda create -n minigo_xeon_opt python=3.6
     conda activate minigo_xeon_opt
+    # Also, noted that if your system glibc version < 2.27 (such as CentOS7.9)
+    # you need to build glibc from source and install it, and then use patchelf to patch your conda env python binaries
+    # patchelf --set-interpreter /usr/local/glibc-2.27/lib/ld-linux-x86-64.so.2 --set-rpath /usr/local/glibc-2.27/lib/ /usr/local/anaconda3/envs/minigo_xeon_opt/bin/python
+    
+    # Install mlperf-logging
+    pip install "git+https://github.com/mlperf/logging.git@1.0.0"
 
     # Install Python dependencies
-    pip3 install -r requirements.txt
+    pip install -r requirements.txt
 
     # Download & extract bootstrap checkpoint
     gsutil cp gs://minigo-pub/ml_perf/0.7/checkpoint.tar.gz .
@@ -49,16 +67,14 @@ The model plays games against itself and uses these games to improve play.
     BAZEL_VERSION=3.0.0
     wget https://github.com/bazelbuild/bazel/releases/download/${BAZEL_VERSION}/bazel-${BAZEL_VERSION}-installer-linux-x86_64.sh
     chmod 755 bazel-${BAZEL_VERSION}-installer-linux-x86_64.sh
-    sh ./bazel-${BAZEL_VERSION}-installer-linux-x86_64.sh --user
+    ./bazel-${BAZEL_VERSION}-installer-linux-x86_64.sh
 
     # Build and install specified Intel-Tensorflow
-    # NOTE: Requires numpy version < 1.19.0 (verified with 1.18.5)
-    cd <WORKSPACE>
     git clone https://github.com/Intel-tensorflow/tensorflow.git
     cd tensorflow
     git checkout 896a070312136fe944fd7a905e72f86dee9771f6
     # Apply compatibility patch for tensorflow-io
-    git apply <WORKSPACE>/patches/compat.patch
+    git apply <WORKSPACE>/aidk/modelzoo/minigo/patches/compat.patch
     # Use all defaults
     ./configure
     bazel build --cxxopt=-D_GLIBCXX_USE_CXX11_ABI=0 --copt=-O3 --copt=-Wformat \
@@ -70,20 +86,20 @@ The model plays games against itself and uses these games to improve play.
     bazel-bin/tensorflow/tools/pip_package/build_pip_package ./tensorflow_pkg/
     pip install ./tensorflow_pkg/tensorflow-2.2.0-cp36-cp36m-linux_x86_64.whl
 
-    cd <WORKSPACE>
-
     # Install Tensorflow-io
-    pip3 install "tensorflow-io==0.13.0" --no-deps
+    pip install "tensorflow-io==0.13.0" --no-deps
 
     # Install horovod
     # Note, please ensure that Intel MPI and GCC have been configured correctly before compling horovod
     pip --no-cache-dir install horovod==0.19.1
 
+    cd <WORKSPACE>/aidk/modelzoo/minigo
+    
     # Install bazel 0.24.1
     BAZEL_VERSION=0.24.1
     wget https://github.com/bazelbuild/bazel/releases/download/${BAZEL_VERSION}/bazel-${BAZEL_VERSION}-installer-linux-x86_64.sh
     chmod 755 bazel-${BAZEL_VERSION}-installer-linux-x86_64.sh
-    sh ./bazel-${BAZEL_VERSION}-installer-linux-x86_64.sh --user
+    ./bazel-${BAZEL_VERSION}-installer-linux-x86_64.sh
 
     # Compile TensorFlow C++ libraries (enter to use default config)
     ./cc/configure_tensorflow.sh
@@ -106,11 +122,10 @@ The model plays games against itself and uses these games to improve play.
     # Running the benchmark creates two log files in <WORKSPACE>: train.log and eval.stdout
     # train.log captures MLPerf logging events, and eval.stdout contains std output from ml_perf/eval_models.py
     # Correct logging errors for compliance
-    python postprocessing.py --in-file train.log --out-file train_postprocess.log
+    python postprocess.py --in-file train.log --out-file train_postprocess.log
     # Update run_stop timestamp using the TTT from eval.stdout, and save as result.txt
     ./logging_postprocess.sh train_postprocess.log eval.stdout result.txt
 
-
     # Run MLPerf logging compliance checker
     python -m mlperf_logging.compliance_checker --config 0.7.0/closed_minigo.yaml --ruleset 0.7.0 result.txt
 ```
diff --git a/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/ml_perf/flags/19/train_loop.flags b/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/ml_perf/flags/19/train_loop.flags
index d469db9..90dddf1 100644
--- a/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/ml_perf/flags/19/train_loop.flags
+++ b/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/ml_perf/flags/19/train_loop.flags
@@ -1,4 +1,4 @@
---iterations=70
+--iterations=98
 
 --window_size=5
 --train_filter=0.3
@@ -9,3 +9,4 @@
 --min_games_per_iteration=8192
 
 --use_bfloat16=true
+--winrate=0.5
diff --git a/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/ml_perf/scripts/cc_libgen_parallel_selfplay.sh b/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/ml_perf/scripts/cc_libgen_parallel_selfplay.sh
new file mode 100755
index 0000000..b8840e0
--- /dev/null
+++ b/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/ml_perf/scripts/cc_libgen_parallel_selfplay.sh
@@ -0,0 +1,8 @@
+#!/bin/bash
+source ml_perf/scripts/common.sh
+echo `hostname`
+bazel build $BAZEL_OPTS \
+    --copt=-O3 \
+    --define=board_size="${board_size}" \
+    --define=tf=1 \
+    cc:concurrent_selfplay cc:sample_records cc:eval
\ No newline at end of file
diff --git a/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/ml_perf/scripts/clean.sh b/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/ml_perf/scripts/clean.sh
index b4db879..ddb3533 100755
--- a/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/ml_perf/scripts/clean.sh
+++ b/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/ml_perf/scripts/clean.sh
@@ -10,6 +10,7 @@ if [[ -v HOSTLIST ]]; then
         ${golden_chunk_tmp_dir} \
         ${selfplay_local_dir}   \
         ${local_signal_dir}
+    mpirun -bootstrap ssh -ppn 1 -hosts $ROOTNODE rm -r $selfplay_master_dir
 else
     sh ml_perf/scripts/rm_tmp_dir.sh \
         ${golden_chunk_local_dir}     \
diff --git a/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/ml_perf/scripts/common.sh b/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/ml_perf/scripts/common.sh
index 523a705..bbee33a 100755
--- a/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/ml_perf/scripts/common.sh
+++ b/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/ml_perf/scripts/common.sh
@@ -27,6 +27,7 @@ while getopts “-:” opt; do
   esac
 done
 
+base_dir=$HOME/mlperf/results-19
 # Assign default values to unset command line arguments.
 if [ -z "${board_size-}" ]; then board_size="19"; fi
 if [ -z "${flag_dir-}" ]; then flag_dir="${base_dir}/flags"; fi
@@ -40,11 +41,11 @@ if [ -z "${golden_chunk_tmp_dir-}" ]
   then golden_chunk_tmp_dir="/tmp/golden_chunks_tmp"
 fi
 if [ -z "${holdout_dir-}" ]; then holdout_dir="${base_dir}/data/holdout"; fi
-if [ -z "${log_dir-}" ]; then log_dir="${base_dir}/logs"; fi
+log_dir="${base_dir}/logs"
 if [ -z "${model_dir-}" ]; then model_dir="${base_dir}/models"; fi
 if [ -z "${selfplay_dir-}" ]; then selfplay_dir="${base_dir}/data/selfplay"; fi
 if [ -z "${sgf_dir-}" ]; then sgf_dir="${base_dir}/sgf"; fi
-if [ -z "${work_dir-}" ]; then work_dir="${base_dir}/work_dir"; fi
+work_dir="${base_dir}/work_dir"
 if [ -z "${window_size-}" ]; then window_size="5"; fi
 if [ -z "${tpu_name-}" ]; then tpu_name=""; fi
 
@@ -76,8 +77,11 @@ function clean_dir {
     gsutil -m rm -rf "${dir}"/*
     set -e
   else
-    mkdir -p "${dir}"
-    rm -rf "${dir}"/*
+    # check whether dir is permitted work path
+    if [[ ${dir} = $HOME/mlperf/* ]] || [[ ${dir} = /tmp/* ]]; then
+      mkdir -p "${dir}"
+      rm -rf "${dir}"/*
+    fi
   fi
 }
 
diff --git a/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/ml_perf/scripts/init_from_checkpoint.sh b/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/ml_perf/scripts/init_from_checkpoint.sh
index e89c6de..89f09cb 100755
--- a/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/ml_perf/scripts/init_from_checkpoint.sh
+++ b/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/ml_perf/scripts/init_from_checkpoint.sh
@@ -25,12 +25,11 @@
 source ml_perf/scripts/common.sh
 
 
-# Build the C++ binaries
-bazel build $BAZEL_OPTS \
-  --copt=-O3 \
-  --define=board_size="${board_size}" \
-  --define=tf=1 \
-  cc:concurrent_selfplay cc:sample_records cc:eval
+if [[ -v HOSTLIST ]]
+then
+  # Generate cc parallel lib
+  mpirun -bootstrap ssh -ppn 1 -hosts $HOSTLIST ml_perf/scripts/cc_libgen_parallel_selfplay.sh --base_dir=$base_dir --board_size=$board_size 2>&1 >/dev/null
+fi
 
 # Initialize a clean directory structure.
 for var_name in flag_dir golden_chunk_dir golden_chunk_tmp_dir holdout_dir \
diff --git a/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/ml_perf/scripts/run_minigo.sh b/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/ml_perf/scripts/run_minigo.sh
index 9d841aa..33fedd5 100755
--- a/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/ml_perf/scripts/run_minigo.sh
+++ b/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/ml_perf/scripts/run_minigo.sh
@@ -5,6 +5,8 @@ timestamp=$(date +%s)
 timestamp=$((timestamp * 1000))
 echo ":::MLLOG {\"namespace\": \"\", \"time_ms\": $timestamp, \"event_type\": \"INTERVAL_START\", \"key\": \"init_start\", \"value\": true, \"metadata\": {\"file\": \"run_minigo.sh\", \"lineno\": 6}}" >> train.log
 
+checkpoint_dir="${checkpoint_dir:=ml_perf/checkpoints/mlperf07}"
+target="${target:=ml_perf/target/target.minigo}"
 
 # Bootstrap the training loop from the checkpoint.
 # This step also builds the required C++ binaries.
@@ -12,7 +14,10 @@ echo ":::MLLOG {\"namespace\": \"\", \"time_ms\": $timestamp, \"event_type\": \"
 ./ml_perf/scripts/init_from_checkpoint.sh \
     --board_size=$1 \
     --base_dir=$BASE_DIR \
-    --checkpoint_dir=ml_perf/checkpoints/mlperf07
+    --checkpoint_dir=$checkpoint_dir
+
+# Sync parallel selfplay
+./ml_perf/scripts/start_parallel_selfplay_sync.sh --base_dir=$BASE_DIR 2>&1 > /dev/null &
 
 # launch all selfplay and standby
 ./ml_perf/scripts/run_mlperf_selfplay.sh $1
@@ -29,10 +34,11 @@ echo ":::MLLOG {\"namespace\": \"\", \"time_ms\": $timestamp, \"event_type\": \"
 ./ml_perf/scripts/train.sh \
      --board_size=$1 \
      --precision=$2 \
-     --base_dir=$BASE_DIR
+     --base_dir=$BASE_DIR \
+     --target=$target
 
 # evaluation
-./ml_perf/scripts/run_mlperf_eval.sh $1  2>&1 | tee eval.stdout
+./ml_perf/scripts/run_mlperf_eval.sh $1 --target=$target 2>&1 | tee eval.stdout
 
 # Clean up temporary directories
 ./ml_perf/scripts/clean.sh $1
diff --git a/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/ml_perf/scripts/run_mlperf_eval.sh b/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/ml_perf/scripts/run_mlperf_eval.sh
index d91b309..8872283 100755
--- a/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/ml_perf/scripts/run_mlperf_eval.sh
+++ b/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/ml_perf/scripts/run_mlperf_eval.sh
@@ -23,5 +23,5 @@ python3 ml_perf/eval_models.py \
      --start=50 \
      --flags_dir=ml_perf/flags/$1 \
      --model_dir=$BASE_DIR/models/ \
-     --target=ml_perf/target/target.minigo \
+     --target=$target \
      --devices=`seq -s, 0 $LAST_PHY_CORE`
diff --git a/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/ml_perf/scripts/start_parallel_selfplay_sync.sh b/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/ml_perf/scripts/start_parallel_selfplay_sync.sh
new file mode 100755
index 0000000..53a5c78
--- /dev/null
+++ b/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/ml_perf/scripts/start_parallel_selfplay_sync.sh
@@ -0,0 +1,15 @@
+#!/bin/bash
+echo $BASE_DIR
+source ml_perf/scripts/common.sh
+
+ABORT_FILE=${abort_file} \
+
+IFS=','
+for NODE in $HOSTLIST; do 
+  if [ $NODE != $ROOTNODE ]; then
+    ml_perf/scripts/loop.sh rsync -r --append --delete-before /root/mlperf/results-19/flags root@$NODE:/root/mlperf/results-19/ 2>&1 > /dev/null &
+    ml_perf/scripts/loop.sh rsync -r --append --delete-before /root/mlperf/results-19/signal root@$NODE:/root/mlperf/results-19/ 2>&1 > /dev/null &
+    ml_perf/scripts/loop.sh rsync -r --append --delete-before /root/mlperf/results-19/models root@$NODE:/root/mlperf/results-19/ 2>&1 > /dev/null &
+  fi
+done
+
diff --git a/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/ml_perf/scripts/train.sh b/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/ml_perf/scripts/train.sh
index 6a01380..99bd145 100755
--- a/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/ml_perf/scripts/train.sh
+++ b/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/ml_perf/scripts/train.sh
@@ -45,6 +45,10 @@ if [[ -v HOSTLIST ]]; then
   echo "Physical cores = $PHY_CORES"
   echo "Virtual cores = $VIRT_CORES"
   echo "Cores per NUMA = $NUMA_CORES"
+
+  LAST_PHY_CORE=$(expr $PHY_CORES - 1)
+  echo "Evaluation Last physical core = $LAST_PHY_CORE"
+
   BOARD_SIZE="${board_size}" \
   CUDA_VISIBLE_DEVICES="0" \
   python3 ml_perf/train_loop.py \
@@ -67,6 +71,8 @@ if [[ -v HOSTLIST ]]; then
     --physical_cores=$PHY_CORES \
     --virtual_cores=$VIRT_CORES \
     --numa_cores=$NUMA_CORES \
+    --devices=`seq -s, 0 $LAST_PHY_CORE` \
+    --target=$target \
     2>&1 | tee "${log_dir}/train_loop.log"
 else
   echo "Run single node training."
@@ -75,6 +81,10 @@ else
   echo "Physical cores = $PHY_CORES"
   echo "Virtual cores = $VIRT_CORES"
   echo "Cores per NUMA = $NUMA_CORES"
+
+  LAST_PHY_CORE=$(expr $PHY_CORES - 1)
+  echo "Evaluation Last physical core = $LAST_PHY_CORE"
+
   python3 ml_perf/train_loop.py \
     --flags_dir="${flag_dir}" \
     --golden_chunk_dir="${golden_chunk_dir}" \
@@ -93,5 +103,7 @@ else
     --physical_cores=$PHY_CORES \
     --virtual_cores=$VIRT_CORES \
     --numa_cores=$NUMA_CORES \
+    --devices=`seq -s, 0 $LAST_PHY_CORE` \
+    --target=$target \
     2>&1 | tee "${log_dir}/train_loop.log"
 fi
diff --git a/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/ml_perf/train_loop.py b/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/ml_perf/train_loop.py
index 42fcee3..25c3822 100644
--- a/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/ml_perf/train_loop.py
+++ b/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/ml_perf/train_loop.py
@@ -82,16 +82,23 @@ flags.DEFINE_integer('numa_cores', None, 'The number of core for each numa '
 flags.DEFINE_integer('train_instance_per_numa', 1, 'The number of instance for '
                      'each numa node.')
 flags.DEFINE_integer('gradient_accumulation_steps', 1, 'Number of steps for gradient accumulation')
-
+'''minigo model evaluation related flags'''
+flags.DEFINE_list('devices', '', 'List of devices to run on.')
+flags.DEFINE_string('target', '', 'Path of the target model.')
+flags.DEFINE_string('sgf_dir', '', 'Directory to write SGFs to.')
+flags.DEFINE_integer('num_games', 256, 'Number of games to run.')
+flags.DEFINE_float('winrate', 0.5,
+                   'Fraction of games that a model must beat the target by.')
 FLAGS = flags.FLAGS
 
 
 # Training loop state.
 class State:
-    def __init__(self, model_num):
+    def __init__(self, model_num, win_rate):
         self.start_time = time.time()
         self.start_iter_num = model_num
         self.iter_num = model_num
+        self.win_rate = win_rate
 
     def _model_name(self, it):
         return '%06d' % it
@@ -404,9 +411,97 @@ def post_train(state):
          '--input_graph={}'.format(selfplay_pb),
          '--dst={}'.format(dst_minigo_file)]))
 
+    logging.info('started evaluation minigo model for iter %s of total %s, last iter winrate is %s', state.iter_num, FLAGS.iterations, state.win_rate)
+    minigo_model_path=f"/root/mlperf/results-19/models/0000{state.iter_num}.minigo"
+    state.win_rate=evaluate_model(minigo_model_path)
+    logging.info('finished evaluation minigo model for iter %s, winrate is %s', state.iter_num, state.win_rate)
+    if state.win_rate >= FLAGS.winrate:
+        logging.info('we have found minigo model better than target!!! iter %s winrate %s', state.iter_num, state.win_rate)
+        metric_file = open("../../../../../../../result/metric.txt", "wt")
+        n = metric_file.write(str(state.win_rate))
+        metric_file.close()
     #resume selfplay
     os.remove(FLAGS.pause)
 
+
+def evaluate_model(eval_model_path):
+    processes = []
+    for i, device in enumerate(FLAGS.devices):
+        a = i * FLAGS.num_games // len(FLAGS.devices)
+        b = (i + 1) * FLAGS.num_games // len(FLAGS.devices)
+        num_games = b - a;
+        
+        env = os.environ.copy()
+        env['CUDA_VISIBLE_DEVICES'] = device
+        processes.append(checked_run([
+            'numactl',
+            '--physcpubind={}'.format(i),
+            'bazel-bin/cc/eval',
+            '--flagfile={}'.format(os.path.join(FLAGS.flags_dir, 'eval.flags')),
+            '--eval_model={}'.format(eval_model_path),
+            '--target_model={}'.format(FLAGS.target),
+            '--sgf_dir={}'.format(FLAGS.sgf_dir),
+            '--parallel_games={}'.format(num_games),
+            '--eval_device=cpu',
+            '--target_device=cpu',
+            '--verbose=false'], env, False))
+    all_output = wait(processes)
+
+    total_wins = 0
+    total_num_games = 0
+    for output in all_output:
+        lines = output.split('\n')
+
+        eval_stats, target_stats = parse_win_stats_table(lines[-7:])
+        num_games = eval_stats.total_wins + target_stats.total_wins
+        total_wins += eval_stats.total_wins
+        total_num_games += num_games
+
+    win_rate = total_wins / total_num_games
+    logging.info('Win rate %s vs %s: %.3f', eval_stats.model_name,
+                 target_stats.model_name, win_rate)
+    
+    return win_rate
+
+def parse_win_stats_table(lines):
+    result = []
+    while True:
+        # Find the start of the win stats table.
+        assert len(lines) > 1
+        if 'Black' in lines[0] and 'White' in lines[0] and 'passes' in lines[1]:
+            break
+        lines = lines[1:]
+
+    # Parse the expected number of lines from the table.
+    for line in lines[2:4]:
+        result.append(WinStats(line))
+
+    return result
+
+class WinStats:
+    """Win-rate stats for a single model."""
+
+    def __init__(self, line):
+        pattern = '\s*(\S+)' + '\s+(\d+)' * 6
+        match = re.search(pattern, line)
+        if match is None:
+            raise ValueError('Can\t parse line "{}"'.format(line))
+        self.model_name = match.group(1)
+        raw_stats = [float(x) for x in match.groups()[1:]]
+        self.black_wins = ColorWinStats(*raw_stats[:3])
+        self.white_wins = ColorWinStats(*raw_stats[3:])
+        self.total_wins = self.black_wins.total + self.white_wins.total
+
+class ColorWinStats:
+    """Win-rate stats for a single model & color."""
+    def __init__(self, total, both_passed, opponent_resigned):
+        self.total = total
+        self.both_passed = both_passed
+        self.opponent_resigned = opponent_resigned
+        # Verify that the total is correct
+        assert total == both_passed + opponent_resigned
+
+
 def main(unused_argv):
     """Run the reinforcement learning loop."""
     logger = logging.getLogger()
@@ -452,7 +547,7 @@ def main(unused_argv):
     mllogger.start(key=mllog.constants.RUN_START)
     with logged_timer('Total time'):
         try:
-            state = State(model_num)
+            state = State(model_num,0)
             wait(checked_run([
                 'python3', 'parse_flags_train.py',
                 '--flagfile={}'.format(os.path.join(FLAGS.flags_dir, 'train.flags'))
@@ -464,7 +559,7 @@ def main(unused_argv):
 
             mllogger.event(key="window_size", value=FLAGS.window_size)
 
-            while state.iter_num <= FLAGS.iterations:
+            while (state.iter_num <= FLAGS.iterations) and (state.win_rate < FLAGS.winrate):
                 mllogger.event(
                     key=mllog.constants.EPOCH_START,
                     value=None,
diff --git a/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/requirements.txt b/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/requirements.txt
index f7b1409..9eb4a35 100644
--- a/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/requirements.txt
+++ b/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/requirements.txt
@@ -5,7 +5,7 @@ google.cloud.logging
 google.cloud.bigtable
 grpcio-tools
 keras
-numpy>=1.14.0
+numpy==1.18.5
 protobuf
 sgf==0.5
 six
diff --git a/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/testing/bootstrap_v2.sh b/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/testing/bootstrap_v2.sh
old mode 100644
new mode 100755
