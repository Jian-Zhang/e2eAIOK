{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import logging\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from datetime import datetime\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "import pyspark.sql.types as T\n",
    "from pyspark import SparkConf\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from horovod.spark.common.backend import SparkBackend \n",
    "\n",
    "\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "import horovod.spark.torch as hvd\n",
    "from horovod.spark.common.store import Store\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#conf = SparkConf().setAppName('pytorch_spark_mnist').setMaster('yarn').set('spark.sql.shuffle.partitions', '16').set('spark.task.cpus', '10')\n",
    "conf = SparkConf().setAppName('pytorch_spark_mnist').setMaster('yarn').set('spark.sql.shuffle.partitions', '16')\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "\n",
    "\n",
    "store = Store.create('/tmp')\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logging.basicConfig(filename='./drivethru_log',level=logging.DEBUG)\n",
    "\n",
    "bucket = ...\n",
    "\n",
    "model_prefix = ...\n",
    "batch_size = 1\n",
    "num_epoch = 1\n",
    "n_plus=522\n",
    "n_time=167\n",
    "n_bkids=126\n",
    "n_weather=35\n",
    "n_feels=20\n",
    "#num_gpus = range(8)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_checkpoint_interval = 5\n",
    "\n",
    "\n",
    "time1=datetime.now()\n",
    "\n",
    "#df=spark.read.json(\"./bluewhale/data_small_simple/data_small_simple0.json\")\n",
    "df=spark.read.json(\"./bluewhale/data/0.json\")\n",
    "feature_cols=['pluids','timeidx','bkidx','weatheridx','feelsBucket']\n",
    "#feature_cols=['pluids']\n",
    "\n",
    "train_df=df.select(*(feature_cols+['label'])).cache()\n",
    "\n",
    "#train_df=df.rdd.map(lambda x:(Vectors.dense(x[0:-1]), x[-1])).toDF([\"features\", \"label\"])\n",
    "print(\"train df\")\n",
    "print(train_df.show())\n",
    "\n",
    "\n",
    "\n",
    "time2=datetime.now()\n",
    "data_prepare_time=time2-time1\n",
    "print(\"data load time:\")\n",
    "print(data_prepare_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plu_embedding(pluids):\n",
    "    embeds_pluids = nn.Embedding(n_plus, 50)\n",
    "    pluids=pluids.type(torch.LongTensor) \n",
    "    pluids = Variable(pluids)\n",
    "    \n",
    "    plu_embed = embeds_pluids(pluids)\n",
    "    return plu_embed\n",
    "def bkidx_embedding(bkidx):\n",
    "    embeds_bkidx = nn.Embedding(n_bkids, 100)\n",
    "    bkidx=bkidx.type(torch.LongTensor) \n",
    "    bkidx = Variable(bkidx)\n",
    "    bkidx_embed = embeds_bkidx(bkidx)\n",
    "    return bkidx_embed\n",
    "def timeidx_embedding(timeidx):\n",
    "    embeds_timeidx = nn.Embedding(n_time, 100)\n",
    "    timeidx=timeidx.type(torch.LongTensor)\n",
    "    timeidx = Variable(timeidx)\n",
    "    time_embed = embeds_timeidx(timeidx)\n",
    "    return time_embed\n",
    "def feels_embedding(feelsBucket):\n",
    "    embeds_feelsBucket = nn.Embedding(n_feels,100)\n",
    "    feelsBucket=feelsBucket.type(torch.LongTensor)\n",
    "    feelsBucket = Variable(feelsBucket)\n",
    "    feels_embed = embeds_feelsBucket(feelsBucket)\n",
    "    return feels_embed\n",
    "def weather_embedding(weather):\n",
    "    embeds_weather = nn.Embedding(n_weather, 100)\n",
    "    weather=weather.type(torch.LongTensor)\n",
    "    weather = Variable(weather)\n",
    "    weather_embed = embeds_weather(weather)\n",
    "    return weather_embed\n",
    "\n",
    "# Bidirectional recurrent neural network (many-to-one)\n",
    "\n",
    "# below is model is built following MXNet's example \n",
    "# Bidirectional recurrent neural network (many-to-one)\n",
    "time3=datetime.now()\n",
    "\n",
    "class BiRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers,fcn_input_size,fcn_output_size):\n",
    "        super(BiRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        \n",
    "        self.hidden1 = nn.Linear(100,100)\n",
    "        self.hidden2 = nn.Linear(100,1)\n",
    "        \n",
    "        self.flatten=nn.Flatten()\n",
    "        \n",
    "        self.fcn_input_size=fcn_input_size\n",
    "        self.fcn_output_size=fcn_output_size\n",
    "        \n",
    "        self.drop_layer=nn.Dropout(p=0.3)\n",
    "        self.fc=nn.Linear(fcn_input_size,fcn_output_size)\n",
    "        \n",
    "    #def forward(self,pluids,bkidx,timeidx,weatheridx,feelsBucket):\n",
    "    \n",
    "    \n",
    "    def forward(self,pluids,timeidx,bkidx,weatheridx,feelsBucket):\n",
    "        # Set initial states\n",
    "        \n",
    "        plu_embed=plu_embedding(pluids)\n",
    "        bkidx_embed=bkidx_embedding(bkidx)\n",
    "        time_embed=timeidx_embedding(timeidx)\n",
    "        weather_embed=weather_embedding(weatheridx)\n",
    "        feels_embed=feels_embedding(feelsBucket)\n",
    "        \n",
    "        \n",
    "        \n",
    "        x=plu_embed\n",
    "        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size) # 2 for bidirection \n",
    "        #c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size)\n",
    "        # Forward propagate gru\n",
    "        #gru_out, _ = self.gru(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size*2)\n",
    "        gru_out, _ = self.gru(x, h0)\n",
    "        ut = F.tanh(self.hidden1(gru_out))\n",
    "        # et shape: [batch_size, seq_len, att_hops]\n",
    "        et = self.hidden2(ut)\n",
    "\n",
    "        # att shape: [batch_size,  att_hops, seq_len]\n",
    "        att = F.softmax(torch.transpose(et, 2, 1))\n",
    "        #att=torch.reshape(att,(100,2))\n",
    "        #att = F.sofrtmax(et).squeeze()\n",
    "        # output shape [batch_size, att_hops, embedding_width]\n",
    "        output= torch.matmul(att, gru_out)\n",
    "        \n",
    "        #flatten the output\n",
    "        attention_output =self.flatten(output)\n",
    "        \n",
    "        context_features=torch.mul(attention_output,(1 + bkidx_embed + time_embed + weather_embed + feels_embed))\n",
    "        \n",
    "\n",
    "        ac1=F.relu(context_features)\n",
    "        dropout1=self.drop_layer(ac1)\n",
    "        fc1=self.fc(dropout1)\n",
    "        output=F.softmax(fc1)\n",
    "        return output\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=BiRNN(50, 50, 5,100,1).to(device)\n",
    "\n",
    "learning_rate=0.01\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.Adagrad(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#num-proc number of worker processes for training, default: `spark.default.parallelism`')\n",
    "#pluids  timeidx  bkidx  weatheridx  feelsBucket\n",
    "#loss=lambda input, target: loss(input, target.long())        \n",
    "# Train a Horovod Spark Estimator on the DataFrame\n",
    "num_proc=4\n",
    "backend = SparkBackend(num_proc, nic=\"em1\")\n",
    "#.type(torch.LongTensor)\n",
    "torch_estimator = hvd.TorchEstimator(backend=backend,\n",
    "                                     store=store,\n",
    "                                     model=model,\n",
    "                                     optimizer=optimizer,\n",
    "                                     loss=lambda input, target: loss(input, target),\n",
    "                                     input_shapes=[[5,1], [1], [1], [1], [1]],\n",
    "                                     feature_cols=feature_cols,\n",
    "                                     label_cols=['label'],\n",
    "                                     batch_size=batch_size,\n",
    "                                     epochs=num_epoch,\n",
    "                                     verbose=1)\n",
    "    \n",
    "torch_model = torch_estimator.fit(train_df).setOutputCols(['label_prob'])\n",
    "\n",
    "time4=datetime.now()\n",
    "model_train_time=time4-time3\n",
    "print(\"model train time\")\n",
    "print(model_train_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
