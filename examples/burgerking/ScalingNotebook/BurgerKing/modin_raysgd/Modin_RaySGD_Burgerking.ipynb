{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modin + RaySGD + Ray for BurgerKing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configargparse\n",
    "import os\n",
    "\n",
    "p = configargparse.ArgParser(default_config_files=['../conf/burgerking.conf'])\n",
    "p.add_argument(\"--ray-init-address\", type=str)\n",
    "p.add_argument(\"--data-prefix\", type=lambda x: os.path.abspath(x))\n",
    "options, _ = p.parse_known_args()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '10.0.0.157',\n",
       " 'raylet_ip_address': '10.0.0.157',\n",
       " 'redis_address': '10.0.0.157:6379',\n",
       " 'object_store_address': '/tmp/ray/session_2020-11-24_14-52-05_191428_92260/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2020-11-24_14-52-05_191428_92260/sockets/raylet',\n",
       " 'webui_url': 'localhost:8265',\n",
       " 'session_dir': '/tmp/ray/session_2020-11-24_14-52-05_191428_92260'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "from ray.util.sgd import TorchTrainer\n",
    "from ray.util.sgd.torch import TrainingOperator\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init(address=options.ray_init_address) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import modin.pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logging.basicConfig(filename='./drivethru_log',level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0.48s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "batch_size = 16000\n",
    "num_epoch = 1\n",
    "\n",
    "df_list = []\n",
    "num_files=10\n",
    "for num in range(0,3):\n",
    "    df = pd.read_json(os.path.join(options.data_prefix, f'{num}.json'), orient='columns', lines=True)\n",
    "    df_list.append(df)\n",
    "data = pd.concat(df_list)\n",
    "\n",
    "end = time.time()\n",
    "prepare_time =end - start\n",
    "print(f\"time: {prepare_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: `Series.tolist` defaulting to pandas implementation.\n",
      "To request implementation, send an email to feature_requests@modin.org.\n"
     ]
    }
   ],
   "source": [
    "n_plus=522\n",
    "n_time=167\n",
    "n_bkids=126\n",
    "n_weather=35\n",
    "n_feels=20\n",
    "\n",
    "data = data[[\"pluids\", \"timeidx\", \"bkidx\", \"weatheridx\", \"feelsBucket\", \"label\"]]\n",
    "train_tensors = [\n",
    "    torch.LongTensor(data['pluids'].tolist()),\n",
    "    torch.tensor(data[[\"timeidx\"]].values),\n",
    "    torch.tensor(data[[\"bkidx\"]].values),\n",
    "    torch.tensor(data[[\"weatheridx\"]].values),\n",
    "    torch.tensor(data[[\"feelsBucket\"]].values),\n",
    "    torch.tensor(data[[\"label\"]].values),\n",
    "]\n",
    "train_dataset = TensorDataset(*train_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bidirectional recurrent neural network (many-to-one)\n",
    "\n",
    "# below is model is built following MXNet's example \n",
    "class BiRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers,fcn_input_size,fcn_output_size):\n",
    "        super(BiRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embeds_pluids = nn.Embedding(n_plus, 50)\n",
    "        self.embeds_bkidx = nn.Embedding(n_bkids, 100)\n",
    "        self.embeds_timeidx = nn.Embedding(n_time, 100)\n",
    "        self.embeds_feelsBucket = nn.Embedding(n_feels, 100)\n",
    "        self.embeds_weather = nn.Embedding(n_weather, 100)\n",
    "        \n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        self.hidden1 = nn.Linear(100,100)\n",
    "        self.hidden2 = nn.Linear(100,1)\n",
    "        \n",
    "        self.flatten=nn.Flatten()\n",
    "        \n",
    "        self.fcn_input_size=fcn_input_size\n",
    "        self.fcn_output_size=fcn_output_size\n",
    "        \n",
    "        self.drop_layer=nn.Dropout(p=0.3)\n",
    "        self.fc=nn.Linear(fcn_input_size,fcn_output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        # Set initial states\n",
    "        pluids, timeidx, bkidx, weatheridx, feelsBucket = x\n",
    "        plu_embed = self.embeds_pluids(pluids.type(torch.LongTensor)).squeeze()\n",
    "        bkidx_embed = self.embeds_bkidx(bkidx.type(torch.LongTensor)).squeeze()\n",
    "        time_embed = self.embeds_timeidx(timeidx.type(torch.LongTensor)).squeeze()\n",
    "        weather_embed = self.embeds_weather(weatheridx.type(torch.LongTensor)).squeeze()\n",
    "        feels_embed = self.embeds_feelsBucket(feelsBucket.type(torch.LongTensor)).squeeze()\n",
    "        \n",
    "        x = plu_embed\n",
    "        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size) # 2 for bidirection \n",
    "        \n",
    "        # Forward propagate gru\n",
    "        gru_out, _ = self.gru(x, h0)\n",
    "        ut = torch.tanh(self.hidden1(gru_out))\n",
    "        et = self.hidden2(ut)\n",
    "        att = F.softmax(torch.transpose(et, 2, 1), dim=-1)\n",
    "        output= torch.matmul(att, gru_out)\n",
    "        \n",
    "        # flatten the output\n",
    "        attention_output =self.flatten(output)\n",
    "        context_features=torch.mul(attention_output,(1 + bkidx_embed + time_embed + weather_embed + feels_embed))\n",
    "        ac1=F.relu(context_features)\n",
    "        dropout1=self.drop_layer(ac1)\n",
    "        output=self.fc(dropout1)\n",
    "       \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Custom Traing and Validation Operator for RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "def model_creator(config):\n",
    "    return BiRNN(50,50,5,100,1).to(device)\n",
    "\n",
    "def optimizer_creator(model, config):\n",
    "    \"\"\"Returns optimizer.\"\"\"\n",
    "    return torch.optim.Adagrad(model.parameters(),lr=1e-2)\n",
    "\n",
    "def data_creator(config):\n",
    "    #Constructs Iterables for training and validation.\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True) \n",
    "    return train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Customer Traing and Validation \n",
    "\n",
    "\n",
    "class RNNOperator(TrainingOperator):\n",
    "    def setup(self, config):\n",
    "        \"\"\"Custom setup for this operator.\n",
    "\n",
    "        Args:\n",
    "            config (dict): Custom configuration value to be passed to\n",
    "                all creator and operator constructors. Same as ``self.config``.\n",
    "        \"\"\"\n",
    "        # self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.batch_idx = 0\n",
    "\n",
    "    def train_batch(self, batch, batch_info):\n",
    "        \"\"\"Trains on one batch of data from the data creator.\n",
    "        Args:\n",
    "            batch: One item of the validation iterator.\n",
    "            batch_info (dict): Information dict passed in from ``train_epoch``.\n",
    "\n",
    "        Returns:\n",
    "            A dict of metrics. Defaults to \"loss\" and \"num_samples\",\n",
    "                corresponding to the total number of datapoints in the batch.\n",
    "        \"\"\"\n",
    "        self.batch_idx += 1\n",
    "        x, label = batch[:-1], batch[-1].squeeze()\n",
    "        output = self.model(x).type(torch.FloatTensor).squeeze()\n",
    "        self.optimizer.zero_grad()\n",
    "        loss = self.criterion(output, label)\n",
    "        loss = Variable(loss, requires_grad = True)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        if self.batch_idx % 1000 == 0:\n",
    "            print(f'batch: {self.batch_idx}, loss: {loss.item()}')\n",
    "        \n",
    "\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        return {\n",
    "            \"loss\": loss.item()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Launches a set of actors which connect via distributed PyTorch and\n",
    "coordinate gradient updates to train the provided model. If Ray is not\n",
    "initialized, TorchTrainer will automatically initialize a local Ray\n",
    "cluster for you. Be sure to run `ray.init(address=\"auto\")` to leverage\n",
    "multi-node training.\n",
    "'''\n",
    "\n",
    "def train_RNN(num_workers=1, use_gpu=False):\n",
    "    trainer = TorchTrainer(\n",
    "        model_creator=model_creator,\n",
    "        data_creator=data_creator,\n",
    "        optimizer_creator=optimizer_creator,\n",
    "        loss_creator=torch.nn.MSELoss,\n",
    "        #loss_creator=nn.BCELoss(),\n",
    "        #loss_creator=torch.nn.CrossEntropyLoss(),\n",
    "        training_operator_cls=RNNOperator,\n",
    "        num_workers=num_workers,\n",
    "        use_gpu=False,\n",
    "        config={\"batch_size\": batch_size})\n",
    "    \n",
    "    for i in range(3):\n",
    "        stats = trainer.train()\n",
    "        print(f\"Step: {i}, stats: {stats}\")\n",
    "        \n",
    "    # print(trainer.validate())\n",
    "    m = trainer.get_model()\n",
    "\n",
    "    model = trainer.get_model()\n",
    "    print(model.parameters())\n",
    "\n",
    "    trainer.shutdown()\n",
    "    print(\"success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0, stats: {'num_samples': 2, 'epoch': 1, 'batch_count': 1, 'loss': 90627.2890625, 'last_loss': 90627.2890625}\n",
      "Step: 1, stats: {'num_samples': 2, 'epoch': 2, 'batch_count': 1, 'loss': 91881.2421875, 'last_loss': 91881.2421875}\n",
      "Step: 2, stats: {'num_samples': 2, 'epoch': 3, 'batch_count': 1, 'loss': 91483.2265625, 'last_loss': 91483.2265625}\n",
      "<generator object Module.parameters at 0x7f81c17b24d0>\n",
      "success!\n"
     ]
    }
   ],
   "source": [
    "train_RNN(num_workers=2, use_gpu=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
