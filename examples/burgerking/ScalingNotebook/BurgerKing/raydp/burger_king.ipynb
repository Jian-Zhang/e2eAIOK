{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RayDP for Burgerking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configargparse\n",
    "import os\n",
    "\n",
    "import databricks.koalas as ks\n",
    "import ray\n",
    "from ray.util.sgd.torch.torch_trainer import TorchTrainer\n",
    "\n",
    "import raydp.spark.context as context\n",
    "from raydp.spark.torch_sgd import TorchEstimator\n",
    "from raydp.spark.utils import random_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = configargparse.ArgParser(default_config_files=['../conf/burgerking.conf'])\n",
    "p.add_argument(\"--spark-home\", type=str)\n",
    "p.add_argument(\"--ray-address\", type=str)\n",
    "p.add_argument(\"--ray-node-ip\", type=str)\n",
    "p.add_argument(\"--ray-passwd\", type=str)\n",
    "p.add_argument(\"--ray-data-path\", type=str)\n",
    "\n",
    "options, _ = p.parse_known_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ray Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add spark home into the env\n",
    "os.environ[\"SPARK_HOME\"] = options.spark_home\n",
    "GB = 1024 * 1024 * 1024\n",
    "\n",
    "# connect to ray cluster\n",
    "ray.init(address=options.ray_address, node_ip_address=options.ray_node_ip, redis_password=options.ray_passwd)\n",
    "\n",
    "# init spark context\n",
    "context.init_spark(app_name=\"Burger King\",\n",
    "                   num_executors=2,\n",
    "                   executor_cores=10,\n",
    "                   executor_memory=int(40 * GB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data processing with koalas\n",
    "df: ks.DataFrame = ks.read_json(options.ray_data_path)\n",
    "train_df, test_df = random_split(df, [0.7, 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_plus = 522\n",
    "n_time = 167\n",
    "n_bkids = 126\n",
    "n_weather = 35\n",
    "n_feels = 20\n",
    "\n",
    "# Bidirectional recurrent neural network (many-to-one)\n",
    "class BiRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, fcn_input_size, fcn_output_size):\n",
    "        super(BiRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embeds_pluids = nn.Embedding(n_plus, 50)\n",
    "        self.embeds_bkidx = nn.Embedding(n_bkids, 100)\n",
    "        self.embeds_timeidx = nn.Embedding(n_time, 100)\n",
    "        self.embeds_feelsBucket = nn.Embedding(n_feels, 100)\n",
    "        self.embeds_weather = nn.Embedding(n_weather, 100)\n",
    "        \n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        self.hidden1 = nn.Linear(100, 100)\n",
    "        self.hidden2 = nn.Linear(100, 1)\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.drop_layer = nn.Dropout(p=0.3)\n",
    "        self.fc = nn.Linear(fcn_input_size, fcn_output_size)\n",
    "        \n",
    "    def forward(self, pluids, timeidx, bkidx, weatheridx, feelsBucket):\n",
    "        plu_embed = self.embeds_pluids(pluids)\n",
    "        bkidx_embed = self.embeds_bkidx(bkidx)\n",
    "        time_embed = self.embeds_timeidx(timeidx)\n",
    "        weather_embed = self.embeds_weather(weatheridx)\n",
    "        feels_embed = self.embeds_feelsBucket(feelsBucket)\n",
    "\n",
    "        x = plu_embed\n",
    "\n",
    "        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size) # 2 for bidirection \n",
    "        # Forward propagate gru\n",
    "        gru_out, _ = self.gru(x, h0)\n",
    "        ut = torch.tanh(self.hidden1(gru_out))\n",
    "        # et shape: [batch_size, seq_len, att_hops]\n",
    "        et = self.hidden2(ut)\n",
    "\n",
    "        # att shape: [batch_size,  att_hops, seq_len]\n",
    "        att = F.softmax(torch.transpose(et, 2, 1))\n",
    "        \n",
    "        # output shape [batch_size, att_hops, embedding_width]\n",
    "        output = torch.matmul(att, gru_out)\n",
    "        \n",
    "        # flatten the output\n",
    "        attention_output = self.flatten(output)\n",
    "        context_features = torch.mul(attention_output,(1 + bkidx_embed + time_embed + weather_embed + feels_embed))\n",
    "        ac1 = F.relu(context_features)\n",
    "        \n",
    "        dropout = self.drop_layer(ac1)\n",
    "        output = self.fc(dropout)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train with SGD\n",
    "model = BiRNN(50, 50, 5, 100, 2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "estimator = TorchEstimator(num_workers=2,\n",
    "                           model=model,\n",
    "                           optimizer=optimizer,\n",
    "                           loss=loss,\n",
    "                           feature_columns=[\"pluids\", \"timeidx\", \"bkidx\", \"weatheridx\", \"feelsBucket\"],\n",
    "                           feature_shapes=[5, 0, 0, 0, 0],\n",
    "                           feature_types=[torch.long, torch.long, torch.long, torch.long, torch.long],\n",
    "                           label_column=\"label\",\n",
    "                           label_type=torch.long,\n",
    "                           batch_size=100,\n",
    "                           num_epochs=10)\n",
    "\n",
    "estimator.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.evaluate(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(estimator.get_model())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.shutdown()\n",
    "context.stop_spark()\n",
    "ray.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
