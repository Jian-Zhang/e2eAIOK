nohup: ignoring input
[1,1]<stdout>:Begin Process:
[1,0]<stdout>:Begin Process:
[1,1]<stdout>:command line args:  {"arch_sparse_feature_size": 16, "arch_embedding_size": "4-3-2", "arch_mlp_bot": "13-512-256-64-16", "arch_mlp_top": "512-256-1", "arch_interaction_op": "dot", "arch_interaction_itself": false, "md_flag": false, "md_threshold": 200, "md_temperature": 0.3, "md_round_dims": false, "qr_flag": false, "qr_threshold": 200, "qr_operation": "mult", "qr_collisions": 4, "activation_function": "relu", "loss_function": "bce", "loss_weights": "1.0-1.0", "loss_threshold": 0.0, "round_targets": true, "data_size": 1, "num_batches": 0, "data_generation": "dataset", "data_trace_file": "./input/dist_emb_j.log", "data_set": "kaggle", "raw_data_file": "/mnt/DP_disk1/dlrm/kaggle/backup/train.txt", "processed_data_file": "/mnt/DP_disk1/dlrm/kaggle/backup/kaggleAdDisplayChallenge_processed.npz", "data_randomize": "total", "data_trace_enable_padding": false, "max_ind_range": -1, "data_sub_sample_rate": 0.0, "num_indices_per_lookup": 10, "num_indices_per_lookup_fixed": false, "num_workers": 0, "memory_map": false, "mini_batch_size": 128, "nepochs": 1, "learning_rate": 0.1, "print_precision": 5, "numpy_rand_seed": 123, "sync_dense_params": true, "inference_only": false, "save_onnx": false, "use_gpu": false, "print_freq": 1000, "test_freq": 5000, "test_mini_batch_size": 128, "test_num_workers": 16, "print_time": true, "debug_mode": false, "enable_profiling": false, "plot_compute_graph": false, "save_model": "", "load_model": "", "mlperf_logging": true, "mlperf_acc_threshold": 0.0, "mlperf_auc_threshold": 0.8025, "mlperf_bin_loader": true, "mlperf_bin_shuffle": false, "lr_num_warmup_steps": 0, "lr_decay_start_step": 0, "lr_num_decay_steps": 0}
[1,0]<stdout>:command line args:  {"arch_sparse_feature_size": 16, "arch_embedding_size": "4-3-2", "arch_mlp_bot": "13-512-256-64-16", "arch_mlp_top": "512-256-1", "arch_interaction_op": "dot", "arch_interaction_itself": false, "md_flag": false, "md_threshold": 200, "md_temperature": 0.3, "md_round_dims": false, "qr_flag": false, "qr_threshold": 200, "qr_operation": "mult", "qr_collisions": 4, "activation_function": "relu", "loss_function": "bce", "loss_weights": "1.0-1.0", "loss_threshold": 0.0, "round_targets": true, "data_size": 1, "num_batches": 0, "data_generation": "dataset", "data_trace_file": "./input/dist_emb_j.log", "data_set": "kaggle", "raw_data_file": "/mnt/DP_disk1/dlrm/kaggle/backup/train.txt", "processed_data_file": "/mnt/DP_disk1/dlrm/kaggle/backup/kaggleAdDisplayChallenge_processed.npz", "data_randomize": "total", "data_trace_enable_padding": false, "max_ind_range": -1, "data_sub_sample_rate": 0.0, "num_indices_per_lookup": 10, "num_indices_per_lookup_fixed": false, "num_workers": 0, "memory_map": false, "mini_batch_size": 128, "nepochs": 1, "learning_rate": 0.1, "print_precision": 5, "numpy_rand_seed": 123, "sync_dense_params": true, "inference_only": false, "save_onnx": false, "use_gpu": false, "print_freq": 1000, "test_freq": 5000, "test_mini_batch_size": 128, "test_num_workers": 16, "print_time": true, "debug_mode": false, "enable_profiling": false, "plot_compute_graph": false, "save_model": "", "load_model": "", "mlperf_logging": true, "mlperf_acc_threshold": 0.0, "mlperf_auc_threshold": 0.8025, "mlperf_bin_loader": true, "mlperf_bin_shuffle": false, "lr_num_warmup_steps": 0, "lr_decay_start_step": 0, "lr_num_decay_steps": 0}
[1,1]<stdout>:Using CPU...
[1,1]<stdout>:Begin data pre-processing
[1,1]<stdout>:Reading pre-processed data=/mnt/DP_disk1/dlrm/kaggle/backup/kaggleAdDisplayChallenge_processed.npz
[1,0]<stdout>:Using CPU...
[1,0]<stdout>:Begin data pre-processing
[1,0]<stdout>:Reading pre-processed data=/mnt/DP_disk1/dlrm/kaggle/backup/kaggleAdDisplayChallenge_processed.npz
[1,1]<stdout>:Sparse fea = 26, Dense fea = 13
[1,1]<stdout>:Defined train indices...
[1,1]<stdout>:Randomized indices across days ...
[1,0]<stdout>:Sparse fea = 26, Dense fea = 13
[1,0]<stdout>:Defined train indices...
[1,0]<stdout>:Randomized indices across days ...
[1,1]<stdout>:Split data according to indices...
[1,1]<stdout>:Reading pre-processed data=/mnt/DP_disk1/dlrm/kaggle/backup/kaggleAdDisplayChallenge_processed.npz
[1,0]<stdout>:Split data according to indices...
[1,0]<stdout>:Reading pre-processed data=/mnt/DP_disk1/dlrm/kaggle/backup/kaggleAdDisplayChallenge_processed.npz
[1,1]<stdout>:Sparse fea = 26, Dense fea = 13
[1,1]<stdout>:Defined test indices...
[1,1]<stdout>:Randomized indices across days ...
[1,1]<stdout>:Split data according to indices...
[1,1]<stdout>:Begin commandline parse
[1,0]<stdout>:Sparse fea = 26, Dense fea = 13
[1,0]<stdout>:Defined test indices...
[1,0]<stdout>:Randomized indices across days ...
[1,0]<stdout>:Split data according to indices...
[1,0]<stdout>:Begin commandline parse
[1,0]<stdout>:Begin Mainloop
[1,0]<stdout>:time/loss/accuracy (if enabled):
[1,1]<stdout>:Begin Mainloop
[1,1]<stdout>:time/loss/accuracy (if enabled):
[1,1]<stdout>:before forward:5.4836273193359375e-06
[1,1]<stdout>:forward time:0.007462501525878906
[1,1]<stdout>:Compute loss time:0.0011594295501708984
[1,0]<stdout>:before forward:6.198883056640625e-06
[1,0]<stdout>:forward time:0.005262136459350586
[1,0]<stdout>:Compute loss time:0.0011587142944335938
[1,1]<stdout>:optimizer zero grad time:0.04189777374267578
[1,0]<stdout>:optimizer zero grad time:0.037737131118774414
[1,1]<stdout>:optimizer backward time:0.03773999214172363
[1,0]<stdout>:optimizer backward time:0.03442883491516113
[1,1]<stdout>:optimizer step time:4.201519012451172
[1,1]<stdout>:learning rate step time:0.00025391578674316406
[1,1]<stdout>:after loss time:4.281538724899292
[1,1]<stdout>:print output time:1.9311904907226562e-05
[1,1]<stdout>:test time:1.3828277587890625e-05
[1,1]<stdout>:training iter1,this iter consuming time:4.290199279785156
[1,0]<stdout>:optimizer step time:4.196037292480469
[1,0]<stdout>:learning rate step time:0.0007784366607666016
[1,0]<stdout>:after loss time:4.269451379776001
[1,0]<stdout>:print output time:2.0503997802734375e-05
[1,0]<stdout>:test time:3.5762786865234375e-05
[1,0]<stdout>:training iter1,this iter consuming time:4.27593469619751
[1,0]<stdout>:before forward:5.9604644775390625e-06
[1,0]<stdout>:forward time:0.006242036819458008
[1,0]<stdout>:Compute loss time:0.0007288455963134766
[1,1]<stdout>:before forward:8.106231689453125e-06
[1,1]<stdout>:forward time:0.003573894500732422
[1,1]<stdout>:Compute loss time:0.00043773651123046875
[1,0]<stdout>:optimizer zero grad time:0.04307913780212402
[1,1]<stdout>:optimizer zero grad time:0.04037976264953613
[1,0]<stdout>:optimizer backward time:0.02408456802368164
[1,1]<stdout>:optimizer backward time:0.03147554397583008
[1,0]<stdout>:optimizer step time:3.9689972400665283
[1,0]<stdout>:learning rate step time:0.00011587142944335938
[1,0]<stdout>:after loss time:4.036350727081299
[1,0]<stdout>:print output time:1.5497207641601562e-05
[1,0]<stdout>:test time:4.1484832763671875e-05
[1,0]<stdout>:training iter2,this iter consuming time:4.043384552001953
[1,0]<stdout>:before forward:5.245208740234375e-06
[1,0]<stdout>:forward time:0.004423618316650391
[1,0]<stdout>:Compute loss time:0.0002980232238769531
[1,1]<stdout>:optimizer step time:3.981562614440918
[1,1]<stdout>:learning rate step time:0.00023937225341796875
[1,1]<stdout>:after loss time:4.053779363632202
[1,1]<stdout>:print output time:3.123283386230469e-05
[1,1]<stdout>:test time:1.7642974853515625e-05
[1,1]<stdout>:training iter2,this iter consuming time:4.05784797668457
[1,1]<stdout>:before forward:8.821487426757812e-06
[1,1]<stdout>:forward time:0.005813121795654297
[1,1]<stdout>:Compute loss time:0.0005624294281005859
[1,0]<stdout>:optimizer zero grad time:0.046393632888793945
[1,0]<stdout>:optimizer backward time:0.026266813278198242
[1,1]<stdout>:optimizer zero grad time:0.05664849281311035
[1,1]<stdout>:optimizer backward time:0.024408817291259766
[1,1]<stdout>:optimizer step time:3.880276679992676
[1,1]<stdout>:learning rate step time:0.00011992454528808594
[1,1]<stdout>:after loss time:3.961540937423706
[1,1]<stdout>:print output time:2.0265579223632812e-05
[1,1]<stdout>:test time:1.9788742065429688e-05
[1,1]<stdout>:training iter3,this iter consuming time:3.9679653644561768
[1,1]<stdout>:before forward:5.4836273193359375e-06
[1,0]<stdout>:optimizer step time:3.9302361011505127
[1,0]<stdout>:learning rate step time:0.00011682510375976562
[1,0]<stdout>:after loss time:4.003093481063843
[1,0]<stdout>:print output time:1.5497207641601562e-05
[1,0]<stdout>:test time:5.316734313964844e-05
[1,0]<stdout>:training iter3,this iter consuming time:4.007889032363892
[1,0]<stdout>:before forward:4.76837158203125e-06
[1,1]<stdout>:forward time:0.004391908645629883
[1,1]<stdout>:Compute loss time:0.00036597251892089844
[1,0]<stdout>:forward time:0.0038480758666992188
[1,0]<stdout>:Compute loss time:0.0002880096435546875
[1,0]<stdout>:optimizer zero grad time:0.04538226127624512
[1,1]<stdout>:optimizer zero grad time:0.05211973190307617
[1,1]<stdout>:optimizer backward time:0.027077198028564453
[1,0]<stdout>:optimizer backward time:0.032099008560180664
[1,0]<stdout>:optimizer step time:4.134619474411011
[1,0]<stdout>:learning rate step time:0.0001068115234375
[1,0]<stdout>:after loss time:4.212313175201416
[1,0]<stdout>:print output time:2.0265579223632812e-05
[1,0]<stdout>:test time:1.4543533325195312e-05
[1,0]<stdout>:training iter4,this iter consuming time:4.216488838195801
[1,0]<stdout>:before forward:5.4836273193359375e-06
[1,0]<stdout>:forward time:0.003849029541015625
[1,0]<stdout>:Compute loss time:0.00033092498779296875
[1,1]<stdout>:optimizer step time:4.145615816116333
[1,1]<stdout>:learning rate step time:0.00023984909057617188
[1,1]<stdout>:after loss time:4.225358486175537
[1,1]<stdout>:print output time:0.00011515617370605469
[1,1]<stdout>:test time:3.2901763916015625e-05
[1,1]<stdout>:training iter4,this iter consuming time:4.230269908905029
[1,1]<stdout>:before forward:1.52587890625e-05
[1,1]<stdout>:forward time:0.005915641784667969
[1,1]<stdout>:Compute loss time:0.0006444454193115234
[1,0]<stdout>:optimizer zero grad time:0.04542350769042969
[1,0]<stdout>:optimizer backward time:0.027498960494995117
[1,1]<stdout>:optimizer zero grad time:0.05166935920715332
[1,1]<stdout>:optimizer backward time:0.03596997261047363
[1,0]<stdout>:optimizer step time:4.124646186828613
[1,0]<stdout>:learning rate step time:0.00010466575622558594
[1,0]<stdout>:after loss time:4.197753667831421
[1,0]<stdout>:print output time:1.71661376953125e-05
[1,0]<stdout>:test time:1.8358230590820312e-05
[1,0]<stdout>:training iter5,this iter consuming time:4.201974630355835
[1,1]<stdout>:optimizer step time:4.093485116958618
[1,1]<stdout>:learning rate step time:0.00011491775512695312
[1,1]<stdout>:after loss time:4.181324481964111
[1,1]<stdout>:print output time:1.811981201171875e-05
[1,1]<stdout>:test time:1.3828277587890625e-05
[1,1]<stdout>:training iter5,this iter consuming time:4.187931776046753
[1,1]<stdout>:before forward:5.7220458984375e-06
[1,1]<stdout>:forward time:0.0038924217224121094
[1,1]<stdout>:Compute loss time:0.0003223419189453125
[1,0]<stdout>:before forward:6.67572021484375e-06
[1,0]<stdout>:forward time:0.0036771297454833984
[1,0]<stdout>:Compute loss time:0.0003180503845214844
[1,1]<stdout>:optimizer zero grad time:0.06076550483703613
[1,0]<stdout>:optimizer zero grad time:0.04604816436767578
[1,1]<stdout>:optimizer backward time:0.02990865707397461
[1,0]<stdout>:optimizer backward time:0.027771711349487305
[1,1]<stdout>:optimizer step time:4.098124265670776
[1,1]<stdout>:learning rate step time:0.00014591217041015625
[1,1]<stdout>:after loss time:4.189039468765259
[1,1]<stdout>:print output time:1.52587890625e-05
[1,1]<stdout>:test time:1.3589859008789062e-05
[1,1]<stdout>:training iter6,this iter consuming time:4.193288803100586
[1,1]<stdout>:before forward:3.790855407714844e-05
[1,1]<stdout>:forward time:0.003587961196899414
[1,1]<stdout>:Compute loss time:0.00031757354736328125
[1,0]<stdout>:optimizer step time:4.105875253677368
[1,0]<stdout>:learning rate step time:0.0002422332763671875
[1,0]<stdout>:after loss time:4.180113315582275
[1,0]<stdout>:print output time:2.4080276489257812e-05
[1,0]<stdout>:test time:2.2649765014648438e-05
[1,0]<stdout>:training iter6,this iter consuming time:4.184161901473999
[1,0]<stdout>:before forward:9.775161743164062e-06
[1,1]<stdout>:optimizer zero grad time:0.0543820858001709
[1,0]<stdout>:forward time:0.00526738166809082
[1,0]<stdout>:Compute loss time:0.0006220340728759766
[1,1]<stdout>:optimizer backward time:0.029074907302856445
[1,0]<stdout>:optimizer zero grad time:0.04309344291687012
[1,0]<stdout>:optimizer backward time:0.029462575912475586
[1,0]<stdout>:optimizer step time:4.0791966915130615
[1,0]<stdout>:learning rate step time:0.00018525123596191406
[1,0]<stdout>:after loss time:4.1520349979400635
[1,0]<stdout>:print output time:2.2411346435546875e-05
[1,0]<stdout>:test time:1.8596649169921875e-05
[1,0]<stdout>:training iter7,this iter consuming time:4.157975196838379
[1,1]<stdout>:optimizer step time:4.130061626434326
[1,1]<stdout>:learning rate step time:0.00022792816162109375
[1,1]<stdout>:after loss time:4.213885545730591
[1,1]<stdout>:print output time:2.3365020751953125e-05
[1,1]<stdout>:test time:1.5974044799804688e-05
[1,1]<stdout>:training iter7,this iter consuming time:4.217868328094482
[1,1]<stdout>:before forward:7.152557373046875e-06
[1,1]<stdout>:forward time:0.005199909210205078
[1,1]<stdout>:Compute loss time:0.0005178451538085938
[1,0]<stdout>:before forward:1.0013580322265625e-05
[1,0]<stdout>:forward time:0.004546165466308594
[1,0]<stdout>:Compute loss time:0.00048351287841796875
[1,1]<stdout>:optimizer zero grad time:0.04674959182739258
[1,0]<stdout>:optimizer zero grad time:0.0460810661315918
[1,1]<stdout>:optimizer backward time:0.03380131721496582
[1,0]<stdout>:optimizer backward time:0.027329206466674805
[1,0]<stdout>:optimizer step time:3.8883650302886963
[1,0]<stdout>:learning rate step time:0.0001957416534423828
[1,0]<stdout>:after loss time:3.9620718955993652
[1,0]<stdout>:print output time:2.1219253540039062e-05
[1,0]<stdout>:test time:1.8358230590820312e-05
[1,0]<stdout>:training iter8,this iter consuming time:3.967151165008545
[1,1]<stdout>:optimizer step time:3.9012691974639893
[1,1]<stdout>:learning rate step time:0.00010991096496582031
[1,1]<stdout>:after loss time:3.9820032119750977
[1,1]<stdout>:print output time:1.5020370483398438e-05
[1,1]<stdout>:test time:1.4066696166992188e-05
[1,1]<stdout>:training iter8,this iter consuming time:3.9877572059631348
[1,1]<stdout>:before forward:4.76837158203125e-06
[1,1]<stdout>:forward time:0.003968477249145508
[1,1]<stdout>:Compute loss time:0.0003185272216796875
[1,1]<stdout>:optimizer zero grad time:0.04585075378417969
[1,0]<stdout>:before forward:1.0013580322265625e-05
[1,0]<stdout>:forward time:0.00516057014465332
[1,0]<stdout>:Compute loss time:0.00043392181396484375
[1,1]<stdout>:optimizer backward time:0.029747486114501953
[1,0]<stdout>:optimizer zero grad time:0.04489421844482422
[1,0]<stdout>:optimizer backward time:0.027294635772705078
[1,1]<stdout>:optimizer step time:4.15300989151001
[1,1]<stdout>:learning rate step time:0.00011587142944335938
[1,1]<stdout>:after loss time:4.228804588317871
[1,1]<stdout>:print output time:1.9311904907226562e-05
[1,1]<stdout>:test time:1.6450881958007812e-05
[1,1]<stdout>:training iter9,this iter consuming time:4.2331321239471436
[1,0]<stdout>:optimizer step time:4.0908873081207275
[1,0]<stdout>:learning rate step time:0.00034737586975097656
[1,1]<stdout>:before forward:7.62939453125e-06
[1,0]<stdout>:after loss time:4.163566589355469
[1,0]<stdout>:print output time:2.5510787963867188e-05
[1,0]<stdout>:test time:3.9577484130859375e-05
[1,0]<stdout>:training iter9,this iter consuming time:4.169236183166504
[1,1]<stdout>:forward time:0.0035636425018310547
[1,1]<stdout>:Compute loss time:0.00031447410583496094
[1,1]<stdout>:optimizer zero grad time:0.04836869239807129
[1,0]<stdout>:before forward:1.1444091796875e-05
[1,0]<stdout>:forward time:0.004480600357055664
[1,0]<stdout>:Compute loss time:0.0005660057067871094
[1,1]<stdout>:optimizer backward time:0.022157669067382812
[1,0]<stdout>:optimizer zero grad time:0.0384516716003418
[1,0]<stdout>:optimizer backward time:0.028047800064086914
[1,1]<stdout>:optimizer step time:4.130669116973877
[1,1]<stdout>:learning rate step time:0.00011491775512695312
[1,1]<stdout>:after loss time:4.201397180557251
[1,1]<stdout>:print output time:1.8596649169921875e-05
[1,1]<stdout>:test time:2.002716064453125e-05
[1,1]<stdout>:training iter10,this iter consuming time:4.205321550369263
[1,1]<stdout>:before forward:6.67572021484375e-06
[1,1]<stdout>:forward time:0.004219770431518555
[1,1]<stdout>:Compute loss time:0.0003669261932373047
[1,0]<stdout>:optimizer step time:4.1028196811676025
[1,0]<stdout>:learning rate step time:0.00037860870361328125
[1,0]<stdout>:after loss time:4.169793605804443
[1,0]<stdout>:print output time:2.4080276489257812e-05
[1,0]<stdout>:test time:2.2411346435546875e-05
[1,0]<stdout>:training iter10,this iter consuming time:4.174898147583008
[1,1]<stdout>:optimizer zero grad time:0.04843473434448242
[1,0]<stdout>:before forward:1.049041748046875e-05
[1,0]<stdout>:forward time:0.005163908004760742
[1,0]<stdout>:Compute loss time:0.0004248619079589844
[1,1]<stdout>:optimizer backward time:0.022414684295654297
[1,0]<stdout>:optimizer zero grad time:0.04212355613708496
[1,0]<stdout>:optimizer backward time:0.025275707244873047
[1,0]<stdout>:optimizer step time:4.135788202285767
[1,0]<stdout>:learning rate step time:0.00023484230041503906
[1,0]<stdout>:after loss time:4.203547239303589
[1,0]<stdout>:print output time:1.8596649169921875e-05
[1,0]<stdout>:test time:1.8596649169921875e-05
[1,0]<stdout>:training iter11,this iter consuming time:4.209183692932129
[1,1]<stdout>:optimizer step time:4.210910081863403
[1,1]<stdout>:learning rate step time:0.0002155303955078125
[1,1]<stdout>:after loss time:4.282110214233398
[1,1]<stdout>:print output time:2.3603439331054688e-05
[1,1]<stdout>:test time:1.9311904907226562e-05
[1,1]<stdout>:training iter11,this iter consuming time:4.286746501922607
[1,1]<stdout>:before forward:7.3909759521484375e-06
[1,1]<stdout>:forward time:0.0042667388916015625
[1,1]<stdout>:Compute loss time:0.0005106925964355469
[1,0]<stdout>:before forward:7.152557373046875e-06
[1,0]<stdout>:forward time:0.003555774688720703
[1,0]<stdout>:Compute loss time:0.0003376007080078125
[1,1]<stdout>:optimizer zero grad time:0.043183088302612305
[1,1]<stdout>:optimizer backward time:0.02278304100036621
[1,0]<stdout>:optimizer zero grad time:0.04285478591918945
[1,0]<stdout>:optimizer backward time:0.02773451805114746
[1,0]<stdout>:optimizer step time:4.039066553115845
[1,0]<stdout>:learning rate step time:0.00022864341735839844
[1,0]<stdout>:after loss time:4.110041379928589
[1,0]<stdout>:print output time:2.384185791015625e-05
[1,0]<stdout>:test time:1.4543533325195312e-05
[1,0]<stdout>:training iter12,this iter consuming time:4.113980293273926
[1,1]<stdout>:optimizer step time:4.071543455123901
[1,1]<stdout>:learning rate step time:0.00013065338134765625
[1,1]<stdout>:after loss time:4.137722969055176
[1,1]<stdout>:print output time:2.1457672119140625e-05
[1,1]<stdout>:test time:2.09808349609375e-05
[1,1]<stdout>:training iter12,this iter consuming time:4.142550230026245
[1,1]<stdout>:before forward:5.9604644775390625e-06
[1,1]<stdout>:forward time:0.0042591094970703125
[1,1]<stdout>:Compute loss time:0.0003733634948730469
[1,0]<stdout>:before forward:9.5367431640625e-06
[1,0]<stdout>:forward time:0.004365205764770508
[1,0]<stdout>:Compute loss time:0.0005469322204589844
[1,1]<stdout>:optimizer zero grad time:0.04574894905090332
[1,0]<stdout>:optimizer zero grad time:0.042109012603759766
[1,1]<stdout>:optimizer backward time:0.0234677791595459
[1,0]<stdout>:optimizer backward time:0.023978233337402344
[1,1]<stdout>:optimizer step time:4.075490236282349
[1,1]<stdout>:learning rate step time:0.00014162063598632812
[1,1]<stdout>:after loss time:4.144944429397583
[1,1]<stdout>:print output time:1.71661376953125e-05
[1,1]<stdout>:test time:1.9788742065429688e-05
[1,1]<stdout>:training iter13,this iter consuming time:4.149619817733765
[1,0]<stdout>:optimizer step time:4.07152795791626
[1,0]<stdout>:learning rate step time:0.000125885009765625
[1,0]<stdout>:after loss time:4.137836694717407
[1,0]<stdout>:print output time:2.09808349609375e-05
[1,0]<stdout>:test time:1.6927719116210938e-05
[1,0]<stdout>:training iter13,this iter consuming time:4.142796277999878
[1,1]<stdout>:before forward:7.3909759521484375e-06
[1,1]<stdout>:forward time:0.0041501522064208984
[1,1]<stdout>:Compute loss time:0.00036835670471191406
[1,0]<stdout>:before forward:6.9141387939453125e-06
[1,0]<stdout>:forward time:0.004329204559326172
[1,0]<stdout>:Compute loss time:0.00034046173095703125
[1,1]<stdout>:optimizer zero grad time:0.04572796821594238
[1,1]<stdout>:optimizer backward time:0.02204728126525879
[1,0]<stdout>:optimizer zero grad time:0.043450117111206055
[1,0]<stdout>:optimizer backward time:0.024089336395263672
[1,1]<stdout>:optimizer step time:4.088733673095703
[1,1]<stdout>:learning rate step time:0.00011157989501953125
[1,1]<stdout>:after loss time:4.156751394271851
[1,1]<stdout>:print output time:1.8358230590820312e-05
[1,1]<stdout>:test time:1.6689300537109375e-05
[1,1]<stdout>:training iter14,this iter consuming time:4.1613123416900635
[1,0]<stdout>:optimizer step time:4.054755926132202
[1,0]<stdout>:learning rate step time:0.0001327991485595703
[1,0]<stdout>:after loss time:4.122540712356567
[1,0]<stdout>:print output time:3.6716461181640625e-05
[1,0]<stdout>:test time:1.71661376953125e-05
[1,0]<stdout>:training iter14,this iter consuming time:4.1272711753845215
[1,1]<stdout>:before forward:5.9604644775390625e-06
[1,1]<stdout>:forward time:0.004226207733154297
[1,1]<stdout>:Compute loss time:0.00035834312438964844
[1,0]<stdout>:before forward:6.9141387939453125e-06
[1,0]<stdout>:forward time:0.004714488983154297
[1,0]<stdout>:Compute loss time:0.00037479400634765625
[1,1]<stdout>:optimizer zero grad time:0.04464125633239746
[1,1]<stdout>:optimizer backward time:0.015990257263183594
[1,0]<stdout>:optimizer zero grad time:0.04209494590759277
[1,0]<stdout>:optimizer backward time:0.027002573013305664
[1,0]<stdout>:optimizer step time:4.103464841842651
[1,0]<stdout>:learning rate step time:0.0002262592315673828
[1,0]<stdout>:after loss time:4.172914505004883
[1,0]<stdout>:print output time:6.67572021484375e-05
[1,0]<stdout>:test time:4.839897155761719e-05
[1,0]<stdout>:training iter15,this iter consuming time:4.178125858306885
[1,1]<stdout>:optimizer step time:4.155228137969971
[1,1]<stdout>:learning rate step time:0.0002498626708984375
[1,1]<stdout>:after loss time:4.216249942779541
[1,1]<stdout>:print output time:2.6702880859375e-05
[1,1]<stdout>:test time:6.365776062011719e-05
[1,1]<stdout>:training iter15,this iter consuming time:4.220930814743042
[1,1]<stdout>:before forward:1.049041748046875e-05
[1,1]<stdout>:forward time:0.005646228790283203
[1,1]<stdout>:Compute loss time:0.0005793571472167969
[1,0]<stdout>:before forward:1.0728836059570312e-05
[1,1]<stdout>:optimizer zero grad time:0.05047345161437988
[1,0]<stdout>:forward time:0.0051229000091552734
[1,0]<stdout>:Compute loss time:0.000614166259765625
[1,1]<stdout>:optimizer backward time:0.022583723068237305
[1,0]<stdout>:optimizer zero grad time:0.044634103775024414
[1,0]<stdout>:optimizer backward time:0.02866363525390625
[1,1]<stdout>:optimizer step time:4.124521732330322
[1,1]<stdout>:learning rate step time:0.00012111663818359375
[1,1]<stdout>:after loss time:4.19778037071228
[1,1]<stdout>:print output time:1.4781951904296875e-05
[1,1]<stdout>:test time:1.5735626220703125e-05
[1,1]<stdout>:training iter16,this iter consuming time:4.204046964645386
[1,1]<stdout>:before forward:5.245208740234375e-06
[1,1]<stdout>:forward time:0.003601551055908203
[1,1]<stdout>:Compute loss time:0.000308990478515625
[1,0]<stdout>:optimizer step time:4.100068092346191
[1,0]<stdout>:learning rate step time:0.0003528594970703125
[1,0]<stdout>:after loss time:4.173836946487427
[1,0]<stdout>:print output time:5.125999450683594e-05
[1,0]<stdout>:test time:1.7404556274414062e-05
[1,0]<stdout>:training iter16,this iter consuming time:4.1796534061431885
[1,1]<stdout>:optimizer zero grad time:0.0531916618347168
[1,0]<stdout>:before forward:5.7220458984375e-06
[1,0]<stdout>:forward time:0.0041255950927734375
[1,0]<stdout>:Compute loss time:0.0003418922424316406
[1,1]<stdout>:optimizer backward time:0.029781579971313477
[1,0]<stdout>:optimizer zero grad time:0.042281150817871094
[1,0]<stdout>:optimizer backward time:0.029880523681640625
[1,0]<stdout>:optimizer step time:4.055225849151611
[1,0]<stdout>:learning rate step time:0.00015616416931152344
[1,0]<stdout>:after loss time:4.127631902694702
[1,0]<stdout>:print output time:1.5974044799804688e-05
[1,0]<stdout>:test time:1.430511474609375e-05
[1,0]<stdout>:training iter17,this iter consuming time:4.132135391235352
[1,1]<stdout>:optimizer step time:4.1126837730407715
[1,1]<stdout>:learning rate step time:0.00011277198791503906
[1,1]<stdout>:after loss time:4.195849180221558
[1,1]<stdout>:print output time:1.71661376953125e-05
[1,1]<stdout>:test time:1.5497207641601562e-05
[1,1]<stdout>:training iter17,this iter consuming time:4.199797630310059
[1,1]<stdout>:before forward:5.9604644775390625e-06
[1,1]<stdout>:forward time:0.003519773483276367
[1,1]<stdout>:Compute loss time:0.00030303001403808594
[1,0]<stdout>:before forward:6.4373016357421875e-06
[1,0]<stdout>:forward time:0.004265785217285156
[1,0]<stdout>:Compute loss time:0.0004057884216308594
[1,1]<stdout>:optimizer zero grad time:0.051329612731933594
[1,0]<stdout>:optimizer zero grad time:0.04268813133239746
[1,1]<stdout>:optimizer backward time:0.026511192321777344
[1,0]<stdout>:optimizer backward time:0.029114723205566406
[1,0]<stdout>:optimizer step time:4.072610855102539
[1,0]<stdout>:learning rate step time:0.0002295970916748047
[1,0]<stdout>:after loss time:4.144823312759399
[1,0]<stdout>:print output time:2.4557113647460938e-05
[1,0]<stdout>:test time:1.4066696166992188e-05
[1,0]<stdout>:training iter18,this iter consuming time:4.149539947509766
[1,1]<stdout>:optimizer step time:4.102746486663818
[1,1]<stdout>:learning rate step time:0.00014066696166992188
[1,1]<stdout>:after loss time:4.1808154582977295
[1,1]<stdout>:print output time:1.9550323486328125e-05
[1,1]<stdout>:test time:1.8596649169921875e-05
[1,1]<stdout>:training iter18,this iter consuming time:4.184682369232178
[1,1]<stdout>:before forward:5.7220458984375e-06
[1,1]<stdout>:forward time:0.004235267639160156
[1,1]<stdout>:Compute loss time:0.0003695487976074219
[1,1]<stdout>:optimizer zero grad time:0.051817893981933594
[1,0]<stdout>:before forward:9.775161743164062e-06
[1,0]<stdout>:forward time:0.004394054412841797
[1,0]<stdout>:Compute loss time:0.0005471706390380859
[1,1]<stdout>:optimizer backward time:0.025743961334228516
[1,0]<stdout>:optimizer zero grad time:0.04201793670654297
[1,0]<stdout>:optimizer backward time:0.02805471420288086
[1,0]<stdout>:optimizer step time:4.08881402015686
[1,0]<stdout>:learning rate step time:0.00010037422180175781
[1,0]<stdout>:after loss time:4.159060478210449
[1,0]<stdout>:print output time:2.288818359375e-05
[1,0]<stdout>:test time:1.5020370483398438e-05
[1,0]<stdout>:training iter19,this iter consuming time:4.164049386978149
[1,1]<stdout>:optimizer step time:4.142937421798706
[1,1]<stdout>:learning rate step time:0.0001323223114013672
[1,1]<stdout>:after loss time:4.220720291137695
[1,1]<stdout>:print output time:1.5974044799804688e-05
[1,1]<stdout>:test time:1.811981201171875e-05
[1,1]<stdout>:training iter19,this iter consuming time:4.225364923477173
[1,1]<stdout>:before forward:5.9604644775390625e-06
[1,1]<stdout>:forward time:0.004163265228271484
[1,1]<stdout>:Compute loss time:0.00039267539978027344
[1,0]<stdout>:before forward:6.67572021484375e-06
[1,0]<stdout>:forward time:0.003550291061401367
[1,0]<stdout>:Compute loss time:0.00033783912658691406
[1,1]<stdout>:optimizer zero grad time:0.05141901969909668
[1,1]<stdout>:optimizer backward time:0.02697896957397461
[1,0]<stdout>:optimizer zero grad time:0.04792189598083496
[1,0]<stdout>:optimizer backward time:0.0265042781829834
[1,0]<stdout>:optimizer step time:4.084712982177734
[1,0]<stdout>:learning rate step time:0.00012922286987304688
[1,0]<stdout>:after loss time:4.159353017807007
[1,0]<stdout>:print output time:2.0503997802734375e-05
[1,0]<stdout>:test time:6.127357482910156e-05
[1,0]<stdout>:training iter20,this iter consuming time:4.163329601287842
[1,1]<stdout>:optimizer step time:4.117314338684082
[1,1]<stdout>:learning rate step time:0.00021219253540039062
[1,1]<stdout>:after loss time:4.196048021316528
[1,1]<stdout>:print output time:2.0742416381835938e-05
[1,1]<stdout>:test time:1.4781951904296875e-05
[1,1]<stdout>:training iter20,this iter consuming time:4.200645446777344
[1,1]<stdout>:before forward:7.62939453125e-06
[1,1]<stdout>:forward time:0.004327058792114258
[1,1]<stdout>:Compute loss time:0.000507354736328125
[1,0]<stdout>:before forward:7.62939453125e-06
[1,0]<stdout>:forward time:0.004332065582275391
[1,0]<stdout>:Compute loss time:0.0004050731658935547
[1,1]<stdout>:optimizer zero grad time:0.05133509635925293
[1,1]<stdout>:optimizer backward time:0.026873111724853516
[1,0]<stdout>:optimizer zero grad time:0.049904823303222656
[1,0]<stdout>:optimizer backward time:0.029783964157104492
[1,0]<stdout>:optimizer step time:4.02993106842041
[1,0]<stdout>:learning rate step time:0.00012445449829101562
[1,0]<stdout>:after loss time:4.109830617904663
[1,0]<stdout>:print output time:1.9311904907226562e-05
[1,0]<stdout>:test time:1.4066696166992188e-05
[1,0]<stdout>:training iter21,this iter consuming time:4.1146087646484375
[1,1]<stdout>:optimizer step time:4.066797494888306
[1,1]<stdout>:learning rate step time:0.00011181831359863281
[1,1]<stdout>:after loss time:4.145192861557007
[1,1]<stdout>:print output time:1.52587890625e-05
[1,1]<stdout>:test time:1.4543533325195312e-05
[1,1]<stdout>:training iter21,this iter consuming time:4.150064706802368
[1,1]<stdout>:before forward:5.7220458984375e-06
[1,1]<stdout>:forward time:0.004009723663330078
[1,1]<stdout>:Compute loss time:0.000354766845703125
[1,0]<stdout>:before forward:7.152557373046875e-06
[1,0]<stdout>:forward time:0.004121541976928711
[1,0]<stdout>:Compute loss time:0.00039505958557128906
[1,1]<stdout>:optimizer zero grad time:0.05330395698547363
[1,1]<stdout>:optimizer backward time:0.026263713836669922
[1,0]<stdout>:optimizer zero grad time:0.05043601989746094
[1,0]<stdout>:optimizer backward time:0.022172927856445312
[1,1]<stdout>:optimizer step time:4.048578262329102
[1,1]<stdout>:learning rate step time:0.00011706352233886719
[1,1]<stdout>:after loss time:4.128344535827637
[1,1]<stdout>:print output time:1.71661376953125e-05
[1,1]<stdout>:test time:1.7404556274414062e-05
[1,1]<stdout>:training iter22,this iter consuming time:4.132749319076538
[1,0]<stdout>:optimizer step time:4.02012300491333
[1,0]<stdout>:learning rate step time:0.00010538101196289062
[1,0]<stdout>:after loss time:4.092920780181885
[1,0]<stdout>:print output time:5.4836273193359375e-05
[1,0]<stdout>:test time:2.1219253540039062e-05
[1,0]<stdout>:training iter22,this iter consuming time:4.097520589828491
[1,1]<stdout>:before forward:4.76837158203125e-06
[1,1]<stdout>:forward time:0.0034940242767333984
[1,1]<stdout>:Compute loss time:0.0002961158752441406
[1,0]<stdout>:before forward:7.152557373046875e-06
[1,0]<stdout>:forward time:0.004220008850097656
[1,0]<stdout>:Compute loss time:0.000385284423828125
[1,1]<stdout>:optimizer zero grad time:0.053289175033569336
[1,1]<stdout>:optimizer backward time:0.029091835021972656
[1,0]<stdout>:optimizer zero grad time:0.0505678653717041
[1,0]<stdout>:optimizer backward time:0.02231884002685547
[1,1]<stdout>:optimizer step time:3.840728998184204
[1,1]<stdout>:learning rate step time:0.0001373291015625
[1,1]<stdout>:after loss time:3.9233319759368896
[1,1]<stdout>:print output time:1.9788742065429688e-05
[1,1]<stdout>:test time:1.8596649169921875e-05
[1,1]<stdout>:training iter23,this iter consuming time:3.9271652698516846
[1,1]<stdout>:before forward:7.867813110351562e-06
[1,1]<stdout>:forward time:0.004157543182373047
[1,1]<stdout>:Compute loss time:0.0003771781921386719
[1,0]<stdout>:optimizer step time:3.839414119720459
[1,0]<stdout>:learning rate step time:0.0002262592315673828
[1,0]<stdout>:after loss time:3.912688732147217
[1,0]<stdout>:print output time:2.2411346435546875e-05
[1,0]<stdout>:test time:1.430511474609375e-05
[1,0]<stdout>:training iter23,this iter consuming time:3.9173378944396973
[1,1]<stdout>:optimizer zero grad time:0.051761627197265625
[1,0]<stdout>:before forward:1.0013580322265625e-05
[1,0]<stdout>:forward time:0.005070209503173828
[1,0]<stdout>:Compute loss time:0.0010614395141601562
[1,1]<stdout>:optimizer backward time:0.022394180297851562
[1,0]<stdout>:optimizer zero grad time:0.05026650428771973
[1,0]<stdout>:optimizer backward time:0.016153812408447266
[1,1]<stdout>:optimizer step time:4.255651473999023
[1,1]<stdout>:learning rate step time:0.00010800361633300781
[1,1]<stdout>:after loss time:4.33000111579895
[1,1]<stdout>:print output time:1.4543533325195312e-05
[1,1]<stdout>:test time:1.3828277587890625e-05
[1,1]<stdout>:training iter24,this iter consuming time:4.334572076797485
[1,1]<stdout>:before forward:5.0067901611328125e-06
[1,1]<stdout>:forward time:0.0034928321838378906
[1,1]<stdout>:Compute loss time:0.0002956390380859375
[1,0]<stdout>:optimizer step time:4.209394454956055
[1,0]<stdout>:learning rate step time:0.00013947486877441406
[1,0]<stdout>:after loss time:4.27606987953186
[1,0]<stdout>:print output time:5.412101745605469e-05
[1,0]<stdout>:test time:1.71661376953125e-05
[1,0]<stdout>:training iter24,this iter consuming time:4.282282829284668
[1,0]<stdout>:before forward:7.62939453125e-06
[1,0]<stdout>:forward time:0.0044248104095458984
[1,0]<stdout>:Compute loss time:0.000385284423828125
[1,1]<stdout>:optimizer zero grad time:0.05173659324645996
[1,1]<stdout>:optimizer backward time:0.021718978881835938
[1,0]<stdout>:optimizer zero grad time:0.062137603759765625
[1,0]<stdout>:optimizer backward time:0.028621196746826172
[1,1]<stdout>:optimizer step time:4.11386513710022
[1,1]<stdout>:learning rate step time:0.00010895729064941406
[1,1]<stdout>:after loss time:4.18750786781311
[1,1]<stdout>:print output time:1.430511474609375e-05
[1,1]<stdout>:test time:2.0742416381835938e-05
[1,1]<stdout>:training iter25,this iter consuming time:4.191336393356323
[1,0]<stdout>:optimizer step time:4.073577880859375
[1,0]<stdout>:learning rate step time:0.00011610984802246094
[1,0]<stdout>:after loss time:4.164534568786621
[1,0]<stdout>:print output time:1.9550323486328125e-05
[1,0]<stdout>:test time:1.52587890625e-05
[1,0]<stdout>:training iter25,this iter consuming time:4.169387102127075
[1,1]<stdout>:before forward:4.5299530029296875e-06
[1,1]<stdout>:forward time:0.0034148693084716797
[1,1]<stdout>:Compute loss time:0.00030350685119628906
[1,0]<stdout>:before forward:6.67572021484375e-06
[1,0]<stdout>:forward time:0.0036110877990722656
[1,0]<stdout>:Compute loss time:0.0003428459167480469
[1,1]<stdout>:optimizer zero grad time:0.053069353103637695
[1,1]<stdout>:optimizer backward time:0.027927160263061523
[1,0]<stdout>:optimizer zero grad time:0.06031632423400879
[1,0]<stdout>:optimizer backward time:0.026697397232055664
[1,1]<stdout>:optimizer step time:4.082410097122192
[1,1]<stdout>:learning rate step time:0.0001049041748046875
[1,1]<stdout>:after loss time:4.163591623306274
[1,1]<stdout>:print output time:1.5735626220703125e-05
[1,1]<stdout>:test time:1.621246337890625e-05
[1,1]<stdout>:training iter26,this iter consuming time:4.167346477508545
[1,0]<stdout>:optimizer step time:4.033995151519775
[1,0]<stdout>:learning rate step time:0.00015354156494140625
[1,0]<stdout>:after loss time:4.12129020690918
[1,0]<stdout>:print output time:5.888938903808594e-05
[1,0]<stdout>:test time:2.193450927734375e-05
[1,0]<stdout>:training iter26,this iter consuming time:4.12533164024353
[1,1]<stdout>:before forward:5.0067901611328125e-06
[1,1]<stdout>:forward time:0.0034062862396240234
[1,1]<stdout>:Compute loss time:0.00029730796813964844
[1,0]<stdout>:before forward:7.62939453125e-06
[1,0]<stdout>:forward time:0.004319906234741211
[1,0]<stdout>:Compute loss time:0.0004074573516845703
[1,1]<stdout>:optimizer zero grad time:0.05302023887634277
[1,1]<stdout>:optimizer backward time:0.02771925926208496
[1,0]<stdout>:optimizer zero grad time:0.058045387268066406
[1,0]<stdout>:optimizer backward time:0.025885820388793945
[1,0]<stdout>:optimizer step time:3.992041826248169
[1,0]<stdout>:learning rate step time:0.00010609626770019531
[1,0]<stdout>:after loss time:4.0761706829071045
[1,0]<stdout>:print output time:1.9550323486328125e-05
[1,0]<stdout>:test time:3.2901763916015625e-05
[1,0]<stdout>:training iter27,this iter consuming time:4.080958127975464
[1,1]<stdout>:optimizer step time:4.037654638290405
[1,1]<stdout>:learning rate step time:0.00020766258239746094
[1,1]<stdout>:after loss time:4.118729829788208
[1,1]<stdout>:print output time:1.9311904907226562e-05
[1,1]<stdout>:test time:1.6450881958007812e-05
[1,1]<stdout>:training iter27,this iter consuming time:4.122474193572998
[1,1]<stdout>:before forward:7.152557373046875e-06
[1,1]<stdout>:forward time:0.004312992095947266
[1,1]<stdout>:Compute loss time:0.0004725456237792969
[1,0]<stdout>:before forward:7.867813110351562e-06
[1,0]<stdout>:forward time:0.004192352294921875
[1,0]<stdout>:Compute loss time:0.0003955364227294922
[1,1]<stdout>:optimizer zero grad time:0.05285143852233887
[1,1]<stdout>:optimizer backward time:0.025362730026245117
[1,0]<stdout>:optimizer zero grad time:0.06116819381713867
[1,0]<stdout>:optimizer backward time:0.028547048568725586
