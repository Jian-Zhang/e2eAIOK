{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIDK RNN-T Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content\n",
    "* ### [Model Architecture](#Model-Architecture)\n",
    "* ### [Environment Setup](#Environment-setup)\n",
    "* ### [Launch training](#Launch-training)\n",
    "* ### [Optimizations](#Optimizations)\n",
    "* ### [Performance](*Performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASR\n",
    "![ASR](./img/asr.png)\n",
    "\n",
    "* The traditional ASR system (top picture) contains acoustic, phonetic and language components that work together as in a pipeline system\n",
    "* The end-to-end ASR system is a single neural network that receives raw audio signal as input and provides a sequence of words at output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "![RNN-T](./img/rnnt_structure.png)\n",
    "\n",
    "RNN-T is an end-to-end ASR model that directly converts audio into text representation.\n",
    "\n",
    "The encoder network is a RNN which maps input acoustic frames into a higher-level representation.\n",
    "The prediction network is a RNN that is explicitly conditioned on the history of previous non-blank targets predicted by the model.\n",
    "The joint network is a feed-forward network that combines the outputs of the prediction network and the encoder to produce logits followed by a softmax layer to produce a distribution over the next output symbol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build docker image\n",
    "\n",
    "```\n",
    "cd Dockerfile-ubuntu18.04\n",
    "docker build -t e2eaiok-pytorch110 . -f DockerfilePytorch110\n",
    "```\n",
    "\n",
    "```\n",
    "docker run -itd --name aidk-rnnt --privileged --network host --device=/dev/dri -v ${dataset_path}:/home/vmagent/app/dataset -v ${aidk_code_path}:/home/vmagent/app/e2eaiok -w /home/vmagent/app/ e2eaiok-pytorch110:latest /bin/bash\n",
    "```\n",
    "Enter container with `docker exec -it aidk-rnnt bash`\n",
    "\n",
    "Start the jupyter notebook service\n",
    "\n",
    "```\n",
    "source /opt/intel/oneapi/setvars.sh --ccl-configuration=cpu_icc --force\n",
    "conda activate pytorch-1.10.0\n",
    "pip install jupyter\n",
    "nohup jupyter notebook --notebook-dir=/home/vmagent/app/e2eaiok/ --ip=0.0.0.0 --port=8888 --allow-root &\n",
    "```\n",
    "\n",
    "Now you can visit AIDK RNN-T demo in http://${hostname}:8888/\n",
    "\n",
    "Notes: RNN-T training is based on LibriSpeech train-clean-100 and evaluated on dev-clean, we evaluated WER with stock model (based on MLPerf submission) at train-clean-100 dataset, and final WER is 0.25, all the following optimization guarantee 0.25 WER. MLPerf submission took 38.7min with 8x A100 on LibriSpeech train-960h dataset.\n",
    "\n",
    "public reference on train-clean-100: https://arxiv.org/pdf/1807.10893.pdf, https://arxiv.org/pdf/1811.00787.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scripts/train.sh: line 25: [: : integer expression expected\n",
      "STARTING TIMING RUN AT 2022-09-09 07:59:46 AM\n",
      "running benchmark\n",
      "scripts/train.sh: line 123: [: -ne: unary operator expected\n",
      "Distributed training\n",
      "/opt/intel/oneapi/intelpython/latest/envs/pytorch-1.10.0/lib/python3.9/runpy.py:127: RuntimeWarning: 'intel_extension_for_pytorch.cpu.launch' found in sys.modules after import of package 'intel_extension_for_pytorch.cpu', but prior to execution of 'intel_extension_for_pytorch.cpu.launch'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2022-09-09 07:59:48,825 - __main__ - INFO - MASTER_ADDR=127.0.0.1\n",
      "2022-09-09 07:59:48,825 - __main__ - INFO - MASTER_PORT=29500\n",
      "2022-09-09 07:59:48,825 - __main__ - INFO - I_MPI_PIN_DOMAIN=[0xffffffffffff0,0xffffffffffff00000000000000,]\n",
      "2022-09-09 07:59:48,826 - __main__ - WARNING - Both TCMalloc and JeMalloc are not found in $CONDA_PREFIX/lib or $VIRTUAL_ENV/lib or /.local/lib/ or /usr/local/lib/ or /usr/local/lib64/ or /usr/lib or /usr/lib64 or /root/.local/lib/ so the LD_PRELOAD environment variable will not be set. This may drop the performance\n",
      "2022-09-09 07:59:48,826 - __main__ - INFO - OMP_NUM_THREADS=48\n",
      "2022-09-09 07:59:48,826 - __main__ - INFO - Using Intel OpenMP\n",
      "2022-09-09 07:59:48,827 - __main__ - INFO - KMP_AFFINITY=granularity=fine,compact,1,0\n",
      "2022-09-09 07:59:48,827 - __main__ - INFO - KMP_BLOCKTIME=1\n",
      "2022-09-09 07:59:48,827 - __main__ - INFO - LD_PRELOAD=/opt/intel/oneapi/intelpython/latest/envs/pytorch-1.10.0/lib/libiomp5.so\n",
      "2022-09-09 07:59:48,827 - __main__ - INFO - CCL_WORKER_COUNT=4\n",
      "2022-09-09 07:59:48,827 - __main__ - INFO - CCL_WORKER_AFFINITY=0,1,2,3,52,53,54,55\n",
      "2022-09-09 07:59:48,827 - __main__ - INFO - ['mpiexec.hydra', '-l', '-np', '2', '-ppn', '2', '-genv', 'I_MPI_PIN_DOMAIN=[0xffffffffffff0,0xffffffffffff00000000000000,]', '-genv', 'OMP_NUM_THREADS=48', '/opt/intel/oneapi/intelpython/latest/envs/pytorch-1.10.0/bin/python', '-u', 'train.py', '--batch_size=16', '--beta1=0.9', '--beta2=0.999', '--max_duration=16.7', '--val_batch_size=16', '--target=0.25', '--lr=0.007', '--min_lr=1e-5', '--lr_exp_gamma=0.939', '--epochs=2', '--warmup_epochs=10', '--hold_epochs=33', '--epochs_this_job=0', '--ema=0.999', '--output_dir', '/results', '--model_config=configs/baseline_v3-1023sp.yaml', '--seed', '2021', '--train_dataset_dir=/home/vmagent/app/dataset/LibriSpeech/train', '--valid_dataset_dir=/home/vmagent/app/dataset/LibriSpeech/valid', '--cudnn_benchmark', '--dali_device', 'cpu', '--weight_decay=1e-3', '--log_frequency=1', '--val_frequency=1', '--grad_accumulation_steps=1', '--prediction_frequency=1000000', '--weights_init_scale=0.5', '--val_manifests=/home/vmagent/app/dataset/LibriSpeech/metadata/dev-test.json', '--train_manifests', '/home/vmagent/app/dataset/LibriSpeech/metadata/train-test.json', '--save_at_the_end', '--max_symbol_per_sample=300', '--apex_transducer_loss=fp16', '--fuse_relu_dropout', '--multi_tensor_ema', '--apex_transducer_joint=pack', '--buffer_pre_alloc', '--ema_update_type=fp16', '--dist', '--dist_backend=ccl', '--enc_n_hid', '1024', '--enc_pre_rnn_layers', '2', '--enc_stack_time_factor', '8', '--enc_post_rnn_layers', '3', '--enc_dropout', '0.1', '--pred_n_hid', '512', '--pred_rnn_layers', '2', '--pred_dropout', '0.3', '--joint_n_hid', '512', '--joint_dropout', '0.3', '--rnn_type', 'lstm', '--amp_level', '1', '--data_cpu_threads', '4', '--batch_split_factor', '1', '--min_seq_split_len', '20', '--vectorized_sa', '--multilayer_lstm', '--enable_prefetch', '--tokenized_transcript', '--vectorized_sampler', '--dist_sampler', '--apex_mlp', '--pre_sort_for_seq_split', '--jit_tensor_formation']\n",
      "[1] world_size:2,rank:1[0] world_size:2,rank:0\n",
      "[1] \n",
      "[1] 2022-09-09 08:00:11,775 - torch.distributed.distributed_c10d - INFO - Added key: store_based_barrier_key:1 to store for rank: 1\n",
      "[0] 2022-09-09 08:00:11,785 - torch.distributed.distributed_c10d - INFO - Added key: store_based_barrier_key:1 to store for rank: 0\n",
      "[0] 2022-09-09 08:00:11,786 - torch.distributed.distributed_c10d - INFO - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.\n",
      "[0] Using CCL_ATL_TRANSPORT=(default)\n",
      "[0] Using CCL_ATL_SHM=(default)\n",
      "[1] Using CCL_ATL_TRANSPORT=(default)\n",
      "[1] Using CCL_ATL_SHM=(default)\n",
      "[1] 2022-09-09 08:00:11,794 - torch.distributed.distributed_c10d - INFO - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710411786, \"event_type\": \"INTERVAL_START\", \"key\": \"init_start\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 355}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710412349, \"event_type\": \"POINT_IN_TIME\", \"key\": \"seed\", \"value\": 2021, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 360}}\n",
      "[0] DLL 2022-09-09 08:00:12.355453 - PARAMETER | epochs :  2\n",
      "[0] DLL 2022-09-09 08:00:12.355631 - PARAMETER | warmup_epochs :  10\n",
      "[0] DLL 2022-09-09 08:00:12.355688 - PARAMETER | hold_epochs :  33\n",
      "[0] DLL 2022-09-09 08:00:12.355733 - PARAMETER | epochs_this_job :  0\n",
      "[0] DLL 2022-09-09 08:00:12.355778 - PARAMETER | cudnn_benchmark :  True\n",
      "[0] DLL 2022-09-09 08:00:12.355826 - PARAMETER | amp_level :  1\n",
      "[0] DLL 2022-09-09 08:00:12.355871 - PARAMETER | seed :  2021\n",
      "[0] DLL 2022-09-09 08:00:12.355912 - PARAMETER | local_rank :  0\n",
      "[0] DLL 2022-09-09 08:00:12.355954 - PARAMETER | target :  0.25\n",
      "[0] DLL 2022-09-09 08:00:12.355997 - PARAMETER | apex_transducer_loss :  fp16\n",
      "[0] DLL 2022-09-09 08:00:12.356038 - PARAMETER | fuse_relu_dropout :  True\n",
      "[0] DLL 2022-09-09 08:00:12.356078 - PARAMETER | weights_init_scale :  0.5\n",
      "[0] DLL 2022-09-09 08:00:12.356124 - PARAMETER | hidden_hidden_bias_scale : \n",
      "[0] DLL 2022-09-09 08:00:12.356163 - PARAMETER | batch_eval_mode : \n",
      "[0] DLL 2022-09-09 08:00:12.356206 - PARAMETER | cg_unroll_factor :  4\n",
      "[0] DLL 2022-09-09 08:00:12.356249 - PARAMETER | apex_transducer_joint :  pack\n",
      "[0] DLL 2022-09-09 08:00:12.356287 - PARAMETER | buffer_pre_alloc :  True\n",
      "[0] DLL 2022-09-09 08:00:12.356328 - PARAMETER | multilayer_lstm :  True\n",
      "[0] DLL 2022-09-09 08:00:12.356367 - PARAMETER | batch_split_factor :  1\n",
      "[0] DLL 2022-09-09 08:00:12.356412 - PARAMETER | apex_mlp :  True\n",
      "[0] DLL 2022-09-09 08:00:12.356451 - PARAMETER | num_cg :  0\n",
      "[0] DLL 2022-09-09 08:00:12.356491 - PARAMETER | min_seq_split_len :  20\n",
      "[0] DLL 2022-09-09 08:00:12.356531 - PARAMETER | pre_sort_for_seq_split :  True\n",
      "[0] DLL 2022-09-09 08:00:12.356569 - PARAMETER | dist :  True\n",
      "[0] DLL 2022-09-09 08:00:12.356607 - PARAMETER | dist_backend :  ccl\n",
      "[0] DLL 2022-09-09 08:00:12.356646 - PARAMETER | use_ipex :  False\n",
      "[0] DLL 2022-09-09 08:00:12.356686 - PARAMETER | batch_size :  16\n",
      "[0] DLL 2022-09-09 08:00:12.356771 - PARAMETER | val_batch_size :  16\n",
      "[0] DLL 2022-09-09 08:00:12.356813 - PARAMETER | lr :  0.007\n",
      "[0] DLL 2022-09-09 08:00:12.356855 - PARAMETER | min_lr :  1e-05\n",
      "[0] DLL 2022-09-09 08:00:12.356898 - PARAMETER | lr_exp_gamma :  0.939\n",
      "[0] DLL 2022-09-09 08:00:12.356938 - PARAMETER | weight_decay :  0.001\n",
      "[0] DLL 2022-09-09 08:00:12.356977 - PARAMETER | grad_accumulation_steps :  1\n",
      "[0] DLL 2022-09-09 08:00:12.357015 - PARAMETER | clip_norm :  1\n",
      "[0] DLL 2022-09-09 08:00:12.357055 - PARAMETER | beta1 :  0.9\n",
      "[0] DLL 2022-09-09 08:00:12.357094 - PARAMETER | beta2 :  0.999\n",
      "[0] DLL 2022-09-09 08:00:12.357134 - PARAMETER | ema :  0.999\n",
      "[0] DLL 2022-09-09 08:00:12.357172 - PARAMETER | multi_tensor_ema :  True\n",
      "[0] DLL 2022-09-09 08:00:12.357210 - PARAMETER | dist_lamb :  False\n",
      "[0] DLL 2022-09-09 08:00:12.357249 - PARAMETER | ema_update_type :  fp16\n",
      "[0] DLL 2022-09-09 08:00:12.357287 - PARAMETER | dwu_group_size :  8\n",
      "[0] DLL 2022-09-09 08:00:12.357327 - PARAMETER | dali_device :  cpu\n",
      "[0] DLL 2022-09-09 08:00:12.357364 - PARAMETER | resume :  False\n",
      "[0] DLL 2022-09-09 08:00:12.357401 - PARAMETER | ckpt : \n",
      "[0] DLL 2022-09-09 08:00:12.357438 - PARAMETER | save_at_the_end :  True\n",
      "[0] DLL 2022-09-09 08:00:12.357477 - PARAMETER | save_frequency : \n",
      "[0] DLL 2022-09-09 08:00:12.357517 - PARAMETER | keep_milestones :  []\n",
      "[0] DLL 2022-09-09 08:00:12.357563 - PARAMETER | save_best_from :  200\n",
      "[0] DLL 2022-09-09 08:00:12.357602 - PARAMETER | val_frequency :  1\n",
      "[0] DLL 2022-09-09 08:00:12.360668 - PARAMETER | log_frequency :  1\n",
      "[0] DLL 2022-09-09 08:00:12.360755 - PARAMETER | prediction_frequency :  1000000\n",
      "[0] DLL 2022-09-09 08:00:12.360802 - PARAMETER | model_config :  configs/baseline_v3-1023sp.yaml\n",
      "[0] DLL 2022-09-09 08:00:12.360848 - PARAMETER | num_buckets :  6\n",
      "[0] DLL 2022-09-09 08:00:12.360892 - PARAMETER | vectorized_sampler :  True\n",
      "[0] DLL 2022-09-09 08:00:12.360936 - PARAMETER | dist_sampler :  True\n",
      "[0] DLL 2022-09-09 08:00:12.360975 - PARAMETER | train_manifests :  ['/home/vmagent/app/dataset/LibriSpeech/metadata/train-test.json']\n",
      "[0] DLL 2022-09-09 08:00:12.361026 - PARAMETER | val_manifests :  ['/home/vmagent/app/dataset/LibriSpeech/metadata/dev-test.json']\n",
      "[0] DLL 2022-09-09 08:00:12.361070 - PARAMETER | max_duration :  16.7\n",
      "[0] DLL 2022-09-09 08:00:12.361113 - PARAMETER | max_txt_len :  125\n",
      "[0] DLL 2022-09-09 08:00:12.361152 - PARAMETER | max_eval_sample_duration :  32.7\n",
      "[0] DLL 2022-09-09 08:00:12.361194 - PARAMETER | train_dataset_dir :  /home/vmagent/app/dataset/LibriSpeech/train\n",
      "[0] DLL 2022-09-09 08:00:12.361239 - PARAMETER | valid_dataset_dir :  /home/vmagent/app/dataset/LibriSpeech/valid\n",
      "[0] DLL 2022-09-09 08:00:12.361279 - PARAMETER | output_dir :  /results\n",
      "[0] DLL 2022-09-09 08:00:12.361319 - PARAMETER | log_file : \n",
      "[0] DLL 2022-09-09 08:00:12.361358 - PARAMETER | max_symbol_per_sample :  300\n",
      "[0] DLL 2022-09-09 08:00:12.361397 - PARAMETER | data_cpu_threads :  4\n",
      "[0] DLL 2022-09-09 08:00:12.361436 - PARAMETER | synthetic_audio_seq_len : \n",
      "[0] DLL 2022-09-09 08:00:12.361474 - PARAMETER | synthetic_text_seq_len : \n",
      "[0] DLL 2022-09-09 08:00:12.361510 - PARAMETER | enable_seq_len_stats :  False\n",
      "[0] DLL 2022-09-09 08:00:12.361549 - PARAMETER | vectorized_sa :  True\n",
      "[0] DLL 2022-09-09 08:00:12.361593 - PARAMETER | in_mem_file_list :  False\n",
      "[0] DLL 2022-09-09 08:00:12.361685 - PARAMETER | enable_prefetch :  True\n",
      "[0] DLL 2022-09-09 08:00:12.361727 - PARAMETER | tokenized_transcript :  True\n",
      "[0] DLL 2022-09-09 08:00:12.361768 - PARAMETER | jit_tensor_formation :  True\n",
      "[0] DLL 2022-09-09 08:00:12.361807 - PARAMETER | dali_dont_use_mmap :  False\n",
      "[0] DLL 2022-09-09 08:00:12.361845 - PARAMETER | training_time_threshold : \n",
      "[0] DLL 2022-09-09 08:00:12.361883 - PARAMETER | enc_n_hid :  1024\n",
      "[0] DLL 2022-09-09 08:00:12.361922 - PARAMETER | enc_pre_rnn_layers :  2\n",
      "[0] DLL 2022-09-09 08:00:12.361961 - PARAMETER | enc_stack_time_factor :  8\n",
      "[0] DLL 2022-09-09 08:00:12.362000 - PARAMETER | enc_post_rnn_layers :  3\n",
      "[0] DLL 2022-09-09 08:00:12.362040 - PARAMETER | enc_dropout :  0.1\n",
      "[0] DLL 2022-09-09 08:00:12.362081 - PARAMETER | pred_n_hid :  512\n",
      "[0] DLL 2022-09-09 08:00:12.362119 - PARAMETER | pred_rnn_layers :  2\n",
      "[0] DLL 2022-09-09 08:00:12.362159 - PARAMETER | pred_dropout :  0.3\n",
      "[0] DLL 2022-09-09 08:00:12.362199 - PARAMETER | joint_n_hid :  512\n",
      "[0] DLL 2022-09-09 08:00:12.362236 - PARAMETER | joint_dropout :  0.3\n",
      "[0] DLL 2022-09-09 08:00:12.362276 - PARAMETER | rnn_type :  lstm\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710412408, \"event_type\": \"POINT_IN_TIME\", \"key\": \"gradient_accumulation_steps\", \"value\": 1, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 378}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710412409, \"event_type\": \"POINT_IN_TIME\", \"key\": \"submission_benchmark\", \"value\": \"rnnt\", \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 384}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710412409, \"event_type\": \"POINT_IN_TIME\", \"key\": \"submission_org\", \"value\": \"Intel\", \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 385}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710412409, \"event_type\": \"POINT_IN_TIME\", \"key\": \"submission_division\", \"value\": \"closed\", \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 386}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710412409, \"event_type\": \"POINT_IN_TIME\", \"key\": \"submission_status\", \"value\": \"onprem\", \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 387}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710412410, \"event_type\": \"POINT_IN_TIME\", \"key\": \"submission_platform\", \"value\": \"CPU\", \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 388}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710412415, \"event_type\": \"POINT_IN_TIME\", \"key\": \"model_weights_initialization_scale\", \"value\": 0.5, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 395}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710412679, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/common/rnn.py\", \"lineno\": 87, \"tensor\": \"pre_rnn\"}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710413624, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/common/rnn.py\", \"lineno\": 87, \"tensor\": \"post_rnn\"}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710413636, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/rnnt/model.py\", \"lineno\": 155, \"tensor\": \"pred_embed\"}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710413726, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/common/rnn.py\", \"lineno\": 87, \"tensor\": \"dec_rnn\"}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710413732, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/rnnt/model.py\", \"lineno\": 176, \"tensor\": \"joint_pred\"}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710413742, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/rnnt/model.py\", \"lineno\": 181, \"tensor\": \"joint_enc\"}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710413753, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/rnnt/model.py\", \"lineno\": 190, \"tensor\": \"joint_net\"}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710413753, \"event_type\": \"POINT_IN_TIME\", \"key\": \"eval_max_prediction_symbols\", \"value\": 300, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 416}}\n",
      "[0] Model size: 74.2M params\n",
      "[0] \n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710413811, \"event_type\": \"POINT_IN_TIME\", \"key\": \"model_eval_ema_factor\", \"value\": 0.999, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 430}}\n",
      "[0] Starting with LRs: 0.007[0] \n",
      "[0] DistributedDataParallel(\n",
      "[0]   (module): RNNT(\n",
      "[0]     (encoder): ModuleDict(\n",
      "[0]       (batch_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "[0]       (pre_rnn): LSTM(\n",
      "[0]         (lstm): LSTM(256, 1024, num_layers=2, dropout=0.1)\n",
      "[0]         (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "[0]         (dropout): Dropout(p=0.1, inplace=False)\n",
      "[0]       )\n",
      "[0]       (stack_time): StackTime()\n",
      "[0]       (post_rnn): LSTM(\n",
      "[0]         (lstm): LSTM(8192, 1024, num_layers=3, dropout=0.1)\n",
      "[0]         (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "[0]         (dropout): Dropout(p=0.1, inplace=False)\n",
      "[0]       )\n",
      "[0]     )\n",
      "[0]     (prediction): ModuleDict(\n",
      "[0]       (embed): Embedding(1023, 512)\n",
      "[0]       (dec_rnn): LSTM(\n",
      "[0]         (lstm): LSTM(512, 512, num_layers=2, dropout=0.3)\n",
      "[0]         (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "[0]         (dropout): Dropout(p=0.3, inplace=False)\n",
      "[0]       )\n",
      "[0]     )\n",
      "[0]     (joint_pred): Linear(in_features=512, out_features=512, bias=True)\n",
      "[0]     (joint_enc): Linear(in_features=1024, out_features=512, bias=True)\n",
      "[0]     (joint_net): Sequential(\n",
      "[0]       (0): FusedReluDropout()\n",
      "[0]       (1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "[0]     )\n",
      "[0]   )\n",
      "[0] )[0] \n",
      "[0] Setting up datasets...[0] \n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710414133, \"event_type\": \"POINT_IN_TIME\", \"key\": \"data_train_max_duration\", \"value\": 16.7, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 470}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710414134, \"event_type\": \"POINT_IN_TIME\", \"key\": \"data_speed_perturbaton_max\", \"value\": 1.15, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 472}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710414134, \"event_type\": \"POINT_IN_TIME\", \"key\": \"data_speed_perturbaton_min\", \"value\": 0.85, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 474}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710414134, \"event_type\": \"POINT_IN_TIME\", \"key\": \"data_spec_augment_freq_n\", \"value\": 2, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 476}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710414135, \"event_type\": \"POINT_IN_TIME\", \"key\": \"data_spec_augment_freq_min\", \"value\": 0, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 478}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710414135, \"event_type\": \"POINT_IN_TIME\", \"key\": \"data_spec_augment_freq_max\", \"value\": 20, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 480}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710414135, \"event_type\": \"POINT_IN_TIME\", \"key\": \"data_spec_augment_time_n\", \"value\": 10, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 482}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710414135, \"event_type\": \"POINT_IN_TIME\", \"key\": \"data_spec_augment_time_min\", \"value\": 0, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 484}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710414135, \"event_type\": \"POINT_IN_TIME\", \"key\": \"data_spec_augment_time_max\", \"value\": 0.03, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 486}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710414136, \"event_type\": \"POINT_IN_TIME\", \"key\": \"global_batch_size\", \"value\": 32, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 488}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710414136, \"event_type\": \"INTERVAL_END\", \"key\": \"init_stop\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 558}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710414137, \"event_type\": \"INTERVAL_START\", \"key\": \"run_start\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 561}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710414137, \"event_type\": \"POINT_IN_TIME\", \"key\": \"data_train_num_buckets\", \"value\": 6, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 567}}\n",
      "[0] Launching vectorized bucketing sampler[0] \n",
      "[0] Launching simple sampler[0] \n",
      "[0] Dataset read by DALI. Number of samples: 96[0] \n",
      "[0] Initializing DALI with parameters:[0] \n",
      "[0] \t           __class__ : <class 'common.data.dali.pipeline.DaliPipeline'>[0] \n",
      "[0] \t          batch_size : 16[0] \n",
      "[0] \t           device_id : None[0] \n",
      "[0] \t        dither_coeff : 1e-05[0] \n",
      "[0] \t       dont_use_mmap : False[0] \n",
      "[0] \t           file_root : /home/vmagent/app/dataset/LibriSpeech/train[0] \n",
      "[0] \t    in_mem_file_list : False[0] \n",
      "[0] \t        max_duration : 16.7[0] \n",
      "[0] \t           nfeatures : 80[0] \n",
      "[0] \t                nfft : 512[0] \n",
      "[0] \t         num_threads : 4[0] \n",
      "[0] \t       pipeline_type : train[0] \n",
      "[0] \t            pre_sort : True[0] \n",
      "[0] \t       preemph_coeff : 0.97[0] \n",
      "[0] \tpreprocessing_device : cpu[0] \n",
      "[0] \t      resample_range : [0.85, 1.15][0] \n",
      "[0] \t         sample_rate : 16000[0] \n",
      "[0] \t             sampler : <common.data.dali.sampler.VectorizedBucketingSampler object at 0x7fbfb299db50>[0] \n",
      "[0] \t                seed : 2021[0] \n",
      "[0] \t                self : <common.data.dali.pipeline.DaliPipeline object at 0x7fbfb299d1c0>[0] \n",
      "[0] \t   silence_threshold : -60[0] \n",
      "[0] \t   synthetic_seq_len : None[0] \n",
      "[0] \t         window_size : 0.02[0] \n",
      "[0] \t       window_stride : 0.01[0] \n",
      "[0] /opt/intel/oneapi/intelpython/latest/envs/pytorch-1.10.0/lib/python3.9/site-packages/nvidia/dali/plugin/base_iterator.py:163: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.\n",
      "[0]   _iterator_deprecation_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] /opt/intel/oneapi/intelpython/latest/envs/pytorch-1.10.0/lib/python3.9/site-packages/nvidia/dali/plugin/base_iterator.py:163: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.\n",
      "[1]   _iterator_deprecation_warning()\n",
      "[0] Dataset read by DALI. Number of samples: 73[0] \n",
      "[0] Initializing DALI with parameters:[0] \n",
      "[0] \t           __class__ : <class 'common.data.dali.pipeline.DaliPipeline'>[0] \n",
      "[0] \t          batch_size : 16[0] \n",
      "[0] \t           device_id : None[0] \n",
      "[0] \t        dither_coeff : 1e-05[0] \n",
      "[0] \t       dont_use_mmap : False[0] \n",
      "[0] \t           file_root : /home/vmagent/app/dataset/LibriSpeech/valid[0] \n",
      "[0] \t    in_mem_file_list : False[0] \n",
      "[0] \t        max_duration : inf[0] \n",
      "[0] \t           nfeatures : 80[0] \n",
      "[0] \t                nfft : 512[0] \n",
      "[0] \t         num_threads : 4[0] \n",
      "[0] \t       pipeline_type : val[0] \n",
      "[0] \t            pre_sort : False[0] \n",
      "[0] \t       preemph_coeff : 0.97[0] \n",
      "[0] \tpreprocessing_device : cpu[0] \n",
      "[0] \t      resample_range : None[0] \n",
      "[0] \t         sample_rate : 16000[0] \n",
      "[0] \t             sampler : <common.data.dali.sampler.SimpleSampler object at 0x7fbfb299dd90>[0] \n",
      "[0] \t                seed : 2021[0] \n",
      "[0] \t                self : <common.data.dali.pipeline.DaliPipeline object at 0x7fbfb299d970>[0] \n",
      "[0] \t   silence_threshold : -60[0] \n",
      "[0] \t   synthetic_seq_len : None[0] \n",
      "[0] \t         window_size : 0.02[0] \n",
      "[0] \t       window_stride : 0.01[0] \n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710416226, \"event_type\": \"POINT_IN_TIME\", \"key\": \"train_samples\", \"value\": 96, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 649}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710416227, \"event_type\": \"POINT_IN_TIME\", \"key\": \"eval_samples\", \"value\": 73, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 650}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710416228, \"event_type\": \"POINT_IN_TIME\", \"key\": \"opt_name\", \"value\": \"lamb\", \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 652}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710416228, \"event_type\": \"POINT_IN_TIME\", \"key\": \"opt_base_learning_rate\", \"value\": 0.007, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 653}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710416228, \"event_type\": \"POINT_IN_TIME\", \"key\": \"opt_lamb_epsilon\", \"value\": 1e-09, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 654}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710416229, \"event_type\": \"POINT_IN_TIME\", \"key\": \"opt_lamb_learning_rate_decay_poly_power\", \"value\": 0.939, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 655}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710416229, \"event_type\": \"POINT_IN_TIME\", \"key\": \"opt_learning_rate_warmup_epochs\", \"value\": 10, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 656}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710416229, \"event_type\": \"POINT_IN_TIME\", \"key\": \"opt_lamb_learning_rate_hold_epochs\", \"value\": 33, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 657}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710416229, \"event_type\": \"POINT_IN_TIME\", \"key\": \"opt_lamb_beta_1\", \"value\": 0.9, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 658}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710416230, \"event_type\": \"POINT_IN_TIME\", \"key\": \"opt_lamb_beta_2\", \"value\": 0.999, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 659}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710416230, \"event_type\": \"POINT_IN_TIME\", \"key\": \"opt_gradient_clip_norm\", \"value\": 1, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 660}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710416230, \"event_type\": \"POINT_IN_TIME\", \"key\": \"opt_learning_rate_alt_decay_func\", \"value\": true, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 661}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710416231, \"event_type\": \"POINT_IN_TIME\", \"key\": \"opt_learning_rate_alt_warmup_func\", \"value\": true, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 662}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710416231, \"event_type\": \"POINT_IN_TIME\", \"key\": \"opt_lamb_learning_rate_min\", \"value\": 1e-05, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 663}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710416231, \"event_type\": \"POINT_IN_TIME\", \"key\": \"opt_weight_decay\", \"value\": 0.001, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 664}}\n",
      "[0] /opt/intel/oneapi/intelpython/latest/envs/pytorch-1.10.0/lib/python3.9/site-packages/torch/profiler/profiler.py:52: UserWarning: Profiler won't be using warmup, this can skew profiler results\n",
      "[0]   warn(\"Profiler won't be using warmup, this can skew profiler results\")\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710416233, \"event_type\": \"INTERVAL_START\", \"key\": \"block_start\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 695, \"first_epoch_num\": 1, \"epoch_count\": 1}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710416233, \"event_type\": \"INTERVAL_START\", \"key\": \"epoch_start\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 698, \"epoch_num\": 1}}\n",
      "[1] /opt/intel/oneapi/intelpython/latest/envs/pytorch-1.10.0/lib/python3.9/site-packages/torch/profiler/profiler.py:52: UserWarning: Profiler won't be using warmup, this can skew profiler results\n",
      "[1]   warn(\"Profiler won't be using warmup, this can skew profiler results\")\n",
      "[1] /home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/common/data/features.py:201: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "[1]   x_lens = (x_lens.int() + stacking - 1) // stacking\n",
      "[0] /home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/common/data/features.py:201: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "[0]   x_lens = (x_lens.int() + stacking - 1) // stacking\n",
      "[1] /home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/common/data/dali/iterator.py:151: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "[1]   pivot_len = (audio_shape_sorted[self.split_batch_size] + stack_factor-1) // stack_factor * stack_factor\n",
      "[1] /home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/common/helpers.py:276: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "[1]   batch_offset = torch.cumsum(g_len * ((feat_lens+self.enc_stack_time_factor-1)//self.enc_stack_time_factor), dim=0)\n",
      "[0] /home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/common/data/dali/iterator.py:151: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "[0]   pivot_len = (audio_shape_sorted[self.split_batch_size] + stack_factor-1) // stack_factor * stack_factor\n",
      "[0] /home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/common/helpers.py:276: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "[0]   batch_offset = torch.cumsum(g_len * ((feat_lens+self.enc_stack_time_factor-1)//self.enc_stack_time_factor), dim=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] /home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/rnnt/model.py:64: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "[1]   x_lens = (x_lens.int() + self.factor - 1) // self.factor\n",
      "[0] /home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/rnnt/model.py:64: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "[0]   x_lens = (x_lens.int() + self.factor - 1) // self.factor\n",
      "[0] DLL 2022-09-09 08:00:31.622960 - epoch    1 | iter    1/3 | loss 1003.32 | utts/s     2 | took 15.24 s | lrate 4.52e-04[0] \n",
      "[0] DLL 2022-09-09 08:00:43.140007 - epoch    1 | iter    2/3 | loss  897.04 | utts/s     3 | took 11.52 s | lrate 6.77e-04[0] \n",
      "[0] DLL 2022-09-09 08:00:52.094818 - epoch    1 | iter    3/3 | loss  601.92 | utts/s     4 | took  8.96 s | lrate 9.03e-04[0] \n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710452096, \"event_type\": \"INTERVAL_END\", \"key\": \"epoch_stop\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 784, \"epoch_num\": 1}}\n",
      "[0] DLL 2022-09-09 08:00:52.096816 - epoch    1 | avg train utts/s     3 | took 35.86 s\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710452097, \"event_type\": \"POINT_IN_TIME\", \"key\": \"throughput\", \"value\": 2.6768749609050704, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 791}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710452097, \"event_type\": \"INTERVAL_START\", \"key\": \"eval_start\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 238, \"epoch_num\": 1}}\n",
      "[1] /home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/rnnt/model.py:53: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "[1]   x_lens = (x_lens.int() + self.factor - 1) // self.factor\n",
      "[0] /home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/rnnt/model.py:53: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "[0]   x_lens = (x_lens.int() + self.factor - 1) // self.factor\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710487877, \"event_type\": \"POINT_IN_TIME\", \"key\": \"eval_accuracy\", \"value\": 20.504347826086956, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 259, \"epoch_num\": 1}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710487878, \"event_type\": \"INTERVAL_END\", \"key\": \"eval_stop\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 260, \"epoch_num\": 1}}\n",
      "[0] DLL 2022-09-09 08:01:27.879340 - epoch    1 |   dev ema wer 2050.43 | took 35.78 s[0] \n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710487879, \"event_type\": \"INTERVAL_END\", \"key\": \"block_stop\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 809, \"first_epoch_num\": 1}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710487880, \"event_type\": \"INTERVAL_START\", \"key\": \"block_start\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 695, \"first_epoch_num\": 2, \"epoch_count\": 1}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710487880, \"event_type\": \"INTERVAL_START\", \"key\": \"epoch_start\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 698, \"epoch_num\": 2}}\n",
      "[0] DLL 2022-09-09 08:01:39.495953 - epoch    2 | iter    1/3 | loss  878.30 | utts/s     3 | took 11.52 s | lrate 1.13e-03[0] \n",
      "[0] DLL 2022-09-09 08:01:50.977803 - epoch    2 | iter    2/3 | loss  903.11 | utts/s     3 | took 11.48 s | lrate 1.35e-03[0] \n",
      "[0] DLL 2022-09-09 08:02:03.370517 - epoch    2 | iter    3/3 | loss  562.67 | utts/s     3 | took 12.39 s | lrate 1.58e-03[0] \n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710523371, \"event_type\": \"INTERVAL_END\", \"key\": \"epoch_stop\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 784, \"epoch_num\": 2}}\n",
      "[0] DLL 2022-09-09 08:02:03.372087 - epoch    2 | avg train utts/s     3 | took 35.49 s[0] \n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710523372, \"event_type\": \"POINT_IN_TIME\", \"key\": \"throughput\", \"value\": 2.7049038225359587, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 791}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710523372, \"event_type\": \"INTERVAL_START\", \"key\": \"eval_start\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 238, \"epoch_num\": 2}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710578043, \"event_type\": \"POINT_IN_TIME\", \"key\": \"eval_accuracy\", \"value\": 20.504347826086956, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 259, \"epoch_num\": 2}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710578044, \"event_type\": \"INTERVAL_END\", \"key\": \"eval_stop\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 260, \"epoch_num\": 2}}\n",
      "[0] DLL 2022-09-09 08:02:58.045241 - epoch    2 |   dev ema wer 2050.43 | took 54.67 s[0] \n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662710578045, \"event_type\": \"INTERVAL_END\", \"key\": \"block_stop\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 809, \"first_epoch_num\": 2}}\n",
      "[0] -------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "[0]                                                    Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "[0] -------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "[0]                                                aten::mm        27.00%       18.110s        27.09%       18.166s     467.914us         38823  \n",
      "[0]                                             aten::addmm        18.07%       12.121s        21.60%       14.486s     348.539us         41561  \n",
      "[0]                                           ProfilerStep*         9.19%        6.167s       100.00%       67.067s       33.533s             2  \n",
      "[0]                                              aten::add_         4.17%        2.794s         4.17%        2.794s      29.318us         95286  \n",
      "[0]                                               aten::add         3.32%        2.225s         3.32%        2.226s     125.225us         17775  \n",
      "[0]                                       torch_ipex::copy_         3.29%        2.205s         3.29%        2.206s      33.368us         66098  \n",
      "[0]                                            aten::matmul         3.06%        2.050s        25.16%       16.876s     469.542us         35942  \n",
      "[0]                                              aten::lstm         2.89%        1.936s        56.02%       37.569s       3.136ms         11981  \n",
      "[0]                                          aten::sigmoid_         2.82%        1.891s         2.82%        1.891s      21.305us         88770  \n",
      "[0]                                               aten::mul         2.28%        1.526s         2.28%        1.530s      15.690us         97538  \n",
      "[0]                                            aten::linear         2.16%        1.451s        51.55%       34.574s     446.102us         77503  \n",
      "[0]                                              aten::_cat         2.09%        1.404s         2.49%        1.670s      33.816us         49376  \n",
      "[0]                                        aten::as_strided         1.56%        1.046s         1.56%        1.046s       1.828us        572432  \n",
      "[0]                                               aten::max         1.25%     837.815ms         1.62%        1.083s      90.469us         11975  \n",
      "[0]                                             aten::slice         1.20%     803.426ms         1.62%        1.088s       6.021us        180689  \n",
      "[0]                                               aten::sum         0.93%     626.874ms         0.95%     639.011ms     440.394us          1451  \n",
      "[0]                                            aten::select         0.83%     558.982ms         1.13%     759.140ms       5.445us        139415  \n",
      "[0]                                         aten::transpose         0.80%     533.945ms         1.14%     761.302ms       7.098us        107253  \n",
      "[0]                                             aten::tanh_         0.78%     520.646ms         0.78%     520.646ms      17.595us         29590  \n",
      "[0]                                                 aten::t         0.75%     503.364ms         1.59%        1.067s      12.817us         83272  \n",
      "[0]                                         aten::unsqueeze         0.69%     463.877ms         1.09%     730.008ms       7.064us        103347  \n",
      "[0]                                            aten::narrow         0.65%     432.772ms         1.78%        1.191s       9.030us        131867  \n",
      "[0]                                             aten::stack         0.64%     430.257ms         4.03%        2.703s      56.371us         47945  \n",
      "[0]                                   aten::constant_pad_nd         0.63%     423.412ms         1.24%     833.205ms      69.503us         11988  \n",
      "[0]                                              aten::tanh         0.62%     417.154ms         0.62%     417.154ms      14.098us         29590  \n",
      "[0]                                              aten::view         0.61%     411.521ms         0.61%     411.521ms       3.768us        109227  \n",
      "[0]                                            aten::unbind         0.57%     379.586ms         1.14%     762.379ms      15.899us         47951  \n",
      "[0]                                      aten::unsafe_split         0.56%     376.588ms         2.12%        1.419s      47.962us         29590  \n",
      "[0]                                             aten::empty         0.36%     242.750ms         0.36%     242.750ms       2.215us        109571  \n",
      "[0]                                      aten::index_select         0.32%     217.561ms         0.59%     392.832ms      32.917us         11934  \n",
      "[0]                                             aten::copy_         0.32%     216.030ms         3.61%        2.421s      36.621us         66098  \n",
      "[0]                                               aten::cat         0.32%     211.426ms         2.80%        1.881s      38.097us         49376  \n",
      "[0]                                         aten::clamp_min         0.30%     202.836ms         0.51%     342.401ms      14.301us         23942  \n",
      "[0]                                             aten::fill_         0.28%     191.127ms         0.28%     191.127ms      14.126us         13530  \n",
      "[0]                                      aten::_unsafe_view         0.27%     180.628ms         0.44%     291.784ms       8.117us         35948  \n",
      "[0]                                            aten::expand         0.25%     164.742ms         0.35%     232.777ms       5.600us         41570  \n",
      "[0]                                               aten::div         0.24%     161.935ms         0.24%     164.229ms     943.845us           174  \n",
      "[0]                                           aten::resize_         0.24%     159.667ms         0.24%     159.667ms       3.233us         49383  \n",
      "[0]                                         aten::embedding         0.22%     148.705ms         0.97%     648.978ms      54.381us         11934  \n",
      "[0]                                      aten::unsafe_chunk         0.18%     117.634ms         2.29%        1.537s      51.937us         29590  \n",
      "[0]     autograd::engine::evaluate_function: AddmmBackward0         0.17%     116.554ms         6.48%        4.348s       3.041ms          1430  \n",
      "[0]                                      aten::resolve_conj         0.17%     111.696ms         0.17%     111.696ms       0.689us        162205  \n",
      "[0]                                          aten::_to_copy         0.17%     110.805ms         0.47%     318.188ms      25.718us         12372  \n",
      "[0]                                Optimizer.step#Lamb.step         0.15%     100.805ms         0.61%     408.331ms     408.331ms             1  \n",
      "[0]                                    torch_ccl::allreduce         0.14%      94.083ms         0.14%      94.083ms       9.408ms            10  \n",
      "[0]                                        aten::unsqueeze_         0.13%      84.763ms         0.16%     109.930ms       4.592us         23941  \n",
      "[0]                                  aten::sigmoid_backward         0.12%      78.680ms         0.12%      78.680ms      18.353us          4287  \n",
      "[0]                                        aten::bernoulli_         0.11%      76.991ms         0.11%      77.055ms       5.927ms            13  \n",
      "[0] autograd::engine::evaluate_function: LogSoftmaxBackw...         0.11%      71.198ms         0.17%     113.646ms     113.646ms             1  \n",
      "[0]                                          aten::squeeze_         0.10%      68.944ms         0.13%      89.182ms       3.725us         23940  \n",
      "[0]                                              aten::relu         0.09%      62.733ms         0.44%     292.643ms      24.446us         11971  \n",
      "[0]                                     aten::empty_strided         0.09%      60.560ms         0.09%      60.560ms       4.891us         12383  \n",
      "[0]         autograd::engine::evaluate_function: TBackward0         0.08%      55.802ms         3.03%        2.032s       1.407ms          1444  \n",
      "[0]                                           aten::reshape         0.08%      54.745ms         0.16%     106.040ms       8.854us         11977  \n",
      "[0]                                                aten::to         0.08%      52.972ms         0.55%     371.148ms      15.169us         24468  \n",
      "[0]                                              aten::mul_         0.08%      51.212ms         0.08%      54.198ms     652.988us            83  \n",
      "[0]       autograd::engine::evaluate_function: MulBackward0         0.07%      49.535ms         0.45%     299.996ms      69.783us          4299  \n",
      "[0]                                      aten::_log_softmax         0.07%      48.299ms         0.07%      48.299ms      48.299ms             1  \n",
      "[0]       autograd::engine::evaluate_function: AddBackward0         0.07%      47.572ms         0.12%      80.247ms      27.931us          2873  \n",
      "[0]                                     aten::tanh_backward         0.07%      46.963ms         0.07%      46.963ms      16.432us          2858  \n",
      "[0]                                       aten::as_strided_         0.07%      45.405ms         0.07%      45.578ms       0.952us         47881  \n",
      "[0]                                            MulBackward0         0.07%      44.434ms         0.37%     250.461ms      58.260us          4299  \n",
      "[0]                                          AddmmBackward0         0.07%      44.322ms         5.30%        3.552s       2.484ms          1430  \n",
      "[0] autograd::engine::evaluate_function: torch::jit::(an...         0.06%      42.483ms         0.34%     229.665ms     229.665ms             1  \n",
      "[0]                        aten::_log_softmax_backward_data         0.06%      42.404ms         0.06%      42.404ms      42.404ms             1  \n",
      "[0]                                              aten::item         0.06%      42.296ms         0.10%      65.669ms       5.407us         12145  \n",
      "[0]                                              aten::norm         0.05%      32.442ms         0.05%      32.636ms     398.000us            82  \n",
      "[0]                                    aten::_reshape_alias         0.05%      31.637ms         0.05%      31.637ms       2.642us         11974  \n",
      "[0]                                              aten::sqrt         0.04%      28.742ms         0.04%      28.742ms     653.227us            44  \n",
      "[0]                                          aten::addcmul_         0.04%      28.678ms         0.04%      28.678ms     699.463us            41  \n",
      "[0] autograd::engine::evaluate_function: SigmoidBackward...         0.04%      28.665ms         0.20%     135.952ms      31.713us          4287  \n",
      "[0]                                        SigmoidBackward0         0.04%      28.607ms         0.16%     107.287ms      25.026us          4287  \n",
      "[0]                         DistributedDataParallel.forward         0.04%      27.953ms         4.24%        2.841s        2.841s             1  \n",
      "[0]      autograd::engine::evaluate_function: TanhBackward0         0.04%      27.799ms         0.18%     123.382ms      43.171us          2858  \n",
      "[0]                              torch_ipex::batch_norm_cpu         0.04%      24.330ms         0.04%      26.917ms       5.383ms             5  \n",
      "[0]                               aten::_local_scalar_dense         0.03%      23.373ms         0.03%      23.377ms       1.925us         12145  \n",
      "[0]                                           TanhBackward0         0.03%      22.761ms         0.10%      69.724ms      24.396us          2858  \n",
      "[0]                                           <backward op>         0.03%      21.809ms         0.28%     187.107ms     187.107ms             1  \n",
      "[0]                               aten::cudnn_is_acceptable         0.03%      17.040ms         0.03%      17.040ms       1.422us         11981  \n",
      "[0] autograd::engine::evaluate_function: torch::autograd...         0.02%      16.210ms         0.22%     149.539ms       3.647ms            41  \n",
      "[0]                                           aten::dropout         0.02%      15.852ms         0.05%      32.147ms       2.682us         11988  \n",
      "[0] torch.distributed.ddp.reducer::search_unused_paramet...         0.02%      15.194ms         0.02%      15.194ms      15.194ms             1  \n",
      "[0] autograd::engine::evaluate_function: UnsafeSplitBack...         0.02%      14.611ms         0.26%     173.928ms     121.713us          1429  \n",
      "[0]        autograd::engine::evaluate_function: MmBackward0         0.02%      13.245ms         0.56%     375.106ms      26.793ms            14  \n",
      "[0]                                                   _RNNT         0.02%      11.211ms         0.09%      62.089ms      62.089ms             1  \n",
      "[0]                                              aten::div_         0.02%      11.173ms         0.02%      11.725ms     586.250us            20  \n",
      "[0]                                    UnsafeSplitBackward0         0.01%       8.400ms         0.24%     159.317ms     111.488us          1429  \n",
      "[0]                                              TBackward0         0.01%       6.780ms         0.04%      28.960ms      20.055us          1444  \n",
      "[0]                                                aten::gt         0.01%       5.735ms         0.01%       5.802ms       5.802ms             1  \n",
      "[0]                                           aten::type_as         0.01%       5.626ms         0.04%      29.595ms      29.595ms             1  \n",
      "[0]                        aten::native_layer_norm_backward         0.01%       5.304ms         0.02%      11.342ms       2.836ms             4  \n",
      "[0]                                 aten::native_layer_norm         0.01%       3.525ms         0.01%       3.641ms     910.250us             4  \n",
      "[0]                                            AddBackward0         0.00%       3.143ms         0.00%       3.143ms       1.094us          2873  \n",
      "[0] autograd::engine::evaluate_function: UnbindBackward0...         0.00%       2.788ms         0.60%     405.739ms      25.359ms            16  \n",
      "[0]     autograd::engine::evaluate_function: StackBackward0         0.00%       2.609ms         0.03%      18.950ms       1.184ms            16  \n",
      "[0]                                          StackBackward0         0.00%       1.654ms         0.02%      16.119ms       1.007ms            16  \n",
      "[0]                                             aten::zero_         0.00%       1.139ms         0.09%      61.279ms     319.161us           192  \n",
      "[0]                                             aten::zeros         0.00%       1.135ms         0.03%      18.016ms     125.111us           144  \n",
      "[0]                     torch_ipex::batch_norm_backward_cpu         0.00%     923.000us         0.00%       1.404ms     702.000us             2  \n",
      "[0]                                             MmBackward0         0.00%     902.000us         0.54%     361.861ms      25.847ms            14  \n",
      "[0] -------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "[0] Self CPU time total: 67.067s\n",
      "[0] \n",
      "[0] DLL 2022-09-09 08:11:39.956336 -  | avg train utts/s     0[0] \n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662711099956, \"event_type\": \"INTERVAL_END\", \"key\": \"run_stop\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 830, \"status\": \"aborted\"}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662711099957, \"event_type\": \"INTERVAL_START\", \"key\": \"eval_start\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 238, \"epoch_num\": 2}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662711117511, \"event_type\": \"POINT_IN_TIME\", \"key\": \"eval_accuracy\", \"value\": 20.504347826086956, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 259, \"epoch_num\": 2}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1662711117512, \"event_type\": \"INTERVAL_END\", \"key\": \"eval_stop\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 260, \"epoch_num\": 2}}\n",
      "[0] DLL 2022-09-09 08:11:57.512776 - epoch    2 |   dev ema wer 2050.43 | took 17.56 s[0] \n",
      "[0] Saving /results/RNN-T_epoch2_checkpoint.pt...[0] \n",
      "ENDING TIMING RUN AT 2022-09-09 08:12:26 AM\n",
      "RESULT,RNN_SPEECH_RECOGNITION,760,2022-09-09 07:59:46 AM\n"
     ]
    }
   ],
   "source": [
    "!cd /home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch && bash scripts/train.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model architecture\n",
    "\n",
    "For RNN-T model democratization, we enabled distributed training with pytorch DDP to scale out model training on multi nodes, added time stack layer and increased time stack factor to reduce input sequence lengh, added layer and batch normalization to speedup training converge, decreased layer size to get a lighter model.\n",
    "\n",
    "<center>\n",
    "<img src=\"./img/model_base.png\" width=\"800\"/><figure>base model</figure>\n",
    "<img src=\"./img/model_opt.png\" width=\"800\"/><figure>democratized model</figure>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed training\n",
    "\n",
    "``` python\n",
    "# data parallel\n",
    "if world_size > 1:\n",
    "    model = DDP(model, find_unused_parameters=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add time stack layer\n",
    "\n",
    "For ASR systems, the number of time frames for an audio input sequence is significantly higher than the number of output text labels. LSTM is sequential model which leads to much time cost in process long sequence data like audio data. The StackTime layer stacks audio frames to reduce sequence length and form a higher dimension input, which helps to speedup training process.\n",
    "\n",
    "```python\n",
    "class StackTime(nn.Module):\n",
    "    def __init__(self, factor):\n",
    "        super().__init__()\n",
    "        self.factor = int(factor)\n",
    "\n",
    "    def stack(self, x):\n",
    "        x = x.transpose(0, 1)\n",
    "        T = x.size(1)\n",
    "        padded = torch.nn.functional.pad(x, (0, 0, 0, (self.factor - (T % self.factor)) % self.factor))\n",
    "        B, T, H = padded.size()\n",
    "        x = padded.reshape(B, T // self.factor, -1)\n",
    "        x = x.transpose(0, 1)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, x_lens):\n",
    "        if type(x) is not list:\n",
    "            x = self.stack(x)\n",
    "            x_lens = (x_lens.int() + self.factor - 1) // self.factor\n",
    "            return x, x_lens\n",
    "        else:\n",
    "            if len(x) != 2:\n",
    "                raise NotImplementedError(\"Only number of seq segments equal to 2 is supported\")\n",
    "            assert x[0].size(1) % self.factor == 0, \"The length of the 1st seq segment should be multiple of stack factor\"\n",
    "            y0 = self.stack(x[0])\n",
    "            y1 = self.stack(x[1])\n",
    "            x_lens = (x_lens.int() + self.factor - 1) // self.factor\n",
    "            return [y0, y1], x_lens\n",
    "```\n",
    "\n",
    "About 4x speedup after increase time stack factor from 2 to 8.\n",
    "\n",
    "<center>\n",
    "<img src=\"./img/time_stack_2.PNG\" width=\"800\"/><figure>time_stack = 2</figure>\n",
    "<img src=\"./img/time_stack_8.PNG\" width=\"800\"/><figure>time_stack = 8</figure>\n",
    "</center>\n",
    "\n",
    "Profiling data proves that less time cost on forward/backward since input sequence reduced with time stack layer\n",
    "\n",
    "<center>\n",
    "<img src=\"./img/stack_profile_base.png\" width=\"800\"/><figure>base model profiling</figure>\n",
    "<img src=\"./img/stack_profile_democratize.png\" width=\"800\"/><figure>democratized model profiling</figure>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add layer normalization and batch normalization\n",
    "\n",
    "Layer normalization for LSTM is important to the success of RNN-T modeling. Add layer normalization for LSTM and batch normalization for input feature help to speedup training converge. It takes 52 epochs to converge without normalization, while only 49 epochs needed with normalization. \n",
    "\n",
    "```python\n",
    "enc_mod[\"batch_norm\"] = nn.BatchNorm1d(pre_rnn_input_size)\n",
    "```\n",
    "\n",
    "```python\n",
    "self.layer_norm = torch.nn.LayerNorm(hidden_size)\n",
    "```\n",
    "\n",
    "<center>\n",
    "<img src=\"./img/no_norm.PNG\" width=\"800\"/><figure>without normalization</figure>\n",
    "<img src=\"./img/norm.PNG\" width=\"800\"/><figure>with normalization</figure>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HPO with SDA (Smart Democratization Advisor)\n",
    "\n",
    "SDA config\n",
    "\n",
    "```\n",
    "model_parameter:\n",
    "  project: sda\n",
    "  experiment: rnnt\n",
    "  parameters:\n",
    "  - bounds:\n",
    "      max: 1.0e-2\n",
    "      min: 1.0e-3\n",
    "    name: learning_rate\n",
    "    transformation: log\n",
    "    type: double\n",
    "  - bounds:\n",
    "      max: 10\n",
    "      min: 1\n",
    "    name: warmup_epochs\n",
    "    type: int\n",
    "metrics:\n",
    "- name: training_time\n",
    "  objective: minimize\n",
    "  threshold: 43200\n",
    "- name: WER\n",
    "  objective: minimize\n",
    "  threshold: 0.25\n",
    " ```\n",
    "\n",
    "request suggestions from SDA\n",
    "\n",
    "```python\n",
    "suggestion = self.conn.experiments(self.experiment.id).suggestions().create()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Framework related optimization\n",
    "\n",
    "leverage IPEX for distributed training and enable socket binding for training in two socket system\n",
    "\n",
    "```bash\n",
    "# Use IPEX launch to launch training, enable NUMA binding in two socket system.\n",
    "${CONDA_PREFIX}/bin/python -m intel_extension_for_pytorch.cpu.launch --distributed --nproc_per_node=2 --nnodes=4 --hostfile hosts train.py ${ARGS}\n",
    "```\n",
    "\n",
    "<center>\n",
    "<img src=\"./img/no_numa_binding.png\" width=\"600\"/><figure>without numa binding</figure>\n",
    "<img src=\"./img/numa_binding.png\" width=\"600\"/><figure>enable numa binding</figure>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Overview\n",
    "\n",
    "* Distributed training with HW scaling delivered 5.16x speedup from 1 node to 4 nodes\n",
    "* Time stacking + reduce LSTM layer size delivered 1.86x speedup, and 9.63x speedup over baseline\n",
    "** Time stack factor: 8, LSTM depth 5 -> 4, LSTM width 1024 -> 512\n",
    "* Add layer normalization in encoder and decoder, add batch normalization for input feature delivered 1.07x speedup, and 10.31x speedup over baseline\n",
    "** Add layer normalization in encoder and decoder for LSTM and batch normalization for audio feature\n",
    "* Reduce CCL worker number delivered 1.07x speedup, and 11.06x speedup over baseline\n",
    "\n",
    "![rnnt_perf_raw](./img/rnnt_perf_raw.png)\n",
    "![rnnt_perf_norm](./img/rnnt_perf_norm.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
