experiment:
  project: "distiller"
  tag: "cifar100_kd_vit_hg_pretrainI21k_res18_tolerance12"
  strategy: "OnlyDistillationStrategy"
  model_save:  "/home/vmagent/app/dataset/model"
  loss:
    backbone: 0.1
    distiller: 0.9
dataset:
  type: "cifar100"
  num_workers: 4
  path:  "/home/vmagent/app/dataset/dataset/cifar"
  ### save_logits
  # train_transform: "vit_hg"
  # test_transform: "vit_hg"
  ### load logits
  train_transform: "vit_hg_train"
  test_transform: "vit_hg_train"
model:
  type: "resnet18_cifar"
distiller:
  type: "kd"
  teacher: 
      type: "vit_base_224_in21k_ft_cifar100"
      pretrain: True
  # save_logits: True
  use_saved_logits: True
  # check_logits: True
  logits_path:  "/home/vmagent/app/dataset/model/distiller/cifar100_kd_vit_hg_pretrainI21k_res18/logits"
  logits_topk: 0
  save_logits_STATT_EPOCH: 1
solver:
  batch_size: 128
  start_epoch: 1
  epochs: 200
  optimizer:
    type: "SGD"
    lr: 0.1
    weight_decay: 5e-4
    momentum: 0.9
  scheduler:
    type: "ReducelrOnPlateau"
    lr_decay_rate: 0.2
    patience: 12
  early_stop:
    flag: True
    tolerance_epoch: 15
